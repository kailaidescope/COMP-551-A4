Starting BERT fine-tuning script
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])
Name: bert.pooler.dense.bias  - Size: torch.Size([768])
Name: classifier.weight  - Size: torch.Size([28, 768])
Name: classifier.bias  - Size: torch.Size([28])
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'eval_loss': 2.887942314147949, 'eval_accuracy': 0.36015831134564646, 'eval_f1': 0.08696326037655457, 'eval_runtime': 3.084, 'eval_samples_per_second': 1474.7, 'eval_steps_per_second': 92.412, 'epoch': 1.0}
{'eval_loss': 3.0496273040771484, 'eval_accuracy': 0.3935795954265611, 'eval_f1': 0.09241510952884857, 'eval_runtime': 3.0872, 'eval_samples_per_second': 1473.194, 'eval_steps_per_second': 92.318, 'epoch': 2.0}
{'eval_loss': 2.4202048778533936, 'eval_accuracy': 0.4098504837291117, 'eval_f1': 0.12374802240642364, 'eval_runtime': 3.1206, 'eval_samples_per_second': 1457.4, 'eval_steps_per_second': 91.328, 'epoch': 3.0}
{'eval_loss': 2.309056282043457, 'eval_accuracy': 0.41204925241864554, 'eval_f1': 0.13634500910043687, 'eval_runtime': 3.1411, 'eval_samples_per_second': 1447.896, 'eval_steps_per_second': 90.732, 'epoch': 4.0}
{'eval_loss': 2.283902168273926, 'eval_accuracy': 0.41072999120492526, 'eval_f1': 0.13383948632870313, 'eval_runtime': 3.1394, 'eval_samples_per_second': 1448.683, 'eval_steps_per_second': 90.782, 'epoch': 5.0}
{'eval_loss': 2.0679821968078613, 'eval_accuracy': 0.4226033421284081, 'eval_f1': 0.1430196335336086, 'eval_runtime': 3.1159, 'eval_samples_per_second': 1459.626, 'eval_steps_per_second': 91.467, 'epoch': 6.0}
{'eval_loss': 1.9637701511383057, 'eval_accuracy': 0.45030782761653476, 'eval_f1': 0.1875290388687221, 'eval_runtime': 3.1031, 'eval_samples_per_second': 1465.626, 'eval_steps_per_second': 91.843, 'epoch': 7.0}
{'eval_loss': 1.859674334526062, 'eval_accuracy': 0.4558047493403694, 'eval_f1': 0.17787223342508127, 'eval_runtime': 3.086, 'eval_samples_per_second': 1473.773, 'eval_steps_per_second': 92.354, 'epoch': 8.0}
{'train_runtime': 256.8835, 'train_samples_per_second': 1130.723, 'train_steps_per_second': 70.694, 'train_loss': 2.570079114468612, 'epoch': 8.0}
Classification head saved.
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [27 27 20 ... 27  0 27]
Metrics:
F1: 0.18738066312787938 
Accuracy: 0.4642701525054466
