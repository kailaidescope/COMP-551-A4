Starting BERT epoch experiments script
Train method: head+1
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.5 
Warmup steps: 500
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])  - Requires grad: False
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])  - Requires grad: False
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.pooler.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: classifier.weight  - Size: torch.Size([28, 768])  - Requires grad: True
Name: classifier.bias  - Size: torch.Size([28])  - Requires grad: True
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8552, 'grad_norm': 10.77702522277832, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.601298213005066, 'eval_accuracy': 0.5279243623570801, 'eval_f1': 0.33323122945790296, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.72      0.73      0.72       208\n         anger       0.33      0.09      0.14       109\n     annoyance       0.17      0.28      0.21       164\n      approval       0.35      0.30      0.32       258\n        caring       0.46      0.06      0.11        96\n     confusion       0.20      0.37      0.26       102\n     curiosity       0.42      0.49      0.45       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.33      0.04      0.08        91\n   disapproval       0.29      0.39      0.34       212\n       disgust       0.25      0.03      0.06        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.29      0.10      0.14        52\n          fear       0.73      0.28      0.40        58\n     gratitude       0.87      0.90      0.88       261\n         grief       0.00      0.00      0.00         6\n           joy       0.77      0.23      0.35       106\n          love       0.70      0.82      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.76      0.42      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.85      0.72        40\n       sadness       0.58      0.50      0.54        84\n      surprise       0.30      0.54      0.38        95\n       neutral       0.59      0.65      0.62      1592\n\n      accuracy                           0.53      4548\n     macro avg       0.41      0.33      0.33      4548\n  weighted avg       0.53      0.53      0.51      4548\n', 'eval_runtime': 3.1005, 'eval_samples_per_second': 1466.861, 'eval_steps_per_second': 91.921, 'epoch': 1.0}
{'loss': 1.6124, 'grad_norm': 7.455870628356934, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.582128643989563, 'eval_accuracy': 0.5470536499560247, 'eval_f1': 0.35895238941010915, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.70      0.66       326\n     amusement       0.62      0.86      0.72       208\n         anger       0.37      0.54      0.44       109\n     annoyance       0.62      0.05      0.09       164\n      approval       0.59      0.15      0.24       258\n        caring       0.00      0.00      0.00        96\n     confusion       0.52      0.13      0.20       102\n     curiosity       0.38      0.59      0.46       164\n        desire       0.58      0.58      0.58        52\ndisappointment       0.19      0.09      0.12        91\n   disapproval       0.29      0.35      0.32       212\n       disgust       0.43      0.33      0.37        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.25      0.32        52\n          fear       0.65      0.41      0.51        58\n     gratitude       0.97      0.85      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.31      0.55      0.39       106\n          love       0.49      0.91      0.64       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.56      0.50      0.53       119\n         pride       0.00      0.00      0.00         9\n   realization       0.40      0.08      0.13        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.82      0.68        40\n       sadness       0.45      0.42      0.43        84\n      surprise       0.57      0.35      0.43        95\n       neutral       0.59      0.68      0.63      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.42      0.37      0.36      4548\n  weighted avg       0.54      0.55      0.51      4548\n', 'eval_runtime': 3.1358, 'eval_samples_per_second': 1450.335, 'eval_steps_per_second': 90.885, 'epoch': 2.0}
{'loss': 1.5347, 'grad_norm': 7.707245349884033, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4243673086166382, 'eval_accuracy': 0.5776165347405453, 'eval_f1': 0.3590865258091233, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.81      0.68       326\n     amusement       0.69      0.75      0.72       208\n         anger       0.41      0.36      0.38       109\n     annoyance       0.41      0.07      0.12       164\n      approval       0.64      0.12      0.21       258\n        caring       0.41      0.31      0.35        96\n     confusion       1.00      0.03      0.06       102\n     curiosity       0.40      0.64      0.49       164\n        desire       0.81      0.48      0.60        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.38      0.21      0.27       212\n       disgust       0.41      0.43      0.42        61\n embarrassment       1.00      0.15      0.26        20\n    excitement       0.55      0.21      0.31        52\n          fear       0.63      0.59      0.61        58\n     gratitude       0.82      0.93      0.87       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.42      0.49       106\n          love       0.64      0.91      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.41      0.51       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.03      0.05        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.56      0.23      0.32        40\n       sadness       0.49      0.44      0.46        84\n      surprise       0.59      0.35      0.44        95\n       neutral       0.57      0.80      0.66      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.35      0.36      4548\n  weighted avg       0.58      0.58      0.53      4548\n', 'eval_runtime': 3.1437, 'eval_samples_per_second': 1446.714, 'eval_steps_per_second': 90.658, 'epoch': 3.0}
{'loss': 1.4635, 'grad_norm': 3.8072714805603027, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3970088958740234, 'eval_accuracy': 0.5828935795954265, 'eval_f1': 0.40581397597251506, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.70      0.69      0.69       326\n     amusement       0.75      0.74      0.74       208\n         anger       0.38      0.54      0.45       109\n     annoyance       0.41      0.15      0.22       164\n      approval       0.53      0.21      0.30       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.50      0.05      0.09       102\n     curiosity       0.44      0.52      0.48       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.26      0.07      0.11        91\n   disapproval       0.35      0.21      0.27       212\n       disgust       0.31      0.57      0.40        61\n embarrassment       0.70      0.35      0.47        20\n    excitement       0.26      0.31      0.28        52\n          fear       0.73      0.41      0.53        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.42      0.49       106\n          love       0.66      0.91      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       1.00      0.44      0.62         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.47      0.54        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.49      0.43      0.46        95\n       neutral       0.58      0.79      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.40      0.41      4548\n  weighted avg       0.58      0.58      0.55      4548\n', 'eval_runtime': 3.1489, 'eval_samples_per_second': 1444.304, 'eval_steps_per_second': 90.507, 'epoch': 4.0}
{'loss': 1.4063, 'grad_norm': 9.451008796691895, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4254101514816284, 'eval_accuracy': 0.5718997361477572, 'eval_f1': 0.3828356507401583, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.41      0.89      0.56       326\n     amusement       0.69      0.84      0.75       208\n         anger       0.39      0.55      0.46       109\n     annoyance       0.34      0.15      0.20       164\n      approval       0.77      0.12      0.20       258\n        caring       0.56      0.32      0.41        96\n     confusion       0.59      0.22      0.32       102\n     curiosity       0.48      0.45      0.46       164\n        desire       0.87      0.38      0.53        52\ndisappointment       0.30      0.03      0.06        91\n   disapproval       0.41      0.06      0.11       212\n       disgust       0.41      0.38      0.39        61\n embarrassment       0.67      0.10      0.17        20\n    excitement       0.91      0.19      0.32        52\n          fear       0.60      0.60      0.60        58\n     gratitude       0.96      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.76      0.30      0.43       106\n          love       0.79      0.47      0.59       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.60      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.62      0.14      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.69      0.60      0.64        40\n       sadness       0.54      0.55      0.54        84\n      surprise       0.59      0.47      0.53        95\n       neutral       0.57      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.52      0.36      0.38      4548\n  weighted avg       0.59      0.57      0.53      4548\n', 'eval_runtime': 3.1699, 'eval_samples_per_second': 1434.765, 'eval_steps_per_second': 89.909, 'epoch': 5.0}
{'loss': 1.3383, 'grad_norm': 7.5498046875, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3382445573806763, 'eval_accuracy': 0.5989445910290238, 'eval_f1': 0.44366544752798526, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.65      0.79      0.72       326\n     amusement       0.67      0.85      0.75       208\n         anger       0.39      0.61      0.48       109\n     annoyance       0.32      0.15      0.21       164\n      approval       0.50      0.21      0.30       258\n        caring       0.47      0.58      0.52        96\n     confusion       0.39      0.29      0.34       102\n     curiosity       0.43      0.73      0.54       164\n        desire       0.57      0.50      0.53        52\ndisappointment       0.27      0.19      0.22        91\n   disapproval       0.51      0.26      0.35       212\n       disgust       0.46      0.38      0.41        61\n embarrassment       0.58      0.35      0.44        20\n    excitement       0.27      0.35      0.30        52\n          fear       0.88      0.36      0.51        58\n     gratitude       0.97      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.56      0.58       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.51      0.58       119\n         pride       1.00      0.11      0.20         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.54      0.54      0.54        84\n      surprise       0.49      0.58      0.53        95\n       neutral       0.63      0.70      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.44      4548\n  weighted avg       0.59      0.60      0.58      4548\n', 'eval_runtime': 3.1533, 'eval_samples_per_second': 1442.318, 'eval_steps_per_second': 90.383, 'epoch': 6.0}
{'loss': 1.2656, 'grad_norm': 6.066023349761963, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.2923067808151245, 'eval_accuracy': 0.6048812664907651, 'eval_f1': 0.45010029438271787, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.83      0.69       326\n     amusement       0.72      0.88      0.79       208\n         anger       0.49      0.47      0.48       109\n     annoyance       0.30      0.25      0.27       164\n      approval       0.49      0.23      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.49      0.28      0.36       102\n     curiosity       0.47      0.35      0.40       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.30      0.15      0.20        91\n   disapproval       0.45      0.24      0.31       212\n       disgust       0.41      0.51      0.46        61\n embarrassment       0.64      0.45      0.53        20\n    excitement       0.52      0.27      0.35        52\n          fear       0.64      0.71      0.67        58\n     gratitude       0.95      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.58      0.57       106\n          love       0.71      0.88      0.78       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.63      0.59      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.59      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.70      0.67        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.52      0.55      0.53        95\n       neutral       0.62      0.74      0.68      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.45      4548\n  weighted avg       0.59      0.60      0.58      4548\n', 'eval_runtime': 3.1638, 'eval_samples_per_second': 1437.505, 'eval_steps_per_second': 90.081, 'epoch': 7.0}
{'loss': 1.169, 'grad_norm': 6.797673225402832, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.2745429277420044, 'eval_accuracy': 0.613896218117854, 'eval_f1': 0.47066318912251753, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.71      0.88      0.79       208\n         anger       0.45      0.53      0.49       109\n     annoyance       0.36      0.22      0.27       164\n      approval       0.50      0.26      0.34       258\n        caring       0.62      0.46      0.53        96\n     confusion       0.46      0.28      0.35       102\n     curiosity       0.46      0.56      0.51       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.30      0.14      0.19        91\n   disapproval       0.46      0.30      0.36       212\n       disgust       0.42      0.49      0.45        61\n embarrassment       0.75      0.45      0.56        20\n    excitement       0.36      0.31      0.33        52\n          fear       0.73      0.62      0.67        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.55      0.59       106\n          love       0.68      0.90      0.78       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.63      0.61      0.62       119\n         pride       1.00      0.22      0.36         9\n   realization       0.52      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.45      0.58      0.51        84\n      surprise       0.56      0.53      0.54        95\n       neutral       0.63      0.74      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.53      0.45      0.47      4548\n  weighted avg       0.60      0.61      0.60      4548\n', 'eval_runtime': 3.1585, 'eval_samples_per_second': 1439.934, 'eval_steps_per_second': 90.233, 'epoch': 8.0}
{'train_runtime': 292.2115, 'train_samples_per_second': 994.02, 'train_steps_per_second': 62.147, 'train_loss': 1.4556102870319383, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 20 ... 27 17 25]
Metrics:
F1: 0.48924124132417063 
Accuracy: 0.612636165577342
Results: {'f1': [0.33323122945790296, 0.35895238941010915, 0.3590865258091233, 0.40581397597251506, 0.3828356507401583, 0.44366544752798526, 0.45010029438271787, 0.47066318912251753, 0.48924124132417063], 'accuracy': [0.5279243623570801, 0.5470536499560247, 0.5776165347405453, 0.5828935795954265, 0.5718997361477572, 0.5989445910290238, 0.6048812664907651, 0.613896218117854, 0.612636165577342], 'duration': [38.713502407073975, 74.88679885864258, 111.29919767379761, 147.82869386672974, 184.46126890182495, 221.16060662269592, 257.77953124046326, 294.5871374607086, 297.7607638835907], 'reports': ['                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.72      0.73      0.72       208\n         anger       0.33      0.09      0.14       109\n     annoyance       0.17      0.28      0.21       164\n      approval       0.35      0.30      0.32       258\n        caring       0.46      0.06      0.11        96\n     confusion       0.20      0.37      0.26       102\n     curiosity       0.42      0.49      0.45       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.33      0.04      0.08        91\n   disapproval       0.29      0.39      0.34       212\n       disgust       0.25      0.03      0.06        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.29      0.10      0.14        52\n          fear       0.73      0.28      0.40        58\n     gratitude       0.87      0.90      0.88       261\n         grief       0.00      0.00      0.00         6\n           joy       0.77      0.23      0.35       106\n          love       0.70      0.82      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.76      0.42      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.85      0.72        40\n       sadness       0.58      0.50      0.54        84\n      surprise       0.30      0.54      0.38        95\n       neutral       0.59      0.65      0.62      1592\n\n      accuracy                           0.53      4548\n     macro avg       0.41      0.33      0.33      4548\n  weighted avg       0.53      0.53      0.51      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.62      0.70      0.66       326\n     amusement       0.62      0.86      0.72       208\n         anger       0.37      0.54      0.44       109\n     annoyance       0.62      0.05      0.09       164\n      approval       0.59      0.15      0.24       258\n        caring       0.00      0.00      0.00        96\n     confusion       0.52      0.13      0.20       102\n     curiosity       0.38      0.59      0.46       164\n        desire       0.58      0.58      0.58        52\ndisappointment       0.19      0.09      0.12        91\n   disapproval       0.29      0.35      0.32       212\n       disgust       0.43      0.33      0.37        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.25      0.32        52\n          fear       0.65      0.41      0.51        58\n     gratitude       0.97      0.85      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.31      0.55      0.39       106\n          love       0.49      0.91      0.64       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.56      0.50      0.53       119\n         pride       0.00      0.00      0.00         9\n   realization       0.40      0.08      0.13        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.82      0.68        40\n       sadness       0.45      0.42      0.43        84\n      surprise       0.57      0.35      0.43        95\n       neutral       0.59      0.68      0.63      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.42      0.37      0.36      4548\n  weighted avg       0.54      0.55      0.51      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.59      0.81      0.68       326\n     amusement       0.69      0.75      0.72       208\n         anger       0.41      0.36      0.38       109\n     annoyance       0.41      0.07      0.12       164\n      approval       0.64      0.12      0.21       258\n        caring       0.41      0.31      0.35        96\n     confusion       1.00      0.03      0.06       102\n     curiosity       0.40      0.64      0.49       164\n        desire       0.81      0.48      0.60        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.38      0.21      0.27       212\n       disgust       0.41      0.43      0.42        61\n embarrassment       1.00      0.15      0.26        20\n    excitement       0.55      0.21      0.31        52\n          fear       0.63      0.59      0.61        58\n     gratitude       0.82      0.93      0.87       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.42      0.49       106\n          love       0.64      0.91      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.41      0.51       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.03      0.05        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.56      0.23      0.32        40\n       sadness       0.49      0.44      0.46        84\n      surprise       0.59      0.35      0.44        95\n       neutral       0.57      0.80      0.66      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.35      0.36      4548\n  weighted avg       0.58      0.58      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.70      0.69      0.69       326\n     amusement       0.75      0.74      0.74       208\n         anger       0.38      0.54      0.45       109\n     annoyance       0.41      0.15      0.22       164\n      approval       0.53      0.21      0.30       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.50      0.05      0.09       102\n     curiosity       0.44      0.52      0.48       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.26      0.07      0.11        91\n   disapproval       0.35      0.21      0.27       212\n       disgust       0.31      0.57      0.40        61\n embarrassment       0.70      0.35      0.47        20\n    excitement       0.26      0.31      0.28        52\n          fear       0.73      0.41      0.53        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.42      0.49       106\n          love       0.66      0.91      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       1.00      0.44      0.62         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.47      0.54        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.49      0.43      0.46        95\n       neutral       0.58      0.79      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.40      0.41      4548\n  weighted avg       0.58      0.58      0.55      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.41      0.89      0.56       326\n     amusement       0.69      0.84      0.75       208\n         anger       0.39      0.55      0.46       109\n     annoyance       0.34      0.15      0.20       164\n      approval       0.77      0.12      0.20       258\n        caring       0.56      0.32      0.41        96\n     confusion       0.59      0.22      0.32       102\n     curiosity       0.48      0.45      0.46       164\n        desire       0.87      0.38      0.53        52\ndisappointment       0.30      0.03      0.06        91\n   disapproval       0.41      0.06      0.11       212\n       disgust       0.41      0.38      0.39        61\n embarrassment       0.67      0.10      0.17        20\n    excitement       0.91      0.19      0.32        52\n          fear       0.60      0.60      0.60        58\n     gratitude       0.96      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.76      0.30      0.43       106\n          love       0.79      0.47      0.59       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.60      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.62      0.14      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.69      0.60      0.64        40\n       sadness       0.54      0.55      0.54        84\n      surprise       0.59      0.47      0.53        95\n       neutral       0.57      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.52      0.36      0.38      4548\n  weighted avg       0.59      0.57      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.65      0.79      0.72       326\n     amusement       0.67      0.85      0.75       208\n         anger       0.39      0.61      0.48       109\n     annoyance       0.32      0.15      0.21       164\n      approval       0.50      0.21      0.30       258\n        caring       0.47      0.58      0.52        96\n     confusion       0.39      0.29      0.34       102\n     curiosity       0.43      0.73      0.54       164\n        desire       0.57      0.50      0.53        52\ndisappointment       0.27      0.19      0.22        91\n   disapproval       0.51      0.26      0.35       212\n       disgust       0.46      0.38      0.41        61\n embarrassment       0.58      0.35      0.44        20\n    excitement       0.27      0.35      0.30        52\n          fear       0.88      0.36      0.51        58\n     gratitude       0.97      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.56      0.58       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.51      0.58       119\n         pride       1.00      0.11      0.20         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.54      0.54      0.54        84\n      surprise       0.49      0.58      0.53        95\n       neutral       0.63      0.70      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.44      4548\n  weighted avg       0.59      0.60      0.58      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.59      0.83      0.69       326\n     amusement       0.72      0.88      0.79       208\n         anger       0.49      0.47      0.48       109\n     annoyance       0.30      0.25      0.27       164\n      approval       0.49      0.23      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.49      0.28      0.36       102\n     curiosity       0.47      0.35      0.40       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.30      0.15      0.20        91\n   disapproval       0.45      0.24      0.31       212\n       disgust       0.41      0.51      0.46        61\n embarrassment       0.64      0.45      0.53        20\n    excitement       0.52      0.27      0.35        52\n          fear       0.64      0.71      0.67        58\n     gratitude       0.95      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.58      0.57       106\n          love       0.71      0.88      0.78       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.63      0.59      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.59      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.70      0.67        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.52      0.55      0.53        95\n       neutral       0.62      0.74      0.68      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.45      4548\n  weighted avg       0.59      0.60      0.58      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.71      0.88      0.79       208\n         anger       0.45      0.53      0.49       109\n     annoyance       0.36      0.22      0.27       164\n      approval       0.50      0.26      0.34       258\n        caring       0.62      0.46      0.53        96\n     confusion       0.46      0.28      0.35       102\n     curiosity       0.46      0.56      0.51       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.30      0.14      0.19        91\n   disapproval       0.46      0.30      0.36       212\n       disgust       0.42      0.49      0.45        61\n embarrassment       0.75      0.45      0.56        20\n    excitement       0.36      0.31      0.33        52\n          fear       0.73      0.62      0.67        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.55      0.59       106\n          love       0.68      0.90      0.78       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.63      0.61      0.62       119\n         pride       1.00      0.22      0.36         9\n   realization       0.52      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.45      0.58      0.51        84\n      surprise       0.56      0.53      0.54        95\n       neutral       0.63      0.74      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.53      0.45      0.47      4548\n  weighted avg       0.60      0.61      0.60      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.63      0.72      0.68       348\n     amusement       0.75      0.87      0.80       186\n         anger       0.52      0.47      0.49       131\n     annoyance       0.35      0.19      0.25       194\n      approval       0.53      0.33      0.41       236\n        caring       0.53      0.43      0.47        86\n     confusion       0.47      0.39      0.43        97\n     curiosity       0.46      0.53      0.49       176\n        desire       0.65      0.43      0.52        56\ndisappointment       0.47      0.24      0.32        88\n   disapproval       0.42      0.33      0.37       195\n       disgust       0.51      0.51      0.51        76\n embarrassment       0.56      0.43      0.49        23\n    excitement       0.45      0.44      0.44        57\n          fear       0.66      0.68      0.67        65\n     gratitude       0.91      0.90      0.91       260\n         grief       0.00      0.00      0.00         2\n           joy       0.51      0.59      0.55        93\n          love       0.74      0.91      0.81       160\n   nervousness       0.62      0.67      0.64        12\n      optimism       0.60      0.62      0.61       107\n         pride       0.40      0.29      0.33         7\n   realization       0.39      0.15      0.21        89\n        relief       0.00      0.00      0.00         7\n       remorse       0.58      0.77      0.66        44\n       sadness       0.59      0.50      0.54       102\n      surprise       0.46      0.38      0.42        87\n       neutral       0.64      0.74      0.68      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.51      0.48      0.49      4590\n  weighted avg       0.60      0.61      0.60      4590\n'], 'final': {'f1': 0.48924124132417063, 'accuracy': 0.612636165577342, 'duration': 297.76400780677795, 'report': '                precision    recall  f1-score   support\n\n    admiration       0.63      0.72      0.68       348\n     amusement       0.75      0.87      0.80       186\n         anger       0.52      0.47      0.49       131\n     annoyance       0.35      0.19      0.25       194\n      approval       0.53      0.33      0.41       236\n        caring       0.53      0.43      0.47        86\n     confusion       0.47      0.39      0.43        97\n     curiosity       0.46      0.53      0.49       176\n        desire       0.65      0.43      0.52        56\ndisappointment       0.47      0.24      0.32        88\n   disapproval       0.42      0.33      0.37       195\n       disgust       0.51      0.51      0.51        76\n embarrassment       0.56      0.43      0.49        23\n    excitement       0.45      0.44      0.44        57\n          fear       0.66      0.68      0.67        65\n     gratitude       0.91      0.90      0.91       260\n         grief       0.00      0.00      0.00         2\n           joy       0.51      0.59      0.55        93\n          love       0.74      0.91      0.81       160\n   nervousness       0.62      0.67      0.64        12\n      optimism       0.60      0.62      0.61       107\n         pride       0.40      0.29      0.33         7\n   realization       0.39      0.15      0.21        89\n        relief       0.00      0.00      0.00         7\n       remorse       0.58      0.77      0.66        44\n       sadness       0.59      0.50      0.54       102\n      surprise       0.46      0.38      0.42        87\n       neutral       0.64      0.74      0.68      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.51      0.48      0.49      4590\n  weighted avg       0.60      0.61      0.60      4590\n'}}
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.72      0.68       348
     amusement       0.75      0.87      0.80       186
         anger       0.52      0.47      0.49       131
     annoyance       0.35      0.19      0.25       194
      approval       0.53      0.33      0.41       236
        caring       0.53      0.43      0.47        86
     confusion       0.47      0.39      0.43        97
     curiosity       0.46      0.53      0.49       176
        desire       0.65      0.43      0.52        56
disappointment       0.47      0.24      0.32        88
   disapproval       0.42      0.33      0.37       195
       disgust       0.51      0.51      0.51        76
 embarrassment       0.56      0.43      0.49        23
    excitement       0.45      0.44      0.44        57
          fear       0.66      0.68      0.67        65
     gratitude       0.91      0.90      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.51      0.59      0.55        93
          love       0.74      0.91      0.81       160
   nervousness       0.62      0.67      0.64        12
      optimism       0.60      0.62      0.61       107
         pride       0.40      0.29      0.33         7
   realization       0.39      0.15      0.21        89
        relief       0.00      0.00      0.00         7
       remorse       0.58      0.77      0.66        44
       sadness       0.59      0.50      0.54       102
      surprise       0.46      0.38      0.42        87
       neutral       0.64      0.74      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.51      0.48      0.49      4590
  weighted avg       0.60      0.61      0.60      4590

F1 scores: [0.33323122945790296, 0.35895238941010915, 0.3590865258091233, 0.40581397597251506, 0.3828356507401583, 0.44366544752798526, 0.45010029438271787, 0.47066318912251753, 0.48924124132417063]
Accuracies: [0.5279243623570801, 0.5470536499560247, 0.5776165347405453, 0.5828935795954265, 0.5718997361477572, 0.5989445910290238, 0.6048812664907651, 0.613896218117854, 0.612636165577342]
Durations: [38.713502407073975, 74.88679885864258, 111.29919767379761, 147.82869386672974, 184.46126890182495, 221.16060662269592, 257.77953124046326, 294.5871374607086, 297.7607638835907]
log_history: [{'loss': 1.8552, 'grad_norm': 10.77702522277832, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0, 'step': 2270}, {'eval_loss': 1.601298213005066, 'eval_accuracy': 0.5279243623570801, 'eval_f1': 0.33323122945790296, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.72      0.73      0.72       208\n         anger       0.33      0.09      0.14       109\n     annoyance       0.17      0.28      0.21       164\n      approval       0.35      0.30      0.32       258\n        caring       0.46      0.06      0.11        96\n     confusion       0.20      0.37      0.26       102\n     curiosity       0.42      0.49      0.45       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.33      0.04      0.08        91\n   disapproval       0.29      0.39      0.34       212\n       disgust       0.25      0.03      0.06        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.29      0.10      0.14        52\n          fear       0.73      0.28      0.40        58\n     gratitude       0.87      0.90      0.88       261\n         grief       0.00      0.00      0.00         6\n           joy       0.77      0.23      0.35       106\n          love       0.70      0.82      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.76      0.42      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.85      0.72        40\n       sadness       0.58      0.50      0.54        84\n      surprise       0.30      0.54      0.38        95\n       neutral       0.59      0.65      0.62      1592\n\n      accuracy                           0.53      4548\n     macro avg       0.41      0.33      0.33      4548\n  weighted avg       0.53      0.53      0.51      4548\n', 'eval_runtime': 3.1005, 'eval_samples_per_second': 1466.861, 'eval_steps_per_second': 91.921, 'epoch': 1.0, 'step': 2270}, {'loss': 1.6124, 'grad_norm': 7.455870628356934, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0, 'step': 4540}, {'eval_loss': 1.582128643989563, 'eval_accuracy': 0.5470536499560247, 'eval_f1': 0.35895238941010915, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.70      0.66       326\n     amusement       0.62      0.86      0.72       208\n         anger       0.37      0.54      0.44       109\n     annoyance       0.62      0.05      0.09       164\n      approval       0.59      0.15      0.24       258\n        caring       0.00      0.00      0.00        96\n     confusion       0.52      0.13      0.20       102\n     curiosity       0.38      0.59      0.46       164\n        desire       0.58      0.58      0.58        52\ndisappointment       0.19      0.09      0.12        91\n   disapproval       0.29      0.35      0.32       212\n       disgust       0.43      0.33      0.37        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.25      0.32        52\n          fear       0.65      0.41      0.51        58\n     gratitude       0.97      0.85      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.31      0.55      0.39       106\n          love       0.49      0.91      0.64       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.56      0.50      0.53       119\n         pride       0.00      0.00      0.00         9\n   realization       0.40      0.08      0.13        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.82      0.68        40\n       sadness       0.45      0.42      0.43        84\n      surprise       0.57      0.35      0.43        95\n       neutral       0.59      0.68      0.63      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.42      0.37      0.36      4548\n  weighted avg       0.54      0.55      0.51      4548\n', 'eval_runtime': 3.1358, 'eval_samples_per_second': 1450.335, 'eval_steps_per_second': 90.885, 'epoch': 2.0, 'step': 4540}, {'loss': 1.5347, 'grad_norm': 7.707245349884033, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0, 'step': 6810}, {'eval_loss': 1.4243673086166382, 'eval_accuracy': 0.5776165347405453, 'eval_f1': 0.3590865258091233, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.81      0.68       326\n     amusement       0.69      0.75      0.72       208\n         anger       0.41      0.36      0.38       109\n     annoyance       0.41      0.07      0.12       164\n      approval       0.64      0.12      0.21       258\n        caring       0.41      0.31      0.35        96\n     confusion       1.00      0.03      0.06       102\n     curiosity       0.40      0.64      0.49       164\n        desire       0.81      0.48      0.60        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.38      0.21      0.27       212\n       disgust       0.41      0.43      0.42        61\n embarrassment       1.00      0.15      0.26        20\n    excitement       0.55      0.21      0.31        52\n          fear       0.63      0.59      0.61        58\n     gratitude       0.82      0.93      0.87       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.42      0.49       106\n          love       0.64      0.91      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.41      0.51       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.03      0.05        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.56      0.23      0.32        40\n       sadness       0.49      0.44      0.46        84\n      surprise       0.59      0.35      0.44        95\n       neutral       0.57      0.80      0.66      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.35      0.36      4548\n  weighted avg       0.58      0.58      0.53      4548\n', 'eval_runtime': 3.1437, 'eval_samples_per_second': 1446.714, 'eval_steps_per_second': 90.658, 'epoch': 3.0, 'step': 6810}, {'loss': 1.4635, 'grad_norm': 3.8072714805603027, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0, 'step': 9080}, {'eval_loss': 1.3970088958740234, 'eval_accuracy': 0.5828935795954265, 'eval_f1': 0.40581397597251506, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.70      0.69      0.69       326\n     amusement       0.75      0.74      0.74       208\n         anger       0.38      0.54      0.45       109\n     annoyance       0.41      0.15      0.22       164\n      approval       0.53      0.21      0.30       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.50      0.05      0.09       102\n     curiosity       0.44      0.52      0.48       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.26      0.07      0.11        91\n   disapproval       0.35      0.21      0.27       212\n       disgust       0.31      0.57      0.40        61\n embarrassment       0.70      0.35      0.47        20\n    excitement       0.26      0.31      0.28        52\n          fear       0.73      0.41      0.53        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.42      0.49       106\n          love       0.66      0.91      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       1.00      0.44      0.62         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.47      0.54        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.49      0.43      0.46        95\n       neutral       0.58      0.79      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.52      0.40      0.41      4548\n  weighted avg       0.58      0.58      0.55      4548\n', 'eval_runtime': 3.1489, 'eval_samples_per_second': 1444.304, 'eval_steps_per_second': 90.507, 'epoch': 4.0, 'step': 9080}, {'loss': 1.4063, 'grad_norm': 9.451008796691895, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0, 'step': 11350}, {'eval_loss': 1.4254101514816284, 'eval_accuracy': 0.5718997361477572, 'eval_f1': 0.3828356507401583, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.41      0.89      0.56       326\n     amusement       0.69      0.84      0.75       208\n         anger       0.39      0.55      0.46       109\n     annoyance       0.34      0.15      0.20       164\n      approval       0.77      0.12      0.20       258\n        caring       0.56      0.32      0.41        96\n     confusion       0.59      0.22      0.32       102\n     curiosity       0.48      0.45      0.46       164\n        desire       0.87      0.38      0.53        52\ndisappointment       0.30      0.03      0.06        91\n   disapproval       0.41      0.06      0.11       212\n       disgust       0.41      0.38      0.39        61\n embarrassment       0.67      0.10      0.17        20\n    excitement       0.91      0.19      0.32        52\n          fear       0.60      0.60      0.60        58\n     gratitude       0.96      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.76      0.30      0.43       106\n          love       0.79      0.47      0.59       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.60      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.62      0.14      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.69      0.60      0.64        40\n       sadness       0.54      0.55      0.54        84\n      surprise       0.59      0.47      0.53        95\n       neutral       0.57      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.52      0.36      0.38      4548\n  weighted avg       0.59      0.57      0.53      4548\n', 'eval_runtime': 3.1699, 'eval_samples_per_second': 1434.765, 'eval_steps_per_second': 89.909, 'epoch': 5.0, 'step': 11350}, {'loss': 1.3383, 'grad_norm': 7.5498046875, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0, 'step': 13620}, {'eval_loss': 1.3382445573806763, 'eval_accuracy': 0.5989445910290238, 'eval_f1': 0.44366544752798526, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.65      0.79      0.72       326\n     amusement       0.67      0.85      0.75       208\n         anger       0.39      0.61      0.48       109\n     annoyance       0.32      0.15      0.21       164\n      approval       0.50      0.21      0.30       258\n        caring       0.47      0.58      0.52        96\n     confusion       0.39      0.29      0.34       102\n     curiosity       0.43      0.73      0.54       164\n        desire       0.57      0.50      0.53        52\ndisappointment       0.27      0.19      0.22        91\n   disapproval       0.51      0.26      0.35       212\n       disgust       0.46      0.38      0.41        61\n embarrassment       0.58      0.35      0.44        20\n    excitement       0.27      0.35      0.30        52\n          fear       0.88      0.36      0.51        58\n     gratitude       0.97      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.56      0.58       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.51      0.58       119\n         pride       1.00      0.11      0.20         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.54      0.54      0.54        84\n      surprise       0.49      0.58      0.53        95\n       neutral       0.63      0.70      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.44      4548\n  weighted avg       0.59      0.60      0.58      4548\n', 'eval_runtime': 3.1533, 'eval_samples_per_second': 1442.318, 'eval_steps_per_second': 90.383, 'epoch': 6.0, 'step': 13620}, {'loss': 1.2656, 'grad_norm': 6.066023349761963, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0, 'step': 15890}, {'eval_loss': 1.2923067808151245, 'eval_accuracy': 0.6048812664907651, 'eval_f1': 0.45010029438271787, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.83      0.69       326\n     amusement       0.72      0.88      0.79       208\n         anger       0.49      0.47      0.48       109\n     annoyance       0.30      0.25      0.27       164\n      approval       0.49      0.23      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.49      0.28      0.36       102\n     curiosity       0.47      0.35      0.40       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.30      0.15      0.20        91\n   disapproval       0.45      0.24      0.31       212\n       disgust       0.41      0.51      0.46        61\n embarrassment       0.64      0.45      0.53        20\n    excitement       0.52      0.27      0.35        52\n          fear       0.64      0.71      0.67        58\n     gratitude       0.95      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.58      0.57       106\n          love       0.71      0.88      0.78       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.63      0.59      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.59      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.70      0.67        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.52      0.55      0.53        95\n       neutral       0.62      0.74      0.68      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.44      0.45      4548\n  weighted avg       0.59      0.60      0.58      4548\n', 'eval_runtime': 3.1638, 'eval_samples_per_second': 1437.505, 'eval_steps_per_second': 90.081, 'epoch': 7.0, 'step': 15890}, {'loss': 1.169, 'grad_norm': 6.797673225402832, 'learning_rate': 0.0, 'epoch': 8.0, 'step': 18160}, {'eval_loss': 1.2745429277420044, 'eval_accuracy': 0.613896218117854, 'eval_f1': 0.47066318912251753, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.71      0.88      0.79       208\n         anger       0.45      0.53      0.49       109\n     annoyance       0.36      0.22      0.27       164\n      approval       0.50      0.26      0.34       258\n        caring       0.62      0.46      0.53        96\n     confusion       0.46      0.28      0.35       102\n     curiosity       0.46      0.56      0.51       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.30      0.14      0.19        91\n   disapproval       0.46      0.30      0.36       212\n       disgust       0.42      0.49      0.45        61\n embarrassment       0.75      0.45      0.56        20\n    excitement       0.36      0.31      0.33        52\n          fear       0.73      0.62      0.67        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.55      0.59       106\n          love       0.68      0.90      0.78       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.63      0.61      0.62       119\n         pride       1.00      0.22      0.36         9\n   realization       0.52      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.45      0.58      0.51        84\n      surprise       0.56      0.53      0.54        95\n       neutral       0.63      0.74      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.53      0.45      0.47      4548\n  weighted avg       0.60      0.61      0.60      4548\n', 'eval_runtime': 3.1585, 'eval_samples_per_second': 1439.934, 'eval_steps_per_second': 90.233, 'epoch': 8.0, 'step': 18160}, {'train_runtime': 292.2115, 'train_samples_per_second': 994.02, 'train_steps_per_second': 62.147, 'total_flos': 5115357451308672.0, 'train_loss': 1.4556102870319383, 'epoch': 8.0, 'step': 18160}]
Training Losses ( 8 ): [1.8552, 1.6124, 1.5347, 1.4635, 1.4063, 1.3383, 1.2656, 1.169]
Validation Losses ( 8 ): [1.601298213005066, 1.582128643989563, 1.4243673086166382, 1.3970088958740234, 1.4254101514816284, 1.3382445573806763, 1.2923067808151245, 1.2745429277420044]
Graphs saved to disk
