Starting BERT epoch experiments script
Train method: head+1
======= Search hyperparam: weight_decay  =======
====  weight_decay :  1e-05  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 1e-05 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8293, 'grad_norm': 8.138333320617676, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5871479511260986, 'eval_accuracy': 0.5393579595426561, 'eval_f1': 0.3445864470129442, 'eval_runtime': 3.1019, 'eval_samples_per_second': 1466.177, 'eval_steps_per_second': 91.878, 'epoch': 1.0}
{'loss': 1.5529, 'grad_norm': 5.9241790771484375, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.490155577659607, 'eval_accuracy': 0.5714599824098505, 'eval_f1': 0.39678917793149665, 'eval_runtime': 3.0905, 'eval_samples_per_second': 1471.593, 'eval_steps_per_second': 92.217, 'epoch': 2.0}
{'loss': 1.4633, 'grad_norm': 5.381358623504639, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4071784019470215, 'eval_accuracy': 0.5864116094986808, 'eval_f1': 0.38065105383595327, 'eval_runtime': 3.11, 'eval_samples_per_second': 1462.39, 'eval_steps_per_second': 91.641, 'epoch': 3.0}
{'loss': 1.3931, 'grad_norm': 2.9792349338531494, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3796545267105103, 'eval_accuracy': 0.5881706244503079, 'eval_f1': 0.4290112715251232, 'eval_runtime': 3.1094, 'eval_samples_per_second': 1462.656, 'eval_steps_per_second': 91.657, 'epoch': 4.0}
{'loss': 1.3399, 'grad_norm': 6.103822708129883, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.3921754360198975, 'eval_accuracy': 0.594547053649956, 'eval_f1': 0.42211602609294, 'eval_runtime': 3.1199, 'eval_samples_per_second': 1457.725, 'eval_steps_per_second': 91.348, 'epoch': 5.0}
{'loss': 1.2853, 'grad_norm': 5.876263618469238, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3613027334213257, 'eval_accuracy': 0.5956464379947229, 'eval_f1': 0.4527487354432277, 'eval_runtime': 3.119, 'eval_samples_per_second': 1458.182, 'eval_steps_per_second': 91.377, 'epoch': 6.0}
{'loss': 1.2352, 'grad_norm': 4.289885520935059, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3337945938110352, 'eval_accuracy': 0.6031222515391381, 'eval_f1': 0.4413755044304342, 'eval_runtime': 3.1199, 'eval_samples_per_second': 1457.743, 'eval_steps_per_second': 91.349, 'epoch': 7.0}
{'loss': 1.1941, 'grad_norm': 4.083288192749023, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3226312398910522, 'eval_accuracy': 0.6057607739665787, 'eval_f1': 0.4511401091276578, 'eval_runtime': 3.119, 'eval_samples_per_second': 1458.169, 'eval_steps_per_second': 91.376, 'epoch': 8.0}
{'train_runtime': 287.6092, 'train_samples_per_second': 1009.926, 'train_steps_per_second': 63.141, 'train_loss': 1.4116471210765418, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 25 20 ... 27  0 25]
Metrics:
F1: 0.47746240906316306 
Accuracy: 0.6069716775599129
Final Report:
                 precision    recall  f1-score   support

    admiration       0.64      0.72      0.68       348
     amusement       0.75      0.87      0.80       186
         anger       0.47      0.40      0.44       131
     annoyance       0.38      0.19      0.25       194
      approval       0.49      0.32      0.39       236
        caring       0.53      0.36      0.43        86
     confusion       0.41      0.29      0.34        97
     curiosity       0.46      0.53      0.50       176
        desire       0.61      0.36      0.45        56
disappointment       0.42      0.27      0.33        88
   disapproval       0.41      0.29      0.34       195
       disgust       0.51      0.49      0.50        76
 embarrassment       0.67      0.43      0.53        23
    excitement       0.43      0.40      0.42        57
          fear       0.71      0.69      0.70        65
     gratitude       0.91      0.89      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.58      0.60      0.59        93
          love       0.74      0.86      0.79       160
   nervousness       0.60      0.50      0.55        12
      optimism       0.61      0.61      0.61       107
         pride       0.50      0.29      0.36         7
   realization       0.38      0.10      0.16        89
        relief       0.00      0.00      0.00         7
       remorse       0.59      0.75      0.66        44
       sadness       0.56      0.54      0.55       102
      surprise       0.51      0.38      0.43        87
       neutral       0.62      0.76      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.52      0.46      0.48      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3445864470129442, 0.39678917793149665, 0.38065105383595327, 0.4290112715251232, 0.42211602609294, 0.4527487354432277, 0.4413755044304342, 0.4511401091276578, 0.47746240906316306]
Accuracies: [0.5393579595426561, 0.5714599824098505, 0.5864116094986808, 0.5881706244503079, 0.594547053649956, 0.5956464379947229, 0.6031222515391381, 0.6057607739665787, 0.6069716775599129]
Durations: [39.74003458023071, 75.38796019554138, 111.23854088783264, 147.10897612571716, 183.04735231399536, 219.02917337417603, 255.00724077224731, 290.99854731559753, 294.1287157535553]
Training Losses ( 8 ): [1.8293, 1.5529, 1.4633, 1.3931, 1.3399, 1.2853, 1.2352, 1.1941]
Validation Losses ( 8 ): [1.5871479511260986, 1.490155577659607, 1.4071784019470215, 1.3796545267105103, 1.3921754360198975, 1.3613027334213257, 1.3337945938110352, 1.3226312398910522]
====  weight_decay :  0.0001  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.0001 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8347, 'grad_norm': 8.231342315673828, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5691031217575073, 'eval_accuracy': 0.5457343887423043, 'eval_f1': 0.3398712415121291, 'eval_runtime': 3.1103, 'eval_samples_per_second': 1462.24, 'eval_steps_per_second': 91.631, 'epoch': 1.0}
{'loss': 1.5528, 'grad_norm': 4.4507246017456055, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.49461829662323, 'eval_accuracy': 0.5672823218997362, 'eval_f1': 0.38155818623975685, 'eval_runtime': 3.1074, 'eval_samples_per_second': 1463.606, 'eval_steps_per_second': 91.717, 'epoch': 2.0}
{'loss': 1.4755, 'grad_norm': 17.51344108581543, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.419768214225769, 'eval_accuracy': 0.5813544415127528, 'eval_f1': 0.3748390967876643, 'eval_runtime': 3.1071, 'eval_samples_per_second': 1463.734, 'eval_steps_per_second': 91.725, 'epoch': 3.0}
{'loss': 1.4057, 'grad_norm': 3.633854389190674, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4006341695785522, 'eval_accuracy': 0.5872911169744943, 'eval_f1': 0.40979339280145866, 'eval_runtime': 3.1099, 'eval_samples_per_second': 1462.413, 'eval_steps_per_second': 91.642, 'epoch': 4.0}
{'loss': 1.3492, 'grad_norm': 6.309856414794922, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.3893975019454956, 'eval_accuracy': 0.5921284080914688, 'eval_f1': 0.4125089927346484, 'eval_runtime': 3.1087, 'eval_samples_per_second': 1462.967, 'eval_steps_per_second': 91.677, 'epoch': 5.0}
{'loss': 1.2936, 'grad_norm': 5.30651330947876, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.360163688659668, 'eval_accuracy': 0.5934476693051891, 'eval_f1': 0.43630570408255276, 'eval_runtime': 3.1121, 'eval_samples_per_second': 1461.395, 'eval_steps_per_second': 91.578, 'epoch': 6.0}
{'loss': 1.2394, 'grad_norm': 4.707581520080566, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.34282386302948, 'eval_accuracy': 0.5989445910290238, 'eval_f1': 0.4305094561441951, 'eval_runtime': 3.1109, 'eval_samples_per_second': 1461.965, 'eval_steps_per_second': 91.614, 'epoch': 7.0}
{'loss': 1.2008, 'grad_norm': 4.492629051208496, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.323449730873108, 'eval_accuracy': 0.6048812664907651, 'eval_f1': 0.4546801413353044, 'eval_runtime': 3.1075, 'eval_samples_per_second': 1463.534, 'eval_steps_per_second': 91.712, 'epoch': 8.0}
{'train_runtime': 288.0399, 'train_samples_per_second': 1008.416, 'train_steps_per_second': 63.047, 'train_loss': 1.4189603561871902, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 20 ... 27 17 27]
Metrics:
F1: 0.47213275465630705 
Accuracy: 0.6082788671023965
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.72      0.67       348
     amusement       0.76      0.87      0.81       186
         anger       0.51      0.43      0.46       131
     annoyance       0.35      0.17      0.23       194
      approval       0.50      0.31      0.38       236
        caring       0.55      0.42      0.47        86
     confusion       0.40      0.28      0.33        97
     curiosity       0.47      0.48      0.47       176
        desire       0.63      0.39      0.48        56
disappointment       0.38      0.19      0.26        88
   disapproval       0.39      0.28      0.33       195
       disgust       0.50      0.49      0.49        76
 embarrassment       0.50      0.35      0.41        23
    excitement       0.51      0.42      0.46        57
          fear       0.71      0.71      0.71        65
     gratitude       0.90      0.89      0.89       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.60      0.58        93
          love       0.74      0.87      0.80       160
   nervousness       0.50      0.50      0.50        12
      optimism       0.59      0.62      0.61       107
         pride       0.50      0.29      0.36         7
   realization       0.42      0.11      0.18        89
        relief       0.00      0.00      0.00         7
       remorse       0.59      0.73      0.65        44
       sadness       0.59      0.48      0.53       102
      surprise       0.50      0.43      0.46        87
       neutral       0.62      0.77      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.51      0.46      0.47      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3398712415121291, 0.38155818623975685, 0.3748390967876643, 0.40979339280145866, 0.4125089927346484, 0.43630570408255276, 0.4305094561441951, 0.4546801413353044, 0.47213275465630705]
Accuracies: [0.5457343887423043, 0.5672823218997362, 0.5813544415127528, 0.5872911169744943, 0.5921284080914688, 0.5934476693051891, 0.5989445910290238, 0.6048812664907651, 0.6082788671023965]
Durations: [39.77004432678223, 75.79098320007324, 111.7938084602356, 147.78518390655518, 183.7935061454773, 219.8026533126831, 255.84230756759644, 291.84096789360046, 294.95700120925903]
Training Losses ( 8 ): [1.8347, 1.5528, 1.4755, 1.4057, 1.3492, 1.2936, 1.2394, 1.2008]
Validation Losses ( 8 ): [1.5691031217575073, 1.49461829662323, 1.419768214225769, 1.4006341695785522, 1.3893975019454956, 1.360163688659668, 1.34282386302948, 1.323449730873108]
====  weight_decay :  0.001  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.001 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8264, 'grad_norm': 8.176504135131836, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5637446641921997, 'eval_accuracy': 0.5463940193491644, 'eval_f1': 0.34692581303162734, 'eval_runtime': 3.1073, 'eval_samples_per_second': 1463.668, 'eval_steps_per_second': 91.721, 'epoch': 1.0}
{'loss': 1.5499, 'grad_norm': 4.73097038269043, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.4434581995010376, 'eval_accuracy': 0.5835532102022867, 'eval_f1': 0.40170948762579384, 'eval_runtime': 3.1055, 'eval_samples_per_second': 1464.505, 'eval_steps_per_second': 91.773, 'epoch': 2.0}
{'loss': 1.47, 'grad_norm': 5.540793418884277, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4016687870025635, 'eval_accuracy': 0.5828935795954265, 'eval_f1': 0.3787092911349717, 'eval_runtime': 3.1047, 'eval_samples_per_second': 1464.855, 'eval_steps_per_second': 91.795, 'epoch': 3.0}
{'loss': 1.394, 'grad_norm': 2.218785524368286, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3916749954223633, 'eval_accuracy': 0.5875109938434476, 'eval_f1': 0.4248929358224793, 'eval_runtime': 3.1066, 'eval_samples_per_second': 1463.994, 'eval_steps_per_second': 91.741, 'epoch': 4.0}
{'loss': 1.3434, 'grad_norm': 7.704932689666748, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4020392894744873, 'eval_accuracy': 0.5912489006156553, 'eval_f1': 0.41385428868204016, 'eval_runtime': 3.1043, 'eval_samples_per_second': 1465.054, 'eval_steps_per_second': 91.807, 'epoch': 5.0}
{'loss': 1.2885, 'grad_norm': 5.28088903427124, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.374370813369751, 'eval_accuracy': 0.5954265611257695, 'eval_f1': 0.4568396267737923, 'eval_runtime': 3.1032, 'eval_samples_per_second': 1465.597, 'eval_steps_per_second': 91.841, 'epoch': 6.0}
{'loss': 1.2391, 'grad_norm': 4.191676616668701, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3591575622558594, 'eval_accuracy': 0.6020228671943711, 'eval_f1': 0.4399774214872035, 'eval_runtime': 3.1032, 'eval_samples_per_second': 1465.572, 'eval_steps_per_second': 91.84, 'epoch': 7.0}
{'loss': 1.1921, 'grad_norm': 3.8457179069519043, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3451766967773438, 'eval_accuracy': 0.6044415127528584, 'eval_f1': 0.46293722188068864, 'eval_runtime': 3.1014, 'eval_samples_per_second': 1466.428, 'eval_steps_per_second': 91.894, 'epoch': 8.0}
{'train_runtime': 287.4653, 'train_samples_per_second': 1010.431, 'train_steps_per_second': 63.173, 'train_loss': 1.4129253908401018, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 17 ... 27  0 25]
Metrics:
F1: 0.4783156264423804 
Accuracy: 0.6091503267973856
Final Report:
                 precision    recall  f1-score   support

    admiration       0.64      0.75      0.69       348
     amusement       0.75      0.87      0.80       186
         anger       0.50      0.43      0.46       131
     annoyance       0.30      0.15      0.20       194
      approval       0.51      0.32      0.39       236
        caring       0.51      0.41      0.45        86
     confusion       0.45      0.31      0.37        97
     curiosity       0.47      0.50      0.48       176
        desire       0.56      0.39      0.46        56
disappointment       0.33      0.18      0.24        88
   disapproval       0.41      0.27      0.33       195
       disgust       0.54      0.53      0.53        76
 embarrassment       0.67      0.43      0.53        23
    excitement       0.47      0.37      0.41        57
          fear       0.74      0.71      0.72        65
     gratitude       0.92      0.88      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.56      0.58      0.57        93
          love       0.74      0.88      0.80       160
   nervousness       0.71      0.42      0.53        12
      optimism       0.61      0.61      0.61       107
         pride       0.33      0.14      0.20         7
   realization       0.35      0.10      0.16        89
        relief       1.00      0.14      0.25         7
       remorse       0.56      0.75      0.64        44
       sadness       0.57      0.51      0.54       102
      surprise       0.45      0.43      0.44        87
       neutral       0.62      0.76      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.55      0.46      0.48      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.34692581303162734, 0.40170948762579384, 0.3787092911349717, 0.4248929358224793, 0.41385428868204016, 0.4568396267737923, 0.4399774214872035, 0.46293722188068864, 0.4783156264423804]
Accuracies: [0.5463940193491644, 0.5835532102022867, 0.5828935795954265, 0.5875109938434476, 0.5912489006156553, 0.5954265611257695, 0.6020228671943711, 0.6044415127528584, 0.6091503267973856]
Durations: [37.26706886291504, 73.20549726486206, 109.2020583152771, 145.12399649620056, 181.04300475120544, 216.94610214233398, 252.90227723121643, 288.81662607192993, 291.9287254810333]
Training Losses ( 8 ): [1.8264, 1.5499, 1.47, 1.394, 1.3434, 1.2885, 1.2391, 1.1921]
Validation Losses ( 8 ): [1.5637446641921997, 1.4434581995010376, 1.4016687870025635, 1.3916749954223633, 1.4020392894744873, 1.374370813369751, 1.3591575622558594, 1.3451766967773438]
====  weight_decay :  0.01  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.01 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8338, 'grad_norm': 7.280858516693115, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5649299621582031, 'eval_accuracy': 0.5428759894459103, 'eval_f1': 0.3296573428029176, 'eval_runtime': 3.1051, 'eval_samples_per_second': 1464.684, 'eval_steps_per_second': 91.784, 'epoch': 1.0}
{'loss': 1.5698, 'grad_norm': 4.455932140350342, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.4758156538009644, 'eval_accuracy': 0.5789357959542656, 'eval_f1': 0.3766719296679145, 'eval_runtime': 3.1085, 'eval_samples_per_second': 1463.095, 'eval_steps_per_second': 91.685, 'epoch': 2.0}
{'loss': 1.4732, 'grad_norm': 4.8257060050964355, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4024004936218262, 'eval_accuracy': 0.5861917326297273, 'eval_f1': 0.3762625682383253, 'eval_runtime': 3.1088, 'eval_samples_per_second': 1462.947, 'eval_steps_per_second': 91.675, 'epoch': 3.0}
{'loss': 1.4033, 'grad_norm': 2.605647325515747, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3863526582717896, 'eval_accuracy': 0.5971855760773966, 'eval_f1': 0.4324384598402962, 'eval_runtime': 3.1088, 'eval_samples_per_second': 1462.956, 'eval_steps_per_second': 91.676, 'epoch': 4.0}
{'loss': 1.3487, 'grad_norm': 6.7465643882751465, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.400431752204895, 'eval_accuracy': 0.5910290237467019, 'eval_f1': 0.41655431618449507, 'eval_runtime': 3.111, 'eval_samples_per_second': 1461.9, 'eval_steps_per_second': 91.61, 'epoch': 5.0}
{'loss': 1.29, 'grad_norm': 4.819457530975342, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3634103536605835, 'eval_accuracy': 0.5978452066842568, 'eval_f1': 0.4476921399337264, 'eval_runtime': 3.1114, 'eval_samples_per_second': 1461.736, 'eval_steps_per_second': 91.6, 'epoch': 6.0}
{'loss': 1.2347, 'grad_norm': 4.786069869995117, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3445625305175781, 'eval_accuracy': 0.5958663148636764, 'eval_f1': 0.44295575678337773, 'eval_runtime': 3.1102, 'eval_samples_per_second': 1462.307, 'eval_steps_per_second': 91.635, 'epoch': 7.0}
{'loss': 1.1865, 'grad_norm': 4.498510837554932, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3380119800567627, 'eval_accuracy': 0.5980650835532102, 'eval_f1': 0.45741685867807175, 'eval_runtime': 3.1102, 'eval_samples_per_second': 1462.273, 'eval_steps_per_second': 91.633, 'epoch': 8.0}
{'train_runtime': 288.253, 'train_samples_per_second': 1007.67, 'train_steps_per_second': 63.0, 'train_loss': 1.417500446336385, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [18 14 20 ... 27 17 27]
Metrics:
F1: 0.48556093306374803 
Accuracy: 0.6095860566448802
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.73      0.68       348
     amusement       0.73      0.87      0.79       186
         anger       0.50      0.43      0.46       131
     annoyance       0.35      0.19      0.24       194
      approval       0.51      0.30      0.38       236
        caring       0.50      0.41      0.45        86
     confusion       0.42      0.32      0.36        97
     curiosity       0.47      0.46      0.46       176
        desire       0.66      0.41      0.51        56
disappointment       0.37      0.23      0.28        88
   disapproval       0.43      0.29      0.34       195
       disgust       0.56      0.53      0.54        76
 embarrassment       0.50      0.39      0.44        23
    excitement       0.44      0.42      0.43        57
          fear       0.68      0.72      0.70        65
     gratitude       0.92      0.91      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.58      0.60      0.59        93
          love       0.75      0.89      0.81       160
   nervousness       0.56      0.42      0.48        12
      optimism       0.57      0.59      0.58       107
         pride       0.50      0.29      0.36         7
   realization       0.43      0.10      0.16        89
        relief       0.50      0.14      0.22         7
       remorse       0.62      0.82      0.71        44
       sadness       0.63      0.51      0.57       102
      surprise       0.47      0.43      0.45        87
       neutral       0.62      0.76      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.53      0.47      0.49      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3296573428029176, 0.3766719296679145, 0.3762625682383253, 0.4324384598402962, 0.41655431618449507, 0.4476921399337264, 0.44295575678337773, 0.45741685867807175, 0.48556093306374803]
Accuracies: [0.5428759894459103, 0.5789357959542656, 0.5861917326297273, 0.5971855760773966, 0.5910290237467019, 0.5978452066842568, 0.5958663148636764, 0.5980650835532102, 0.6095860566448802]
Durations: [39.72866749763489, 75.76469135284424, 111.80146026611328, 147.80592441558838, 183.8423044681549, 219.87101793289185, 255.92814874649048, 291.97466826438904, 295.0912938117981]
Training Losses ( 8 ): [1.8338, 1.5698, 1.4732, 1.4033, 1.3487, 1.29, 1.2347, 1.1865]
Validation Losses ( 8 ): [1.5649299621582031, 1.4758156538009644, 1.4024004936218262, 1.3863526582717896, 1.400431752204895, 1.3634103536605835, 1.3445625305175781, 1.3380119800567627]
====  weight_decay :  0.1  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.1 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8342, 'grad_norm': 8.215070724487305, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.537731409072876, 'eval_accuracy': 0.552990325417766, 'eval_f1': 0.33833237838297786, 'eval_runtime': 3.1101, 'eval_samples_per_second': 1462.345, 'eval_steps_per_second': 91.638, 'epoch': 1.0}
{'loss': 1.5693, 'grad_norm': 5.315792560577393, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5128542184829712, 'eval_accuracy': 0.5716798592788038, 'eval_f1': 0.37364688633306065, 'eval_runtime': 3.1096, 'eval_samples_per_second': 1462.555, 'eval_steps_per_second': 91.651, 'epoch': 2.0}
{'loss': 1.4902, 'grad_norm': 4.573399543762207, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.419344186782837, 'eval_accuracy': 0.5804749340369393, 'eval_f1': 0.3694520552992079, 'eval_runtime': 3.1082, 'eval_samples_per_second': 1463.213, 'eval_steps_per_second': 91.692, 'epoch': 3.0}
{'loss': 1.4193, 'grad_norm': 3.7225475311279297, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3903018236160278, 'eval_accuracy': 0.5850923482849604, 'eval_f1': 0.4087030800628048, 'eval_runtime': 3.1093, 'eval_samples_per_second': 1462.696, 'eval_steps_per_second': 91.66, 'epoch': 4.0}
{'loss': 1.3584, 'grad_norm': 6.226444721221924, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.3968901634216309, 'eval_accuracy': 0.5853122251539138, 'eval_f1': 0.3947235411668455, 'eval_runtime': 3.1114, 'eval_samples_per_second': 1461.713, 'eval_steps_per_second': 91.598, 'epoch': 5.0}
{'loss': 1.3026, 'grad_norm': 5.838990211486816, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3527816534042358, 'eval_accuracy': 0.5958663148636764, 'eval_f1': 0.4430544568506186, 'eval_runtime': 3.1101, 'eval_samples_per_second': 1462.342, 'eval_steps_per_second': 91.638, 'epoch': 6.0}
{'loss': 1.2383, 'grad_norm': 3.9234206676483154, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3396953344345093, 'eval_accuracy': 0.5974054529463501, 'eval_f1': 0.43960009396714206, 'eval_runtime': 3.1117, 'eval_samples_per_second': 1461.592, 'eval_steps_per_second': 91.591, 'epoch': 7.0}
{'loss': 1.1676, 'grad_norm': 5.232569217681885, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3234912157058716, 'eval_accuracy': 0.6026824978012313, 'eval_f1': 0.46219692656664096, 'eval_runtime': 3.1119, 'eval_samples_per_second': 1461.509, 'eval_steps_per_second': 91.585, 'epoch': 8.0}
{'train_runtime': 287.9205, 'train_samples_per_second': 1008.834, 'train_steps_per_second': 63.073, 'train_loss': 1.4224893040594024, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25  0 20 ... 27 17 27]
Metrics:
F1: 0.4712115857433065 
Accuracy: 0.6093681917211329
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.73      0.67       348
     amusement       0.74      0.88      0.80       186
         anger       0.51      0.40      0.45       131
     annoyance       0.40      0.20      0.27       194
      approval       0.53      0.35      0.42       236
        caring       0.45      0.35      0.39        86
     confusion       0.38      0.28      0.32        97
     curiosity       0.46      0.52      0.49       176
        desire       0.56      0.36      0.43        56
disappointment       0.45      0.16      0.24        88
   disapproval       0.44      0.31      0.36       195
       disgust       0.46      0.46      0.46        76
 embarrassment       0.53      0.39      0.45        23
    excitement       0.42      0.40      0.41        57
          fear       0.69      0.68      0.68        65
     gratitude       0.92      0.90      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.58      0.57        93
          love       0.75      0.88      0.81       160
   nervousness       0.67      0.50      0.57        12
      optimism       0.58      0.61      0.59       107
         pride       0.40      0.29      0.33         7
   realization       0.41      0.13      0.20        89
        relief       0.00      0.00      0.00         7
       remorse       0.60      0.77      0.67        44
       sadness       0.59      0.58      0.58       102
      surprise       0.46      0.37      0.41        87
       neutral       0.63      0.76      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.51      0.46      0.47      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.33833237838297786, 0.37364688633306065, 0.3694520552992079, 0.4087030800628048, 0.3947235411668455, 0.4430544568506186, 0.43960009396714206, 0.46219692656664096, 0.4712115857433065]
Accuracies: [0.552990325417766, 0.5716798592788038, 0.5804749340369393, 0.5850923482849604, 0.5853122251539138, 0.5958663148636764, 0.5974054529463501, 0.6026824978012313, 0.6093681917211329]
Durations: [37.17577838897705, 73.17265200614929, 109.19949769973755, 145.13994216918945, 181.1133964061737, 217.1062936782837, 253.11545062065125, 289.1330349445343, 292.2499053478241]
Training Losses ( 8 ): [1.8342, 1.5693, 1.4902, 1.4193, 1.3584, 1.3026, 1.2383, 1.1676]
Validation Losses ( 8 ): [1.537731409072876, 1.5128542184829712, 1.419344186782837, 1.3903018236160278, 1.3968901634216309, 1.3527816534042358, 1.3396953344345093, 1.3234912157058716]
====  weight_decay :  1.0  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 1.0 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8959, 'grad_norm': 8.82880687713623, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6588811874389648, 'eval_accuracy': 0.5310026385224275, 'eval_f1': 0.2953324909048085, 'eval_runtime': 3.1112, 'eval_samples_per_second': 1461.829, 'eval_steps_per_second': 91.605, 'epoch': 1.0}
{'loss': 1.7094, 'grad_norm': 6.2344794273376465, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.665259599685669, 'eval_accuracy': 0.5354001759014951, 'eval_f1': 0.31121940181857405, 'eval_runtime': 3.1088, 'eval_samples_per_second': 1462.958, 'eval_steps_per_second': 91.676, 'epoch': 2.0}
{'loss': 1.6197, 'grad_norm': 7.066353797912598, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4900264739990234, 'eval_accuracy': 0.5789357959542656, 'eval_f1': 0.33263020087757456, 'eval_runtime': 3.1084, 'eval_samples_per_second': 1463.14, 'eval_steps_per_second': 91.688, 'epoch': 3.0}
{'loss': 1.5206, 'grad_norm': 5.215970993041992, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4585480690002441, 'eval_accuracy': 0.5677220756376429, 'eval_f1': 0.36119126270237184, 'eval_runtime': 3.1082, 'eval_samples_per_second': 1463.245, 'eval_steps_per_second': 91.694, 'epoch': 4.0}
{'loss': 1.4664, 'grad_norm': 9.738844871520996, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4058293104171753, 'eval_accuracy': 0.5806948109058927, 'eval_f1': 0.39529432676839277, 'eval_runtime': 3.1099, 'eval_samples_per_second': 1462.41, 'eval_steps_per_second': 91.642, 'epoch': 5.0}
{'loss': 1.4063, 'grad_norm': 7.412135124206543, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3539191484451294, 'eval_accuracy': 0.5976253298153035, 'eval_f1': 0.42467692606372387, 'eval_runtime': 3.1116, 'eval_samples_per_second': 1461.646, 'eval_steps_per_second': 91.594, 'epoch': 6.0}
{'loss': 1.3329, 'grad_norm': 6.535971164703369, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3108389377593994, 'eval_accuracy': 0.6009234828496042, 'eval_f1': 0.4324381258904613, 'eval_runtime': 3.1081, 'eval_samples_per_second': 1463.273, 'eval_steps_per_second': 91.696, 'epoch': 7.0}
{'loss': 1.2384, 'grad_norm': 7.927535057067871, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.2719240188598633, 'eval_accuracy': 0.6134564643799473, 'eval_f1': 0.4560982263408811, 'eval_runtime': 3.1106, 'eval_samples_per_second': 1462.107, 'eval_steps_per_second': 91.623, 'epoch': 8.0}
{'train_runtime': 287.9941, 'train_samples_per_second': 1008.576, 'train_steps_per_second': 63.057, 'train_loss': 1.5236913605408522, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 20 ... 27 17 27]
Metrics:
F1: 0.48442998262818204 
Accuracy: 0.6135076252723312
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.74      0.68       348
     amusement       0.74      0.90      0.81       186
         anger       0.49      0.47      0.48       131
     annoyance       0.33      0.16      0.22       194
      approval       0.52      0.33      0.41       236
        caring       0.52      0.45      0.48        86
     confusion       0.47      0.39      0.43        97
     curiosity       0.49      0.59      0.53       176
        desire       0.62      0.41      0.49        56
disappointment       0.43      0.23      0.30        88
   disapproval       0.43      0.33      0.37       195
       disgust       0.48      0.46      0.47        76
 embarrassment       0.45      0.43      0.44        23
    excitement       0.51      0.42      0.46        57
          fear       0.63      0.63      0.63        65
     gratitude       0.90      0.89      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.56      0.58      0.57        93
          love       0.72      0.91      0.80       160
   nervousness       0.67      0.50      0.57        12
      optimism       0.59      0.59      0.59       107
         pride       0.50      0.14      0.22         7
   realization       0.48      0.12      0.20        89
        relief       0.50      0.14      0.22         7
       remorse       0.58      0.73      0.65        44
       sadness       0.55      0.50      0.53       102
      surprise       0.48      0.38      0.42        87
       neutral       0.64      0.74      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.53      0.47      0.48      4590
  weighted avg       0.60      0.61      0.60      4590

F1 scores: [0.2953324909048085, 0.31121940181857405, 0.33263020087757456, 0.36119126270237184, 0.39529432676839277, 0.42467692606372387, 0.4324381258904613, 0.4560982263408811, 0.48442998262818204]
Accuracies: [0.5310026385224275, 0.5354001759014951, 0.5789357959542656, 0.5677220756376429, 0.5806948109058927, 0.5976253298153035, 0.6009234828496042, 0.6134564643799473, 0.6135076252723312]
Durations: [37.29700016975403, 73.31433391571045, 109.34944033622742, 145.30849885940552, 181.277174949646, 217.28695702552795, 253.304181098938, 289.31755924224854, 292.4359223842621]
Training Losses ( 8 ): [1.8959, 1.7094, 1.6197, 1.5206, 1.4664, 1.4063, 1.3329, 1.2384]
Validation Losses ( 8 ): [1.6588811874389648, 1.665259599685669, 1.4900264739990234, 1.4585480690002441, 1.4058293104171753, 1.3539191484451294, 1.3108389377593994, 1.2719240188598633]
====  weight_decay :  10.0  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 10.0 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 2.0608, 'grad_norm': 7.439424514770508, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.8265467882156372, 'eval_accuracy': 0.4980211081794195, 'eval_f1': 0.18680351853967178, 'eval_runtime': 3.1161, 'eval_samples_per_second': 1459.525, 'eval_steps_per_second': 91.461, 'epoch': 1.0}
{'loss': 1.9365, 'grad_norm': 7.0083160400390625, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.9155793190002441, 'eval_accuracy': 0.5, 'eval_f1': 0.20120923145901742, 'eval_runtime': 3.1197, 'eval_samples_per_second': 1457.85, 'eval_steps_per_second': 91.356, 'epoch': 2.0}
{'loss': 1.8715, 'grad_norm': 10.585646629333496, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.7127386331558228, 'eval_accuracy': 0.5175901495162709, 'eval_f1': 0.21179547987641498, 'eval_runtime': 3.1215, 'eval_samples_per_second': 1457.003, 'eval_steps_per_second': 91.303, 'epoch': 3.0}
{'loss': 1.8036, 'grad_norm': 6.347440719604492, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.7277928590774536, 'eval_accuracy': 0.5241864555848724, 'eval_f1': 0.21955675132091962, 'eval_runtime': 3.1233, 'eval_samples_per_second': 1456.174, 'eval_steps_per_second': 91.251, 'epoch': 4.0}
{'loss': 1.7529, 'grad_norm': 11.699670791625977, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.6863489151000977, 'eval_accuracy': 0.5035180299032542, 'eval_f1': 0.20303764363036647, 'eval_runtime': 3.117, 'eval_samples_per_second': 1459.097, 'eval_steps_per_second': 91.434, 'epoch': 5.0}
{'loss': 1.6889, 'grad_norm': 10.4028902053833, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.5628547668457031, 'eval_accuracy': 0.5567282321899736, 'eval_f1': 0.31030074970581634, 'eval_runtime': 3.1276, 'eval_samples_per_second': 1454.137, 'eval_steps_per_second': 91.123, 'epoch': 6.0}
{'loss': 1.6241, 'grad_norm': 8.472448348999023, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.5340728759765625, 'eval_accuracy': 0.5679419525065963, 'eval_f1': 0.3187023616700926, 'eval_runtime': 3.1227, 'eval_samples_per_second': 1456.453, 'eval_steps_per_second': 91.268, 'epoch': 7.0}
{'loss': 1.5455, 'grad_norm': 8.319470405578613, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.4553879499435425, 'eval_accuracy': 0.5844327176781002, 'eval_f1': 0.342931393745502, 'eval_runtime': 3.1181, 'eval_samples_per_second': 1458.596, 'eval_steps_per_second': 91.403, 'epoch': 8.0}
{'train_runtime': 289.0521, 'train_samples_per_second': 1004.884, 'train_steps_per_second': 62.826, 'train_loss': 1.7854627432802175, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 11 17 ... 27 17 27]
Metrics:
F1: 0.3482178487099086 
Accuracy: 0.5882352941176471
Final Report:
                 precision    recall  f1-score   support

    admiration       0.59      0.72      0.65       348
     amusement       0.74      0.86      0.80       186
         anger       0.47      0.46      0.46       131
     annoyance       0.29      0.02      0.04       194
      approval       0.71      0.24      0.36       236
        caring       0.71      0.17      0.28        86
     confusion       0.45      0.21      0.28        97
     curiosity       0.48      0.59      0.53       176
        desire       0.62      0.23      0.34        56
disappointment       0.00      0.00      0.00        88
   disapproval       0.41      0.12      0.19       195
       disgust       0.33      0.17      0.23        76
 embarrassment       0.00      0.00      0.00        23
    excitement       0.67      0.11      0.18        57
          fear       0.52      0.57      0.54        65
     gratitude       0.89      0.90      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.49      0.49      0.49        93
          love       0.68      0.93      0.79       160
   nervousness       0.00      0.00      0.00        12
      optimism       0.56      0.56      0.56       107
         pride       0.00      0.00      0.00         7
   realization       0.00      0.00      0.00        89
        relief       0.00      0.00      0.00         7
       remorse       0.62      0.64      0.63        44
       sadness       0.46      0.49      0.47       102
      surprise       0.45      0.29      0.35        87
       neutral       0.57      0.84      0.68      1606

      accuracy                           0.59      4590
     macro avg       0.42      0.34      0.35      4590
  weighted avg       0.55      0.59      0.53      4590

F1 scores: [0.18680351853967178, 0.20120923145901742, 0.21179547987641498, 0.21955675132091962, 0.20303764363036647, 0.31030074970581634, 0.3187023616700926, 0.342931393745502, 0.3482178487099086]
Accuracies: [0.4980211081794195, 0.5, 0.5175901495162709, 0.5241864555848724, 0.5035180299032542, 0.5567282321899736, 0.5679419525065963, 0.5844327176781002, 0.5882352941176471]
Durations: [39.94757056236267, 76.0788938999176, 112.21991038322449, 148.31595039367676, 184.44320583343506, 220.57310247421265, 256.7424740791321, 292.9114634990692, 296.04044103622437]
Training Losses ( 8 ): [2.0608, 1.9365, 1.8715, 1.8036, 1.7529, 1.6889, 1.6241, 1.5455]
Validation Losses ( 8 ): [1.8265467882156372, 1.9155793190002441, 1.7127386331558228, 1.7277928590774536, 1.6863489151000977, 1.5628547668457031, 1.5340728759765625, 1.4553879499435425]
====  weight_decay :  100.0  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 100.0 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 2.5978, 'grad_norm': 8.749022483825684, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 2.4548535346984863, 'eval_accuracy': 0.40127528583992966, 'eval_f1': 0.05572144427755447, 'eval_runtime': 3.117, 'eval_samples_per_second': 1459.114, 'eval_steps_per_second': 91.435, 'epoch': 1.0}
{'loss': 2.4716, 'grad_norm': 6.20036506652832, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 2.4481005668640137, 'eval_accuracy': 0.3691732629727353, 'eval_f1': 0.02975858150269497, 'eval_runtime': 3.1177, 'eval_samples_per_second': 1458.777, 'eval_steps_per_second': 91.414, 'epoch': 2.0}
{'loss': 2.4141, 'grad_norm': 9.016950607299805, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 2.3767666816711426, 'eval_accuracy': 0.40281442392260336, 'eval_f1': 0.0513564393681915, 'eval_runtime': 3.1215, 'eval_samples_per_second': 1456.973, 'eval_steps_per_second': 91.301, 'epoch': 3.0}
{'loss': 2.3888, 'grad_norm': 6.605321884155273, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 2.3216257095336914, 'eval_accuracy': 0.39050131926121373, 'eval_f1': 0.03619259771721881, 'eval_runtime': 3.1218, 'eval_samples_per_second': 1456.875, 'eval_steps_per_second': 91.295, 'epoch': 4.0}
{'loss': 2.3746, 'grad_norm': 9.726272583007812, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 2.329334020614624, 'eval_accuracy': 0.4118293755496922, 'eval_f1': 0.052881672286561245, 'eval_runtime': 3.1185, 'eval_samples_per_second': 1458.391, 'eval_steps_per_second': 91.39, 'epoch': 5.0}
{'loss': 2.3577, 'grad_norm': 6.565628528594971, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 2.289804697036743, 'eval_accuracy': 0.41798592788038696, 'eval_f1': 0.0568082498367045, 'eval_runtime': 3.1223, 'eval_samples_per_second': 1456.638, 'eval_steps_per_second': 91.28, 'epoch': 6.0}
{'loss': 2.2975, 'grad_norm': 6.188076019287109, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 2.2526445388793945, 'eval_accuracy': 0.4289797713280563, 'eval_f1': 0.0614051253454523, 'eval_runtime': 3.1195, 'eval_samples_per_second': 1457.938, 'eval_steps_per_second': 91.362, 'epoch': 7.0}
{'loss': 2.2418, 'grad_norm': 8.747234344482422, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 2.1901776790618896, 'eval_accuracy': 0.43161829375549693, 'eval_f1': 0.06292820038924125, 'eval_runtime': 3.1217, 'eval_samples_per_second': 1456.895, 'eval_steps_per_second': 91.296, 'epoch': 8.0}
{'train_runtime': 288.8395, 'train_samples_per_second': 1005.624, 'train_steps_per_second': 62.872, 'train_loss': 2.3929935942662444, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [15 27  0 ... 27  0 27]
Metrics:
F1: 0.06295516530868736 
Accuracy: 0.4339869281045752
Final Report:
                 precision    recall  f1-score   support

    admiration       0.33      0.64      0.44       348
     amusement       0.00      0.00      0.00       186
         anger       0.00      0.00      0.00       131
     annoyance       0.00      0.00      0.00       194
      approval       0.00      0.00      0.00       236
        caring       0.00      0.00      0.00        86
     confusion       0.00      0.00      0.00        97
     curiosity       0.00      0.00      0.00       176
        desire       0.00      0.00      0.00        56
disappointment       0.00      0.00      0.00        88
   disapproval       0.00      0.00      0.00       195
       disgust       0.00      0.00      0.00        76
 embarrassment       0.00      0.00      0.00        23
    excitement       0.00      0.00      0.00        57
          fear       0.00      0.00      0.00        65
     gratitude       0.60      0.93      0.73       260
         grief       0.00      0.00      0.00         2
           joy       0.00      0.00      0.00        93
          love       0.00      0.00      0.00       160
   nervousness       0.00      0.00      0.00        12
      optimism       0.00      0.00      0.00       107
         pride       0.00      0.00      0.00         7
   realization       0.00      0.00      0.00        89
        relief       0.00      0.00      0.00         7
       remorse       0.00      0.00      0.00        44
       sadness       0.00      0.00      0.00       102
      surprise       0.00      0.00      0.00        87
       neutral       0.44      0.95      0.60      1606

      accuracy                           0.43      4590
     macro avg       0.05      0.09      0.06      4590
  weighted avg       0.21      0.43      0.28      4590

F1 scores: [0.05572144427755447, 0.02975858150269497, 0.0513564393681915, 0.03619259771721881, 0.052881672286561245, 0.0568082498367045, 0.0614051253454523, 0.06292820038924125, 0.06295516530868736]
Accuracies: [0.40127528583992966, 0.3691732629727353, 0.40281442392260336, 0.39050131926121373, 0.4118293755496922, 0.41798592788038696, 0.4289797713280563, 0.43161829375549693, 0.4339869281045752]
Durations: [40.63497352600098, 76.75151371955872, 112.89684581756592, 148.96841192245483, 185.06589674949646, 221.1824653148651, 257.3037779331207, 293.4316203594208, 296.55613923072815]
Training Losses ( 8 ): [2.5978, 2.4716, 2.4141, 2.3888, 2.3746, 2.3577, 2.2975, 2.2418]
Validation Losses ( 8 ): [2.4548535346984863, 2.4481005668640137, 2.3767666816711426, 2.3216257095336914, 2.329334020614624, 2.289804697036743, 2.2526445388793945, 2.1901776790618896]
Graphs saved to disk
