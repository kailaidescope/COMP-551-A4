Starting BERT epoch experiments script
Train method: head+1
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.2 
Warmup steps: 500
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])  - Requires grad: False
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])  - Requires grad: False
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.pooler.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: classifier.weight  - Size: torch.Size([28, 768])  - Requires grad: True
Name: classifier.bias  - Size: torch.Size([28])  - Requires grad: True
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8478, 'grad_norm': 8.1551513671875, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6096770763397217, 'eval_accuracy': 0.5389182058047494, 'eval_f1': 0.32331561087696664, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.64      0.80      0.71       208\n         anger       0.00      0.00      0.00       109\n     annoyance       0.18      0.26      0.21       164\n      approval       0.40      0.16      0.23       258\n        caring       0.56      0.21      0.30        96\n     confusion       0.26      0.27      0.27       102\n     curiosity       0.40      0.68      0.50       164\n        desire       0.69      0.48      0.57        52\ndisappointment       0.00      0.00      0.00        91\n   disapproval       0.32      0.38      0.35       212\n       disgust       0.57      0.07      0.12        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.33      0.02      0.04        52\n          fear       0.79      0.33      0.46        58\n     gratitude       0.92      0.89      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.42      0.53      0.47       106\n          love       0.71      0.66      0.68       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.89      0.29      0.43       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.51      0.88      0.64        40\n       sadness       0.41      0.49      0.45        84\n      surprise       0.39      0.46      0.42        95\n       neutral       0.58      0.69      0.63      1592\n\n      accuracy                           0.54      4548\n     macro avg       0.38      0.33      0.32      4548\n  weighted avg       0.51      0.54      0.51      4548\n', 'eval_runtime': 3.1883, 'eval_samples_per_second': 1426.472, 'eval_steps_per_second': 89.39, 'epoch': 1.0}
{'loss': 1.5992, 'grad_norm': 4.5680460929870605, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5014300346374512, 'eval_accuracy': 0.5657431838170625, 'eval_f1': 0.36166847501396887, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.71      0.67       326\n     amusement       0.68      0.79      0.73       208\n         anger       0.39      0.57      0.46       109\n     annoyance       0.31      0.02      0.05       164\n      approval       0.54      0.13      0.21       258\n        caring       0.57      0.08      0.15        96\n     confusion       0.39      0.12      0.18       102\n     curiosity       0.40      0.66      0.50       164\n        desire       0.67      0.62      0.64        52\ndisappointment       0.18      0.12      0.15        91\n   disapproval       0.35      0.28      0.31       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.10      0.17        20\n    excitement       0.67      0.04      0.07        52\n          fear       0.62      0.45      0.52        58\n     gratitude       0.95      0.87      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.41      0.63      0.50       106\n          love       0.65      0.91      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.55      0.55      0.55       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.72      0.67        40\n       sadness       0.49      0.50      0.50        84\n      surprise       0.52      0.34      0.41        95\n       neutral       0.57      0.74      0.64      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.43      0.37      0.36      4548\n  weighted avg       0.54      0.57      0.53      4548\n', 'eval_runtime': 3.1892, 'eval_samples_per_second': 1426.055, 'eval_steps_per_second': 89.364, 'epoch': 2.0}
{'loss': 1.5198, 'grad_norm': 4.995558261871338, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4456453323364258, 'eval_accuracy': 0.5697009674582234, 'eval_f1': 0.35178404491035425, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.77      0.69       326\n     amusement       0.75      0.71      0.73       208\n         anger       0.28      0.56      0.37       109\n     annoyance       0.20      0.04      0.06       164\n      approval       0.57      0.19      0.29       258\n        caring       0.37      0.27      0.31        96\n     confusion       0.73      0.11      0.19       102\n     curiosity       0.40      0.32      0.35       164\n        desire       0.83      0.38      0.53        52\ndisappointment       1.00      0.01      0.02        91\n   disapproval       0.41      0.21      0.28       212\n       disgust       0.39      0.44      0.41        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.38      0.27      0.31        52\n          fear       0.49      0.59      0.54        58\n     gratitude       0.88      0.90      0.89       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.46      0.53       106\n          love       0.66      0.90      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.70      0.47      0.56       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.25      0.36        40\n       sadness       0.45      0.45      0.45        84\n      surprise       0.59      0.38      0.46        95\n       neutral       0.56      0.80      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.47      0.34      0.35      4548\n  weighted avg       0.56      0.57      0.53      4548\n', 'eval_runtime': 3.199, 'eval_samples_per_second': 1421.684, 'eval_steps_per_second': 89.09, 'epoch': 3.0}
{'loss': 1.461, 'grad_norm': 3.929426670074463, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4337005615234375, 'eval_accuracy': 0.5817941952506597, 'eval_f1': 0.40908971806215005, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.67      0.68       326\n     amusement       0.75      0.75      0.75       208\n         anger       0.40      0.46      0.43       109\n     annoyance       0.34      0.10      0.16       164\n      approval       0.50      0.19      0.28       258\n        caring       0.56      0.09      0.16        96\n     confusion       0.57      0.17      0.26       102\n     curiosity       0.44      0.57      0.50       164\n        desire       0.76      0.54      0.63        52\ndisappointment       0.21      0.09      0.12        91\n   disapproval       0.43      0.17      0.25       212\n       disgust       0.31      0.52      0.39        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.28      0.27      0.27        52\n          fear       0.64      0.47      0.54        58\n     gratitude       0.96      0.88      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.48      0.55       106\n          love       0.65      0.92      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.62      0.54      0.57       119\n         pride       1.00      0.44      0.62         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.55      0.55      0.55        40\n       sadness       0.33      0.63      0.43        84\n      surprise       0.47      0.53      0.50        95\n       neutral       0.58      0.78      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.40      0.41      4548\n  weighted avg       0.56      0.58      0.55      4548\n', 'eval_runtime': 3.2094, 'eval_samples_per_second': 1417.099, 'eval_steps_per_second': 88.802, 'epoch': 4.0}
{'loss': 1.4047, 'grad_norm': 8.136186599731445, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4147231578826904, 'eval_accuracy': 0.5813544415127528, 'eval_f1': 0.37388925704584, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.49      0.85      0.62       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.37      0.50      0.42       109\n     annoyance       0.43      0.07      0.12       164\n      approval       0.59      0.14      0.23       258\n        caring       0.55      0.29      0.38        96\n     confusion       0.52      0.22      0.31       102\n     curiosity       0.49      0.38      0.43       164\n        desire       0.86      0.37      0.51        52\ndisappointment       0.40      0.02      0.04        91\n   disapproval       0.47      0.03      0.06       212\n       disgust       0.43      0.38      0.40        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.58      0.13      0.22        52\n          fear       0.56      0.59      0.57        58\n     gratitude       0.92      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.71      0.30      0.42       106\n          love       0.75      0.76      0.75       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.65      0.53      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.60      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.65      0.63        40\n       sadness       0.49      0.56      0.53        84\n      surprise       0.55      0.51      0.52        95\n       neutral       0.56      0.81      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.50      0.36      0.37      4548\n  weighted avg       0.58      0.58      0.53      4548\n', 'eval_runtime': 3.2132, 'eval_samples_per_second': 1415.414, 'eval_steps_per_second': 88.697, 'epoch': 5.0}
{'loss': 1.3416, 'grad_norm': 7.752401828765869, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.380066990852356, 'eval_accuracy': 0.5828935795954265, 'eval_f1': 0.4231322288104632, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.79      0.69       326\n     amusement       0.64      0.87      0.74       208\n         anger       0.34      0.61      0.44       109\n     annoyance       0.28      0.07      0.12       164\n      approval       0.49      0.19      0.27       258\n        caring       0.45      0.62      0.52        96\n     confusion       0.40      0.30      0.34       102\n     curiosity       0.41      0.62      0.49       164\n        desire       0.64      0.48      0.55        52\ndisappointment       0.24      0.09      0.13        91\n   disapproval       0.49      0.25      0.33       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.50      0.50        20\n    excitement       0.30      0.40      0.34        52\n          fear       0.72      0.45      0.55        58\n     gratitude       0.95      0.88      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.50      0.53       106\n          love       0.73      0.88      0.80       173\n   nervousness       0.50      0.12      0.20         8\n      optimism       0.66      0.45      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.57      0.05      0.10        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.75      0.67        40\n       sadness       0.47      0.57      0.51        84\n      surprise       0.50      0.56      0.53        95\n       neutral       0.61      0.69      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.43      0.42      4548\n  weighted avg       0.57      0.58      0.56      4548\n', 'eval_runtime': 3.2229, 'eval_samples_per_second': 1411.173, 'eval_steps_per_second': 88.431, 'epoch': 6.0}
{'loss': 1.2591, 'grad_norm': 5.878385066986084, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3341237306594849, 'eval_accuracy': 0.6000439753737907, 'eval_f1': 0.43549554622130116, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.82      0.68       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.45      0.47      0.46       109\n     annoyance       0.31      0.17      0.22       164\n      approval       0.40      0.21      0.28       258\n        caring       0.55      0.36      0.44        96\n     confusion       0.41      0.27      0.33       102\n     curiosity       0.48      0.35      0.40       164\n        desire       0.64      0.56      0.60        52\ndisappointment       0.28      0.12      0.17        91\n   disapproval       0.46      0.25      0.33       212\n       disgust       0.46      0.43      0.44        61\n embarrassment       0.56      0.50      0.53        20\n    excitement       0.47      0.29      0.36        52\n          fear       0.67      0.62      0.64        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.55      0.56       106\n          love       0.72      0.90      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.58      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.50      0.12      0.20        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.50      0.61      0.55        84\n      surprise       0.56      0.59      0.57        95\n       neutral       0.61      0.75      0.67      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.47      0.43      0.44      4548\n  weighted avg       0.57      0.60      0.57      4548\n', 'eval_runtime': 3.2215, 'eval_samples_per_second': 1411.754, 'eval_steps_per_second': 88.467, 'epoch': 7.0}
{'loss': 1.1685, 'grad_norm': 6.102255821228027, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3234590291976929, 'eval_accuracy': 0.6051011433597185, 'eval_f1': 0.4590791199277396, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.79      0.72       326\n     amusement       0.69      0.85      0.76       208\n         anger       0.41      0.51      0.45       109\n     annoyance       0.31      0.16      0.21       164\n      approval       0.47      0.22      0.30       258\n        caring       0.57      0.45      0.50        96\n     confusion       0.42      0.29      0.34       102\n     curiosity       0.47      0.50      0.49       164\n        desire       0.61      0.48      0.54        52\ndisappointment       0.32      0.19      0.24        91\n   disapproval       0.46      0.29      0.35       212\n       disgust       0.45      0.43      0.44        61\n embarrassment       0.60      0.45      0.51        20\n    excitement       0.38      0.35      0.36        52\n          fear       0.65      0.55      0.60        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.54      0.58       106\n          love       0.70      0.90      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.59      0.61       119\n         pride       1.00      0.33      0.50         9\n   realization       0.39      0.15      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.68      0.66        40\n       sadness       0.47      0.61      0.53        84\n      surprise       0.56      0.55      0.55        95\n       neutral       0.62      0.74      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.45      0.46      4548\n  weighted avg       0.58      0.61      0.58      4548\n', 'eval_runtime': 3.2291, 'eval_samples_per_second': 1408.444, 'eval_steps_per_second': 88.26, 'epoch': 8.0}
{'train_runtime': 298.5467, 'train_samples_per_second': 972.926, 'train_steps_per_second': 60.828, 'train_loss': 1.4502056239460008, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 20 ... 27  0 27]
Metrics:
F1: 0.479313159067138 
Accuracy: 0.6137254901960785
Results: {'f1': [0.32331561087696664, 0.36166847501396887, 0.35178404491035425, 0.40908971806215005, 0.37388925704584, 0.4231322288104632, 0.43549554622130116, 0.4590791199277396, 0.479313159067138], 'accuracy': [0.5389182058047494, 0.5657431838170625, 0.5697009674582234, 0.5817941952506597, 0.5813544415127528, 0.5828935795954265, 0.6000439753737907, 0.6051011433597185, 0.6137254901960785], 'duration': [40.072882890701294, 77.11294150352478, 114.28286623954773, 151.55595993995667, 188.8852858543396, 226.2690885066986, 263.6437931060791, 301.0447974205017, 304.27831959724426], 'reports': ['                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.64      0.80      0.71       208\n         anger       0.00      0.00      0.00       109\n     annoyance       0.18      0.26      0.21       164\n      approval       0.40      0.16      0.23       258\n        caring       0.56      0.21      0.30        96\n     confusion       0.26      0.27      0.27       102\n     curiosity       0.40      0.68      0.50       164\n        desire       0.69      0.48      0.57        52\ndisappointment       0.00      0.00      0.00        91\n   disapproval       0.32      0.38      0.35       212\n       disgust       0.57      0.07      0.12        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.33      0.02      0.04        52\n          fear       0.79      0.33      0.46        58\n     gratitude       0.92      0.89      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.42      0.53      0.47       106\n          love       0.71      0.66      0.68       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.89      0.29      0.43       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.51      0.88      0.64        40\n       sadness       0.41      0.49      0.45        84\n      surprise       0.39      0.46      0.42        95\n       neutral       0.58      0.69      0.63      1592\n\n      accuracy                           0.54      4548\n     macro avg       0.38      0.33      0.32      4548\n  weighted avg       0.51      0.54      0.51      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.64      0.71      0.67       326\n     amusement       0.68      0.79      0.73       208\n         anger       0.39      0.57      0.46       109\n     annoyance       0.31      0.02      0.05       164\n      approval       0.54      0.13      0.21       258\n        caring       0.57      0.08      0.15        96\n     confusion       0.39      0.12      0.18       102\n     curiosity       0.40      0.66      0.50       164\n        desire       0.67      0.62      0.64        52\ndisappointment       0.18      0.12      0.15        91\n   disapproval       0.35      0.28      0.31       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.10      0.17        20\n    excitement       0.67      0.04      0.07        52\n          fear       0.62      0.45      0.52        58\n     gratitude       0.95      0.87      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.41      0.63      0.50       106\n          love       0.65      0.91      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.55      0.55      0.55       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.72      0.67        40\n       sadness       0.49      0.50      0.50        84\n      surprise       0.52      0.34      0.41        95\n       neutral       0.57      0.74      0.64      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.43      0.37      0.36      4548\n  weighted avg       0.54      0.57      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.62      0.77      0.69       326\n     amusement       0.75      0.71      0.73       208\n         anger       0.28      0.56      0.37       109\n     annoyance       0.20      0.04      0.06       164\n      approval       0.57      0.19      0.29       258\n        caring       0.37      0.27      0.31        96\n     confusion       0.73      0.11      0.19       102\n     curiosity       0.40      0.32      0.35       164\n        desire       0.83      0.38      0.53        52\ndisappointment       1.00      0.01      0.02        91\n   disapproval       0.41      0.21      0.28       212\n       disgust       0.39      0.44      0.41        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.38      0.27      0.31        52\n          fear       0.49      0.59      0.54        58\n     gratitude       0.88      0.90      0.89       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.46      0.53       106\n          love       0.66      0.90      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.70      0.47      0.56       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.25      0.36        40\n       sadness       0.45      0.45      0.45        84\n      surprise       0.59      0.38      0.46        95\n       neutral       0.56      0.80      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.47      0.34      0.35      4548\n  weighted avg       0.56      0.57      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.68      0.67      0.68       326\n     amusement       0.75      0.75      0.75       208\n         anger       0.40      0.46      0.43       109\n     annoyance       0.34      0.10      0.16       164\n      approval       0.50      0.19      0.28       258\n        caring       0.56      0.09      0.16        96\n     confusion       0.57      0.17      0.26       102\n     curiosity       0.44      0.57      0.50       164\n        desire       0.76      0.54      0.63        52\ndisappointment       0.21      0.09      0.12        91\n   disapproval       0.43      0.17      0.25       212\n       disgust       0.31      0.52      0.39        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.28      0.27      0.27        52\n          fear       0.64      0.47      0.54        58\n     gratitude       0.96      0.88      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.48      0.55       106\n          love       0.65      0.92      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.62      0.54      0.57       119\n         pride       1.00      0.44      0.62         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.55      0.55      0.55        40\n       sadness       0.33      0.63      0.43        84\n      surprise       0.47      0.53      0.50        95\n       neutral       0.58      0.78      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.40      0.41      4548\n  weighted avg       0.56      0.58      0.55      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.49      0.85      0.62       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.37      0.50      0.42       109\n     annoyance       0.43      0.07      0.12       164\n      approval       0.59      0.14      0.23       258\n        caring       0.55      0.29      0.38        96\n     confusion       0.52      0.22      0.31       102\n     curiosity       0.49      0.38      0.43       164\n        desire       0.86      0.37      0.51        52\ndisappointment       0.40      0.02      0.04        91\n   disapproval       0.47      0.03      0.06       212\n       disgust       0.43      0.38      0.40        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.58      0.13      0.22        52\n          fear       0.56      0.59      0.57        58\n     gratitude       0.92      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.71      0.30      0.42       106\n          love       0.75      0.76      0.75       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.65      0.53      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.60      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.65      0.63        40\n       sadness       0.49      0.56      0.53        84\n      surprise       0.55      0.51      0.52        95\n       neutral       0.56      0.81      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.50      0.36      0.37      4548\n  weighted avg       0.58      0.58      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.62      0.79      0.69       326\n     amusement       0.64      0.87      0.74       208\n         anger       0.34      0.61      0.44       109\n     annoyance       0.28      0.07      0.12       164\n      approval       0.49      0.19      0.27       258\n        caring       0.45      0.62      0.52        96\n     confusion       0.40      0.30      0.34       102\n     curiosity       0.41      0.62      0.49       164\n        desire       0.64      0.48      0.55        52\ndisappointment       0.24      0.09      0.13        91\n   disapproval       0.49      0.25      0.33       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.50      0.50        20\n    excitement       0.30      0.40      0.34        52\n          fear       0.72      0.45      0.55        58\n     gratitude       0.95      0.88      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.50      0.53       106\n          love       0.73      0.88      0.80       173\n   nervousness       0.50      0.12      0.20         8\n      optimism       0.66      0.45      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.57      0.05      0.10        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.75      0.67        40\n       sadness       0.47      0.57      0.51        84\n      surprise       0.50      0.56      0.53        95\n       neutral       0.61      0.69      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.43      0.42      4548\n  weighted avg       0.57      0.58      0.56      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.59      0.82      0.68       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.45      0.47      0.46       109\n     annoyance       0.31      0.17      0.22       164\n      approval       0.40      0.21      0.28       258\n        caring       0.55      0.36      0.44        96\n     confusion       0.41      0.27      0.33       102\n     curiosity       0.48      0.35      0.40       164\n        desire       0.64      0.56      0.60        52\ndisappointment       0.28      0.12      0.17        91\n   disapproval       0.46      0.25      0.33       212\n       disgust       0.46      0.43      0.44        61\n embarrassment       0.56      0.50      0.53        20\n    excitement       0.47      0.29      0.36        52\n          fear       0.67      0.62      0.64        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.55      0.56       106\n          love       0.72      0.90      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.58      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.50      0.12      0.20        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.50      0.61      0.55        84\n      surprise       0.56      0.59      0.57        95\n       neutral       0.61      0.75      0.67      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.47      0.43      0.44      4548\n  weighted avg       0.57      0.60      0.57      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.67      0.79      0.72       326\n     amusement       0.69      0.85      0.76       208\n         anger       0.41      0.51      0.45       109\n     annoyance       0.31      0.16      0.21       164\n      approval       0.47      0.22      0.30       258\n        caring       0.57      0.45      0.50        96\n     confusion       0.42      0.29      0.34       102\n     curiosity       0.47      0.50      0.49       164\n        desire       0.61      0.48      0.54        52\ndisappointment       0.32      0.19      0.24        91\n   disapproval       0.46      0.29      0.35       212\n       disgust       0.45      0.43      0.44        61\n embarrassment       0.60      0.45      0.51        20\n    excitement       0.38      0.35      0.36        52\n          fear       0.65      0.55      0.60        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.54      0.58       106\n          love       0.70      0.90      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.59      0.61       119\n         pride       1.00      0.33      0.50         9\n   realization       0.39      0.15      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.68      0.66        40\n       sadness       0.47      0.61      0.53        84\n      surprise       0.56      0.55      0.55        95\n       neutral       0.62      0.74      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.45      0.46      4548\n  weighted avg       0.58      0.61      0.58      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.64      0.72      0.68       348\n     amusement       0.76      0.87      0.81       186\n         anger       0.49      0.43      0.46       131\n     annoyance       0.34      0.19      0.24       194\n      approval       0.56      0.32      0.40       236\n        caring       0.55      0.42      0.47        86\n     confusion       0.43      0.33      0.37        97\n     curiosity       0.49      0.55      0.52       176\n        desire       0.66      0.41      0.51        56\ndisappointment       0.42      0.22      0.29        88\n   disapproval       0.42      0.30      0.35       195\n       disgust       0.53      0.54      0.53        76\n embarrassment       0.47      0.39      0.43        23\n    excitement       0.50      0.47      0.49        57\n          fear       0.67      0.74      0.70        65\n     gratitude       0.90      0.89      0.90       260\n         grief       0.00      0.00      0.00         2\n           joy       0.56      0.62      0.59        93\n          love       0.74      0.86      0.80       160\n   nervousness       0.57      0.33      0.42        12\n      optimism       0.61      0.61      0.61       107\n         pride       0.50      0.29      0.36         7\n   realization       0.50      0.11      0.18        89\n        relief       0.00      0.00      0.00         7\n       remorse       0.55      0.75      0.63        44\n       sadness       0.59      0.54      0.56       102\n      surprise       0.47      0.40      0.43        87\n       neutral       0.63      0.76      0.69      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.52      0.47      0.48      4590\n  weighted avg       0.60      0.61      0.60      4590\n'], 'final': {'f1': 0.479313159067138, 'accuracy': 0.6137254901960785, 'duration': 304.2815270423889, 'report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.72      0.68       348\n     amusement       0.76      0.87      0.81       186\n         anger       0.49      0.43      0.46       131\n     annoyance       0.34      0.19      0.24       194\n      approval       0.56      0.32      0.40       236\n        caring       0.55      0.42      0.47        86\n     confusion       0.43      0.33      0.37        97\n     curiosity       0.49      0.55      0.52       176\n        desire       0.66      0.41      0.51        56\ndisappointment       0.42      0.22      0.29        88\n   disapproval       0.42      0.30      0.35       195\n       disgust       0.53      0.54      0.53        76\n embarrassment       0.47      0.39      0.43        23\n    excitement       0.50      0.47      0.49        57\n          fear       0.67      0.74      0.70        65\n     gratitude       0.90      0.89      0.90       260\n         grief       0.00      0.00      0.00         2\n           joy       0.56      0.62      0.59        93\n          love       0.74      0.86      0.80       160\n   nervousness       0.57      0.33      0.42        12\n      optimism       0.61      0.61      0.61       107\n         pride       0.50      0.29      0.36         7\n   realization       0.50      0.11      0.18        89\n        relief       0.00      0.00      0.00         7\n       remorse       0.55      0.75      0.63        44\n       sadness       0.59      0.54      0.56       102\n      surprise       0.47      0.40      0.43        87\n       neutral       0.63      0.76      0.69      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.52      0.47      0.48      4590\n  weighted avg       0.60      0.61      0.60      4590\n'}}
Final Report:
                 precision    recall  f1-score   support

    admiration       0.64      0.72      0.68       348
     amusement       0.76      0.87      0.81       186
         anger       0.49      0.43      0.46       131
     annoyance       0.34      0.19      0.24       194
      approval       0.56      0.32      0.40       236
        caring       0.55      0.42      0.47        86
     confusion       0.43      0.33      0.37        97
     curiosity       0.49      0.55      0.52       176
        desire       0.66      0.41      0.51        56
disappointment       0.42      0.22      0.29        88
   disapproval       0.42      0.30      0.35       195
       disgust       0.53      0.54      0.53        76
 embarrassment       0.47      0.39      0.43        23
    excitement       0.50      0.47      0.49        57
          fear       0.67      0.74      0.70        65
     gratitude       0.90      0.89      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.56      0.62      0.59        93
          love       0.74      0.86      0.80       160
   nervousness       0.57      0.33      0.42        12
      optimism       0.61      0.61      0.61       107
         pride       0.50      0.29      0.36         7
   realization       0.50      0.11      0.18        89
        relief       0.00      0.00      0.00         7
       remorse       0.55      0.75      0.63        44
       sadness       0.59      0.54      0.56       102
      surprise       0.47      0.40      0.43        87
       neutral       0.63      0.76      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.52      0.47      0.48      4590
  weighted avg       0.60      0.61      0.60      4590

F1 scores: [0.32331561087696664, 0.36166847501396887, 0.35178404491035425, 0.40908971806215005, 0.37388925704584, 0.4231322288104632, 0.43549554622130116, 0.4590791199277396, 0.479313159067138]
Accuracies: [0.5389182058047494, 0.5657431838170625, 0.5697009674582234, 0.5817941952506597, 0.5813544415127528, 0.5828935795954265, 0.6000439753737907, 0.6051011433597185, 0.6137254901960785]
Durations: [40.072882890701294, 77.11294150352478, 114.28286623954773, 151.55595993995667, 188.8852858543396, 226.2690885066986, 263.6437931060791, 301.0447974205017, 304.27831959724426]
log_history: [{'loss': 1.8478, 'grad_norm': 8.1551513671875, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0, 'step': 2270}, {'eval_loss': 1.6096770763397217, 'eval_accuracy': 0.5389182058047494, 'eval_f1': 0.32331561087696664, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.58      0.76      0.66       326\n     amusement       0.64      0.80      0.71       208\n         anger       0.00      0.00      0.00       109\n     annoyance       0.18      0.26      0.21       164\n      approval       0.40      0.16      0.23       258\n        caring       0.56      0.21      0.30        96\n     confusion       0.26      0.27      0.27       102\n     curiosity       0.40      0.68      0.50       164\n        desire       0.69      0.48      0.57        52\ndisappointment       0.00      0.00      0.00        91\n   disapproval       0.32      0.38      0.35       212\n       disgust       0.57      0.07      0.12        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.33      0.02      0.04        52\n          fear       0.79      0.33      0.46        58\n     gratitude       0.92      0.89      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.42      0.53      0.47       106\n          love       0.71      0.66      0.68       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.89      0.29      0.43       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.51      0.88      0.64        40\n       sadness       0.41      0.49      0.45        84\n      surprise       0.39      0.46      0.42        95\n       neutral       0.58      0.69      0.63      1592\n\n      accuracy                           0.54      4548\n     macro avg       0.38      0.33      0.32      4548\n  weighted avg       0.51      0.54      0.51      4548\n', 'eval_runtime': 3.1883, 'eval_samples_per_second': 1426.472, 'eval_steps_per_second': 89.39, 'epoch': 1.0, 'step': 2270}, {'loss': 1.5992, 'grad_norm': 4.5680460929870605, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0, 'step': 4540}, {'eval_loss': 1.5014300346374512, 'eval_accuracy': 0.5657431838170625, 'eval_f1': 0.36166847501396887, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.71      0.67       326\n     amusement       0.68      0.79      0.73       208\n         anger       0.39      0.57      0.46       109\n     annoyance       0.31      0.02      0.05       164\n      approval       0.54      0.13      0.21       258\n        caring       0.57      0.08      0.15        96\n     confusion       0.39      0.12      0.18       102\n     curiosity       0.40      0.66      0.50       164\n        desire       0.67      0.62      0.64        52\ndisappointment       0.18      0.12      0.15        91\n   disapproval       0.35      0.28      0.31       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.10      0.17        20\n    excitement       0.67      0.04      0.07        52\n          fear       0.62      0.45      0.52        58\n     gratitude       0.95      0.87      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.41      0.63      0.50       106\n          love       0.65      0.91      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.55      0.55      0.55       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.72      0.67        40\n       sadness       0.49      0.50      0.50        84\n      surprise       0.52      0.34      0.41        95\n       neutral       0.57      0.74      0.64      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.43      0.37      0.36      4548\n  weighted avg       0.54      0.57      0.53      4548\n', 'eval_runtime': 3.1892, 'eval_samples_per_second': 1426.055, 'eval_steps_per_second': 89.364, 'epoch': 2.0, 'step': 4540}, {'loss': 1.5198, 'grad_norm': 4.995558261871338, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0, 'step': 6810}, {'eval_loss': 1.4456453323364258, 'eval_accuracy': 0.5697009674582234, 'eval_f1': 0.35178404491035425, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.77      0.69       326\n     amusement       0.75      0.71      0.73       208\n         anger       0.28      0.56      0.37       109\n     annoyance       0.20      0.04      0.06       164\n      approval       0.57      0.19      0.29       258\n        caring       0.37      0.27      0.31        96\n     confusion       0.73      0.11      0.19       102\n     curiosity       0.40      0.32      0.35       164\n        desire       0.83      0.38      0.53        52\ndisappointment       1.00      0.01      0.02        91\n   disapproval       0.41      0.21      0.28       212\n       disgust       0.39      0.44      0.41        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.38      0.27      0.31        52\n          fear       0.49      0.59      0.54        58\n     gratitude       0.88      0.90      0.89       261\n         grief       0.00      0.00      0.00         6\n           joy       0.61      0.46      0.53       106\n          love       0.66      0.90      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.70      0.47      0.56       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.25      0.36        40\n       sadness       0.45      0.45      0.45        84\n      surprise       0.59      0.38      0.46        95\n       neutral       0.56      0.80      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.47      0.34      0.35      4548\n  weighted avg       0.56      0.57      0.53      4548\n', 'eval_runtime': 3.199, 'eval_samples_per_second': 1421.684, 'eval_steps_per_second': 89.09, 'epoch': 3.0, 'step': 6810}, {'loss': 1.461, 'grad_norm': 3.929426670074463, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0, 'step': 9080}, {'eval_loss': 1.4337005615234375, 'eval_accuracy': 0.5817941952506597, 'eval_f1': 0.40908971806215005, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.67      0.68       326\n     amusement       0.75      0.75      0.75       208\n         anger       0.40      0.46      0.43       109\n     annoyance       0.34      0.10      0.16       164\n      approval       0.50      0.19      0.28       258\n        caring       0.56      0.09      0.16        96\n     confusion       0.57      0.17      0.26       102\n     curiosity       0.44      0.57      0.50       164\n        desire       0.76      0.54      0.63        52\ndisappointment       0.21      0.09      0.12        91\n   disapproval       0.43      0.17      0.25       212\n       disgust       0.31      0.52      0.39        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.28      0.27      0.27        52\n          fear       0.64      0.47      0.54        58\n     gratitude       0.96      0.88      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.48      0.55       106\n          love       0.65      0.92      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.62      0.54      0.57       119\n         pride       1.00      0.44      0.62         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.55      0.55      0.55        40\n       sadness       0.33      0.63      0.43        84\n      surprise       0.47      0.53      0.50        95\n       neutral       0.58      0.78      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.40      0.41      4548\n  weighted avg       0.56      0.58      0.55      4548\n', 'eval_runtime': 3.2094, 'eval_samples_per_second': 1417.099, 'eval_steps_per_second': 88.802, 'epoch': 4.0, 'step': 9080}, {'loss': 1.4047, 'grad_norm': 8.136186599731445, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0, 'step': 11350}, {'eval_loss': 1.4147231578826904, 'eval_accuracy': 0.5813544415127528, 'eval_f1': 0.37388925704584, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.49      0.85      0.62       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.37      0.50      0.42       109\n     annoyance       0.43      0.07      0.12       164\n      approval       0.59      0.14      0.23       258\n        caring       0.55      0.29      0.38        96\n     confusion       0.52      0.22      0.31       102\n     curiosity       0.49      0.38      0.43       164\n        desire       0.86      0.37      0.51        52\ndisappointment       0.40      0.02      0.04        91\n   disapproval       0.47      0.03      0.06       212\n       disgust       0.43      0.38      0.40        61\n embarrassment       0.50      0.05      0.09        20\n    excitement       0.58      0.13      0.22        52\n          fear       0.56      0.59      0.57        58\n     gratitude       0.92      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.71      0.30      0.42       106\n          love       0.75      0.76      0.75       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.65      0.53      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.60      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.65      0.63        40\n       sadness       0.49      0.56      0.53        84\n      surprise       0.55      0.51      0.52        95\n       neutral       0.56      0.81      0.67      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.50      0.36      0.37      4548\n  weighted avg       0.58      0.58      0.53      4548\n', 'eval_runtime': 3.2132, 'eval_samples_per_second': 1415.414, 'eval_steps_per_second': 88.697, 'epoch': 5.0, 'step': 11350}, {'loss': 1.3416, 'grad_norm': 7.752401828765869, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0, 'step': 13620}, {'eval_loss': 1.380066990852356, 'eval_accuracy': 0.5828935795954265, 'eval_f1': 0.4231322288104632, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.79      0.69       326\n     amusement       0.64      0.87      0.74       208\n         anger       0.34      0.61      0.44       109\n     annoyance       0.28      0.07      0.12       164\n      approval       0.49      0.19      0.27       258\n        caring       0.45      0.62      0.52        96\n     confusion       0.40      0.30      0.34       102\n     curiosity       0.41      0.62      0.49       164\n        desire       0.64      0.48      0.55        52\ndisappointment       0.24      0.09      0.13        91\n   disapproval       0.49      0.25      0.33       212\n       disgust       0.45      0.34      0.39        61\n embarrassment       0.50      0.50      0.50        20\n    excitement       0.30      0.40      0.34        52\n          fear       0.72      0.45      0.55        58\n     gratitude       0.95      0.88      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.50      0.53       106\n          love       0.73      0.88      0.80       173\n   nervousness       0.50      0.12      0.20         8\n      optimism       0.66      0.45      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.57      0.05      0.10        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.75      0.67        40\n       sadness       0.47      0.57      0.51        84\n      surprise       0.50      0.56      0.53        95\n       neutral       0.61      0.69      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.47      0.43      0.42      4548\n  weighted avg       0.57      0.58      0.56      4548\n', 'eval_runtime': 3.2229, 'eval_samples_per_second': 1411.173, 'eval_steps_per_second': 88.431, 'epoch': 6.0, 'step': 13620}, {'loss': 1.2591, 'grad_norm': 5.878385066986084, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0, 'step': 15890}, {'eval_loss': 1.3341237306594849, 'eval_accuracy': 0.6000439753737907, 'eval_f1': 0.43549554622130116, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.82      0.68       326\n     amusement       0.70      0.85      0.77       208\n         anger       0.45      0.47      0.46       109\n     annoyance       0.31      0.17      0.22       164\n      approval       0.40      0.21      0.28       258\n        caring       0.55      0.36      0.44        96\n     confusion       0.41      0.27      0.33       102\n     curiosity       0.48      0.35      0.40       164\n        desire       0.64      0.56      0.60        52\ndisappointment       0.28      0.12      0.17        91\n   disapproval       0.46      0.25      0.33       212\n       disgust       0.46      0.43      0.44        61\n embarrassment       0.56      0.50      0.53        20\n    excitement       0.47      0.29      0.36        52\n          fear       0.67      0.62      0.64        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.57      0.55      0.56       106\n          love       0.72      0.90      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.58      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.50      0.12      0.20        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.72      0.67        40\n       sadness       0.50      0.61      0.55        84\n      surprise       0.56      0.59      0.57        95\n       neutral       0.61      0.75      0.67      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.47      0.43      0.44      4548\n  weighted avg       0.57      0.60      0.57      4548\n', 'eval_runtime': 3.2215, 'eval_samples_per_second': 1411.754, 'eval_steps_per_second': 88.467, 'epoch': 7.0, 'step': 15890}, {'loss': 1.1685, 'grad_norm': 6.102255821228027, 'learning_rate': 0.0, 'epoch': 8.0, 'step': 18160}, {'eval_loss': 1.3234590291976929, 'eval_accuracy': 0.6051011433597185, 'eval_f1': 0.4590791199277396, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.79      0.72       326\n     amusement       0.69      0.85      0.76       208\n         anger       0.41      0.51      0.45       109\n     annoyance       0.31      0.16      0.21       164\n      approval       0.47      0.22      0.30       258\n        caring       0.57      0.45      0.50        96\n     confusion       0.42      0.29      0.34       102\n     curiosity       0.47      0.50      0.49       164\n        desire       0.61      0.48      0.54        52\ndisappointment       0.32      0.19      0.24        91\n   disapproval       0.46      0.29      0.35       212\n       disgust       0.45      0.43      0.44        61\n embarrassment       0.60      0.45      0.51        20\n    excitement       0.38      0.35      0.36        52\n          fear       0.65      0.55      0.60        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.54      0.58       106\n          love       0.70      0.90      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.64      0.59      0.61       119\n         pride       1.00      0.33      0.50         9\n   realization       0.39      0.15      0.22        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.68      0.66        40\n       sadness       0.47      0.61      0.53        84\n      surprise       0.56      0.55      0.55        95\n       neutral       0.62      0.74      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.45      0.46      4548\n  weighted avg       0.58      0.61      0.58      4548\n', 'eval_runtime': 3.2291, 'eval_samples_per_second': 1408.444, 'eval_steps_per_second': 88.26, 'epoch': 8.0, 'step': 18160}, {'train_runtime': 298.5467, 'train_samples_per_second': 972.926, 'train_steps_per_second': 60.828, 'total_flos': 5115357451308672.0, 'train_loss': 1.4502056239460008, 'epoch': 8.0, 'step': 18160}]
Training Losses ( 8 ): [1.8478, 1.5992, 1.5198, 1.461, 1.4047, 1.3416, 1.2591, 1.1685]
Validation Losses ( 8 ): [1.6096770763397217, 1.5014300346374512, 1.4456453323364258, 1.4337005615234375, 1.4147231578826904, 1.380066990852356, 1.3341237306594849, 1.3234590291976929]
Graphs saved to disk
