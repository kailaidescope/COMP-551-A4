Starting BERT epoch experiments script
Train method: head+1
Learning rate: 0.001 
Num epochs: 8 
Batch size: 32 
Weight decay: 1 
Warmup steps: 500
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])  - Requires grad: False
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])  - Requires grad: False
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.pooler.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: classifier.weight  - Size: torch.Size([28, 768])  - Requires grad: True
Name: classifier.bias  - Size: torch.Size([28])  - Requires grad: True
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8024, 'grad_norm': 4.479425430297852, 'learning_rate': 0.000925990675990676, 'epoch': 1.0}
{'eval_loss': 1.541856288909912, 'eval_accuracy': 0.5532102022867195, 'eval_f1': 0.34053712731709346, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.59      0.84      0.69       208\n         anger       1.00      0.01      0.02       109\n     annoyance       0.19      0.48      0.27       164\n      approval       0.63      0.13      0.21       258\n        caring       0.50      0.17      0.25        96\n     confusion       0.34      0.32      0.33       102\n     curiosity       0.45      0.61      0.52       164\n        desire       0.73      0.37      0.49        52\ndisappointment       0.25      0.01      0.02        91\n   disapproval       0.39      0.30      0.34       212\n       disgust       0.33      0.05      0.09        61\n embarrassment       0.29      0.35      0.32        20\n    excitement       0.75      0.06      0.11        52\n          fear       0.76      0.22      0.35        58\n     gratitude       0.97      0.86      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.45      0.49       106\n          love       0.69      0.82      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.72      0.43      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.52      0.85      0.64        40\n       sadness       0.33      0.49      0.39        84\n      surprise       0.53      0.41      0.46        95\n       neutral       0.59      0.71      0.65      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.45      0.35      0.34      4548\n  weighted avg       0.57      0.55      0.52      4548\n', 'eval_runtime': 2.9448, 'eval_samples_per_second': 1544.436, 'eval_steps_per_second': 48.561, 'epoch': 1.0}
{'loss': 1.5537, 'grad_norm': 4.1944169998168945, 'learning_rate': 0.0007937062937062938, 'epoch': 2.0}
{'eval_loss': 1.4451704025268555, 'eval_accuracy': 0.5778364116094987, 'eval_f1': 0.38997937933335003, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.69      0.68      0.69       326\n     amusement       0.72      0.87      0.78       208\n         anger       0.41      0.47      0.44       109\n     annoyance       0.38      0.18      0.25       164\n      approval       0.82      0.07      0.13       258\n        caring       0.25      0.02      0.04        96\n     confusion       0.48      0.12      0.19       102\n     curiosity       0.46      0.61      0.52       164\n        desire       0.85      0.42      0.56        52\ndisappointment       0.17      0.08      0.11        91\n   disapproval       0.30      0.31      0.30       212\n       disgust       0.36      0.39      0.38        61\n embarrassment       0.46      0.30      0.36        20\n    excitement       1.00      0.04      0.07        52\n          fear       0.67      0.50      0.57        58\n     gratitude       0.99      0.87      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.51      0.63      0.57       106\n          love       0.74      0.84      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.53      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.30      0.22      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.82      0.74        40\n       sadness       0.63      0.43      0.51        84\n      surprise       0.65      0.42      0.51        95\n       neutral       0.56      0.77      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.49      0.38      0.39      4548\n  weighted avg       0.58      0.58      0.54      4548\n', 'eval_runtime': 2.9605, 'eval_samples_per_second': 1536.23, 'eval_steps_per_second': 48.303, 'epoch': 2.0}
{'loss': 1.4814, 'grad_norm': 3.404491424560547, 'learning_rate': 0.0006614219114219114, 'epoch': 3.0}
{'eval_loss': 1.3813832998275757, 'eval_accuracy': 0.5914687774846086, 'eval_f1': 0.3892309739218486, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.78      0.69       326\n     amusement       0.74      0.73      0.73       208\n         anger       0.36      0.46      0.40       109\n     annoyance       0.42      0.10      0.16       164\n      approval       0.69      0.14      0.24       258\n        caring       0.58      0.19      0.28        96\n     confusion       0.49      0.19      0.27       102\n     curiosity       0.46      0.51      0.48       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.49      0.14      0.22       212\n       disgust       0.44      0.39      0.41        61\n embarrassment       0.80      0.20      0.32        20\n    excitement       0.28      0.25      0.27        52\n          fear       0.45      0.57      0.50        58\n     gratitude       0.90      0.91      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.56      0.58       106\n          love       0.69      0.88      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.60      0.56      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.69      0.12      0.21        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.65      0.66        40\n       sadness       0.60      0.35      0.44        84\n      surprise       0.58      0.47      0.52        95\n       neutral       0.57      0.82      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.37      0.39      4548\n  weighted avg       0.58      0.59      0.55      4548\n', 'eval_runtime': 2.995, 'eval_samples_per_second': 1518.536, 'eval_steps_per_second': 47.746, 'epoch': 3.0}
{'loss': 1.423, 'grad_norm': 3.310408115386963, 'learning_rate': 0.0005291375291375291, 'epoch': 4.0}
{'eval_loss': 1.3701871633529663, 'eval_accuracy': 0.5897097625329816, 'eval_f1': 0.4058873082614291, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.77      0.77      0.77       208\n         anger       0.61      0.37      0.46       109\n     annoyance       0.45      0.15      0.23       164\n      approval       0.45      0.23      0.31       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.46      0.25      0.33       102\n     curiosity       0.43      0.62      0.51       164\n        desire       0.64      0.54      0.58        52\ndisappointment       0.32      0.07      0.11        91\n   disapproval       0.33      0.32      0.33       212\n       disgust       0.31      0.61      0.41        61\n embarrassment       0.64      0.35      0.45        20\n    excitement       0.33      0.29      0.31        52\n          fear       0.63      0.50      0.56        58\n     gratitude       0.91      0.90      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.55      0.55       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.72      0.45      0.55        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.54      0.44      0.49        95\n       neutral       0.61      0.74      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.40      0.41      4548\n  weighted avg       0.59      0.59      0.56      4548\n', 'eval_runtime': 3.0111, 'eval_samples_per_second': 1510.413, 'eval_steps_per_second': 47.491, 'epoch': 4.0}
{'loss': 1.3646, 'grad_norm': 3.861185073852539, 'learning_rate': 0.0003968531468531469, 'epoch': 5.0}
{'eval_loss': 1.3969956636428833, 'eval_accuracy': 0.5738786279683378, 'eval_f1': 0.3740716927865218, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.44      0.88      0.58       326\n     amusement       0.68      0.84      0.75       208\n         anger       0.38      0.54      0.44       109\n     annoyance       0.40      0.10      0.17       164\n      approval       0.62      0.16      0.25       258\n        caring       0.67      0.23      0.34        96\n     confusion       0.46      0.24      0.31       102\n     curiosity       0.53      0.24      0.33       164\n        desire       0.84      0.40      0.55        52\ndisappointment       0.60      0.03      0.06        91\n   disapproval       0.47      0.13      0.21       212\n       disgust       0.50      0.31      0.38        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.19      0.27        52\n          fear       0.51      0.66      0.57        58\n     gratitude       0.94      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.65      0.16      0.26       106\n          love       0.74      0.69      0.71       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.55      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.54      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.59      0.47      0.53        40\n       sadness       0.48      0.55      0.51        84\n      surprise       0.51      0.60      0.55        95\n       neutral       0.58      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.49      0.36      0.37      4548\n  weighted avg       0.58      0.57      0.53      4548\n', 'eval_runtime': 3.0163, 'eval_samples_per_second': 1507.784, 'eval_steps_per_second': 47.408, 'epoch': 5.0}
{'loss': 1.3029, 'grad_norm': 3.490330696105957, 'learning_rate': 0.00026456876456876455, 'epoch': 6.0}
{'eval_loss': 1.331539511680603, 'eval_accuracy': 0.5947669305189094, 'eval_f1': 0.43700791306335923, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.60      0.82      0.69       326\n     amusement       0.63      0.92      0.75       208\n         anger       0.44      0.45      0.45       109\n     annoyance       0.47      0.15      0.23       164\n      approval       0.54      0.19      0.28       258\n        caring       0.54      0.47      0.50        96\n     confusion       0.37      0.32      0.34       102\n     curiosity       0.43      0.65      0.52       164\n        desire       0.55      0.50      0.53        52\ndisappointment       0.23      0.13      0.17        91\n   disapproval       0.48      0.14      0.22       212\n       disgust       0.51      0.38      0.43        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.74      0.45      0.56        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.58      0.57       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.54      0.59       119\n         pride       0.50      0.22      0.31         9\n   realization       0.61      0.19      0.29        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.62      0.60        40\n       sadness       0.44      0.57      0.50        84\n      surprise       0.51      0.56      0.53        95\n       neutral       0.61      0.72      0.66      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.48      0.43      0.44      4548\n  weighted avg       0.58      0.59      0.57      4548\n', 'eval_runtime': 3.015, 'eval_samples_per_second': 1508.446, 'eval_steps_per_second': 47.429, 'epoch': 6.0}
{'loss': 1.2344, 'grad_norm': 3.8311047554016113, 'learning_rate': 0.00013228438228438227, 'epoch': 7.0}
{'eval_loss': 1.28355872631073, 'eval_accuracy': 0.6070800351802991, 'eval_f1': 0.4467454871530697, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.83      0.72       326\n     amusement       0.72      0.91      0.80       208\n         anger       0.44      0.50      0.47       109\n     annoyance       0.33      0.23      0.27       164\n      approval       0.48      0.26      0.34       258\n        caring       0.54      0.35      0.43        96\n     confusion       0.49      0.35      0.41       102\n     curiosity       0.45      0.37      0.41       164\n        desire       0.59      0.56      0.57        52\ndisappointment       0.37      0.16      0.23        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.49      0.41      0.45        61\n embarrassment       0.40      0.40      0.40        20\n    excitement       0.54      0.29      0.38        52\n          fear       0.51      0.69      0.58        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.60      0.58       106\n          love       0.73      0.87      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.58      0.61      0.59       119\n         pride       1.00      0.11      0.20         9\n   realization       0.45      0.18      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.62      0.62        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.47      0.62      0.53        95\n       neutral       0.63      0.72      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.44      0.45      4548\n  weighted avg       0.59      0.61      0.59      4548\n', 'eval_runtime': 3.0176, 'eval_samples_per_second': 1507.159, 'eval_steps_per_second': 47.389, 'epoch': 7.0}
{'loss': 1.1416, 'grad_norm': 3.696929454803467, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.2610737085342407, 'eval_accuracy': 0.6134564643799473, 'eval_f1': 0.46243391934273304, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.82      0.74       326\n     amusement       0.72      0.91      0.81       208\n         anger       0.42      0.48      0.45       109\n     annoyance       0.34      0.21      0.26       164\n      approval       0.52      0.27      0.36       258\n        caring       0.56      0.46      0.50        96\n     confusion       0.48      0.31      0.38       102\n     curiosity       0.47      0.50      0.48       164\n        desire       0.65      0.58      0.61        52\ndisappointment       0.28      0.14      0.19        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.46      0.49      0.48        61\n embarrassment       0.62      0.40      0.48        20\n    excitement       0.42      0.33      0.37        52\n          fear       0.66      0.50      0.57        58\n     gratitude       0.91      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.71      0.90      0.79       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.66      0.60      0.63       119\n         pride       1.00      0.11      0.20         9\n   realization       0.48      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.46      0.60      0.52        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.63      0.73      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.55      0.45      0.46      4548\n  weighted avg       0.60      0.61      0.59      4548\n', 'eval_runtime': 3.0208, 'eval_samples_per_second': 1505.581, 'eval_steps_per_second': 47.339, 'epoch': 8.0}
{'train_runtime': 260.634, 'train_samples_per_second': 1114.452, 'train_steps_per_second': 34.838, 'train_loss': 1.4129993321086867, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 11 20 ... 27 17 27]
Metrics:
F1: 0.49664419187427505 
Accuracy: 0.614161220043573
Results: {'f1': [0.34053712731709346, 0.38997937933335003, 0.3892309739218486, 0.4058873082614291, 0.3740716927865218, 0.43700791306335923, 0.4467454871530697, 0.46243391934273304, 0.49664419187427505], 'accuracy': [0.5532102022867195, 0.5778364116094987, 0.5914687774846086, 0.5897097625329816, 0.5738786279683378, 0.5947669305189094, 0.6070800351802991, 0.6134564643799473, 0.614161220043573], 'duration': [34.89977169036865, 67.03103160858154, 99.37545394897461, 132.01799511909485, 164.83250188827515, 197.5596125125885, 230.39795088768005, 263.1402266025543, 266.14936089515686], 'reports': ['                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.59      0.84      0.69       208\n         anger       1.00      0.01      0.02       109\n     annoyance       0.19      0.48      0.27       164\n      approval       0.63      0.13      0.21       258\n        caring       0.50      0.17      0.25        96\n     confusion       0.34      0.32      0.33       102\n     curiosity       0.45      0.61      0.52       164\n        desire       0.73      0.37      0.49        52\ndisappointment       0.25      0.01      0.02        91\n   disapproval       0.39      0.30      0.34       212\n       disgust       0.33      0.05      0.09        61\n embarrassment       0.29      0.35      0.32        20\n    excitement       0.75      0.06      0.11        52\n          fear       0.76      0.22      0.35        58\n     gratitude       0.97      0.86      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.45      0.49       106\n          love       0.69      0.82      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.72      0.43      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.52      0.85      0.64        40\n       sadness       0.33      0.49      0.39        84\n      surprise       0.53      0.41      0.46        95\n       neutral       0.59      0.71      0.65      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.45      0.35      0.34      4548\n  weighted avg       0.57      0.55      0.52      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.69      0.68      0.69       326\n     amusement       0.72      0.87      0.78       208\n         anger       0.41      0.47      0.44       109\n     annoyance       0.38      0.18      0.25       164\n      approval       0.82      0.07      0.13       258\n        caring       0.25      0.02      0.04        96\n     confusion       0.48      0.12      0.19       102\n     curiosity       0.46      0.61      0.52       164\n        desire       0.85      0.42      0.56        52\ndisappointment       0.17      0.08      0.11        91\n   disapproval       0.30      0.31      0.30       212\n       disgust       0.36      0.39      0.38        61\n embarrassment       0.46      0.30      0.36        20\n    excitement       1.00      0.04      0.07        52\n          fear       0.67      0.50      0.57        58\n     gratitude       0.99      0.87      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.51      0.63      0.57       106\n          love       0.74      0.84      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.53      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.30      0.22      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.82      0.74        40\n       sadness       0.63      0.43      0.51        84\n      surprise       0.65      0.42      0.51        95\n       neutral       0.56      0.77      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.49      0.38      0.39      4548\n  weighted avg       0.58      0.58      0.54      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.62      0.78      0.69       326\n     amusement       0.74      0.73      0.73       208\n         anger       0.36      0.46      0.40       109\n     annoyance       0.42      0.10      0.16       164\n      approval       0.69      0.14      0.24       258\n        caring       0.58      0.19      0.28        96\n     confusion       0.49      0.19      0.27       102\n     curiosity       0.46      0.51      0.48       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.49      0.14      0.22       212\n       disgust       0.44      0.39      0.41        61\n embarrassment       0.80      0.20      0.32        20\n    excitement       0.28      0.25      0.27        52\n          fear       0.45      0.57      0.50        58\n     gratitude       0.90      0.91      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.56      0.58       106\n          love       0.69      0.88      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.60      0.56      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.69      0.12      0.21        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.65      0.66        40\n       sadness       0.60      0.35      0.44        84\n      surprise       0.58      0.47      0.52        95\n       neutral       0.57      0.82      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.37      0.39      4548\n  weighted avg       0.58      0.59      0.55      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.77      0.77      0.77       208\n         anger       0.61      0.37      0.46       109\n     annoyance       0.45      0.15      0.23       164\n      approval       0.45      0.23      0.31       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.46      0.25      0.33       102\n     curiosity       0.43      0.62      0.51       164\n        desire       0.64      0.54      0.58        52\ndisappointment       0.32      0.07      0.11        91\n   disapproval       0.33      0.32      0.33       212\n       disgust       0.31      0.61      0.41        61\n embarrassment       0.64      0.35      0.45        20\n    excitement       0.33      0.29      0.31        52\n          fear       0.63      0.50      0.56        58\n     gratitude       0.91      0.90      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.55      0.55       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.72      0.45      0.55        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.54      0.44      0.49        95\n       neutral       0.61      0.74      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.40      0.41      4548\n  weighted avg       0.59      0.59      0.56      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.44      0.88      0.58       326\n     amusement       0.68      0.84      0.75       208\n         anger       0.38      0.54      0.44       109\n     annoyance       0.40      0.10      0.17       164\n      approval       0.62      0.16      0.25       258\n        caring       0.67      0.23      0.34        96\n     confusion       0.46      0.24      0.31       102\n     curiosity       0.53      0.24      0.33       164\n        desire       0.84      0.40      0.55        52\ndisappointment       0.60      0.03      0.06        91\n   disapproval       0.47      0.13      0.21       212\n       disgust       0.50      0.31      0.38        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.19      0.27        52\n          fear       0.51      0.66      0.57        58\n     gratitude       0.94      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.65      0.16      0.26       106\n          love       0.74      0.69      0.71       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.55      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.54      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.59      0.47      0.53        40\n       sadness       0.48      0.55      0.51        84\n      surprise       0.51      0.60      0.55        95\n       neutral       0.58      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.49      0.36      0.37      4548\n  weighted avg       0.58      0.57      0.53      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.60      0.82      0.69       326\n     amusement       0.63      0.92      0.75       208\n         anger       0.44      0.45      0.45       109\n     annoyance       0.47      0.15      0.23       164\n      approval       0.54      0.19      0.28       258\n        caring       0.54      0.47      0.50        96\n     confusion       0.37      0.32      0.34       102\n     curiosity       0.43      0.65      0.52       164\n        desire       0.55      0.50      0.53        52\ndisappointment       0.23      0.13      0.17        91\n   disapproval       0.48      0.14      0.22       212\n       disgust       0.51      0.38      0.43        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.74      0.45      0.56        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.58      0.57       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.54      0.59       119\n         pride       0.50      0.22      0.31         9\n   realization       0.61      0.19      0.29        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.62      0.60        40\n       sadness       0.44      0.57      0.50        84\n      surprise       0.51      0.56      0.53        95\n       neutral       0.61      0.72      0.66      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.48      0.43      0.44      4548\n  weighted avg       0.58      0.59      0.57      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.64      0.83      0.72       326\n     amusement       0.72      0.91      0.80       208\n         anger       0.44      0.50      0.47       109\n     annoyance       0.33      0.23      0.27       164\n      approval       0.48      0.26      0.34       258\n        caring       0.54      0.35      0.43        96\n     confusion       0.49      0.35      0.41       102\n     curiosity       0.45      0.37      0.41       164\n        desire       0.59      0.56      0.57        52\ndisappointment       0.37      0.16      0.23        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.49      0.41      0.45        61\n embarrassment       0.40      0.40      0.40        20\n    excitement       0.54      0.29      0.38        52\n          fear       0.51      0.69      0.58        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.60      0.58       106\n          love       0.73      0.87      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.58      0.61      0.59       119\n         pride       1.00      0.11      0.20         9\n   realization       0.45      0.18      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.62      0.62        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.47      0.62      0.53        95\n       neutral       0.63      0.72      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.44      0.45      4548\n  weighted avg       0.59      0.61      0.59      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.67      0.82      0.74       326\n     amusement       0.72      0.91      0.81       208\n         anger       0.42      0.48      0.45       109\n     annoyance       0.34      0.21      0.26       164\n      approval       0.52      0.27      0.36       258\n        caring       0.56      0.46      0.50        96\n     confusion       0.48      0.31      0.38       102\n     curiosity       0.47      0.50      0.48       164\n        desire       0.65      0.58      0.61        52\ndisappointment       0.28      0.14      0.19        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.46      0.49      0.48        61\n embarrassment       0.62      0.40      0.48        20\n    excitement       0.42      0.33      0.37        52\n          fear       0.66      0.50      0.57        58\n     gratitude       0.91      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.71      0.90      0.79       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.66      0.60      0.63       119\n         pride       1.00      0.11      0.20         9\n   realization       0.48      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.46      0.60      0.52        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.63      0.73      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.55      0.45      0.46      4548\n  weighted avg       0.60      0.61      0.59      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.62      0.73      0.67       348\n     amusement       0.72      0.89      0.80       186\n         anger       0.50      0.43      0.46       131\n     annoyance       0.38      0.21      0.27       194\n      approval       0.56      0.32      0.40       236\n        caring       0.43      0.37      0.40        86\n     confusion       0.49      0.41      0.45        97\n     curiosity       0.46      0.52      0.49       176\n        desire       0.66      0.41      0.51        56\ndisappointment       0.38      0.18      0.25        88\n   disapproval       0.43      0.33      0.37       195\n       disgust       0.56      0.50      0.53        76\n embarrassment       0.59      0.43      0.50        23\n    excitement       0.50      0.46      0.48        57\n          fear       0.69      0.75      0.72        65\n     gratitude       0.91      0.90      0.91       260\n         grief       0.00      0.00      0.00         2\n           joy       0.54      0.59      0.57        93\n          love       0.74      0.90      0.81       160\n   nervousness       0.67      0.50      0.57        12\n      optimism       0.60      0.63      0.61       107\n         pride       0.40      0.29      0.33         7\n   realization       0.42      0.17      0.24        89\n        relief       1.00      0.14      0.25         7\n       remorse       0.60      0.70      0.65        44\n       sadness       0.56      0.55      0.55       102\n      surprise       0.47      0.40      0.43        87\n       neutral       0.64      0.74      0.69      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.55      0.48      0.50      4590\n  weighted avg       0.60      0.61      0.60      4590\n'], 'final': {'f1': 0.49664419187427505, 'accuracy': 0.614161220043573, 'duration': 266.15264534950256, 'report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.73      0.67       348\n     amusement       0.72      0.89      0.80       186\n         anger       0.50      0.43      0.46       131\n     annoyance       0.38      0.21      0.27       194\n      approval       0.56      0.32      0.40       236\n        caring       0.43      0.37      0.40        86\n     confusion       0.49      0.41      0.45        97\n     curiosity       0.46      0.52      0.49       176\n        desire       0.66      0.41      0.51        56\ndisappointment       0.38      0.18      0.25        88\n   disapproval       0.43      0.33      0.37       195\n       disgust       0.56      0.50      0.53        76\n embarrassment       0.59      0.43      0.50        23\n    excitement       0.50      0.46      0.48        57\n          fear       0.69      0.75      0.72        65\n     gratitude       0.91      0.90      0.91       260\n         grief       0.00      0.00      0.00         2\n           joy       0.54      0.59      0.57        93\n          love       0.74      0.90      0.81       160\n   nervousness       0.67      0.50      0.57        12\n      optimism       0.60      0.63      0.61       107\n         pride       0.40      0.29      0.33         7\n   realization       0.42      0.17      0.24        89\n        relief       1.00      0.14      0.25         7\n       remorse       0.60      0.70      0.65        44\n       sadness       0.56      0.55      0.55       102\n      surprise       0.47      0.40      0.43        87\n       neutral       0.64      0.74      0.69      1606\n\n      accuracy                           0.61      4590\n     macro avg       0.55      0.48      0.50      4590\n  weighted avg       0.60      0.61      0.60      4590\n'}}
Final Report:
                 precision    recall  f1-score   support

    admiration       0.62      0.73      0.67       348
     amusement       0.72      0.89      0.80       186
         anger       0.50      0.43      0.46       131
     annoyance       0.38      0.21      0.27       194
      approval       0.56      0.32      0.40       236
        caring       0.43      0.37      0.40        86
     confusion       0.49      0.41      0.45        97
     curiosity       0.46      0.52      0.49       176
        desire       0.66      0.41      0.51        56
disappointment       0.38      0.18      0.25        88
   disapproval       0.43      0.33      0.37       195
       disgust       0.56      0.50      0.53        76
 embarrassment       0.59      0.43      0.50        23
    excitement       0.50      0.46      0.48        57
          fear       0.69      0.75      0.72        65
     gratitude       0.91      0.90      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.54      0.59      0.57        93
          love       0.74      0.90      0.81       160
   nervousness       0.67      0.50      0.57        12
      optimism       0.60      0.63      0.61       107
         pride       0.40      0.29      0.33         7
   realization       0.42      0.17      0.24        89
        relief       1.00      0.14      0.25         7
       remorse       0.60      0.70      0.65        44
       sadness       0.56      0.55      0.55       102
      surprise       0.47      0.40      0.43        87
       neutral       0.64      0.74      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.55      0.48      0.50      4590
  weighted avg       0.60      0.61      0.60      4590

F1 scores: [0.34053712731709346, 0.38997937933335003, 0.3892309739218486, 0.4058873082614291, 0.3740716927865218, 0.43700791306335923, 0.4467454871530697, 0.46243391934273304, 0.49664419187427505]
Accuracies: [0.5532102022867195, 0.5778364116094987, 0.5914687774846086, 0.5897097625329816, 0.5738786279683378, 0.5947669305189094, 0.6070800351802991, 0.6134564643799473, 0.614161220043573]
Durations: [34.89977169036865, 67.03103160858154, 99.37545394897461, 132.01799511909485, 164.83250188827515, 197.5596125125885, 230.39795088768005, 263.1402266025543, 266.14936089515686]
log_history: [{'loss': 1.8024, 'grad_norm': 4.479425430297852, 'learning_rate': 0.000925990675990676, 'epoch': 1.0, 'step': 1135}, {'eval_loss': 1.541856288909912, 'eval_accuracy': 0.5532102022867195, 'eval_f1': 0.34053712731709346, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.59      0.84      0.69       208\n         anger       1.00      0.01      0.02       109\n     annoyance       0.19      0.48      0.27       164\n      approval       0.63      0.13      0.21       258\n        caring       0.50      0.17      0.25        96\n     confusion       0.34      0.32      0.33       102\n     curiosity       0.45      0.61      0.52       164\n        desire       0.73      0.37      0.49        52\ndisappointment       0.25      0.01      0.02        91\n   disapproval       0.39      0.30      0.34       212\n       disgust       0.33      0.05      0.09        61\n embarrassment       0.29      0.35      0.32        20\n    excitement       0.75      0.06      0.11        52\n          fear       0.76      0.22      0.35        58\n     gratitude       0.97      0.86      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.45      0.49       106\n          love       0.69      0.82      0.75       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.72      0.43      0.54       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.52      0.85      0.64        40\n       sadness       0.33      0.49      0.39        84\n      surprise       0.53      0.41      0.46        95\n       neutral       0.59      0.71      0.65      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.45      0.35      0.34      4548\n  weighted avg       0.57      0.55      0.52      4548\n', 'eval_runtime': 2.9448, 'eval_samples_per_second': 1544.436, 'eval_steps_per_second': 48.561, 'epoch': 1.0, 'step': 1135}, {'loss': 1.5537, 'grad_norm': 4.1944169998168945, 'learning_rate': 0.0007937062937062938, 'epoch': 2.0, 'step': 2270}, {'eval_loss': 1.4451704025268555, 'eval_accuracy': 0.5778364116094987, 'eval_f1': 0.38997937933335003, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.69      0.68      0.69       326\n     amusement       0.72      0.87      0.78       208\n         anger       0.41      0.47      0.44       109\n     annoyance       0.38      0.18      0.25       164\n      approval       0.82      0.07      0.13       258\n        caring       0.25      0.02      0.04        96\n     confusion       0.48      0.12      0.19       102\n     curiosity       0.46      0.61      0.52       164\n        desire       0.85      0.42      0.56        52\ndisappointment       0.17      0.08      0.11        91\n   disapproval       0.30      0.31      0.30       212\n       disgust       0.36      0.39      0.38        61\n embarrassment       0.46      0.30      0.36        20\n    excitement       1.00      0.04      0.07        52\n          fear       0.67      0.50      0.57        58\n     gratitude       0.99      0.87      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.51      0.63      0.57       106\n          love       0.74      0.84      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.68      0.53      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.30      0.22      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.82      0.74        40\n       sadness       0.63      0.43      0.51        84\n      surprise       0.65      0.42      0.51        95\n       neutral       0.56      0.77      0.65      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.49      0.38      0.39      4548\n  weighted avg       0.58      0.58      0.54      4548\n', 'eval_runtime': 2.9605, 'eval_samples_per_second': 1536.23, 'eval_steps_per_second': 48.303, 'epoch': 2.0, 'step': 2270}, {'loss': 1.4814, 'grad_norm': 3.404491424560547, 'learning_rate': 0.0006614219114219114, 'epoch': 3.0, 'step': 3405}, {'eval_loss': 1.3813832998275757, 'eval_accuracy': 0.5914687774846086, 'eval_f1': 0.3892309739218486, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.62      0.78      0.69       326\n     amusement       0.74      0.73      0.73       208\n         anger       0.36      0.46      0.40       109\n     annoyance       0.42      0.10      0.16       164\n      approval       0.69      0.14      0.24       258\n        caring       0.58      0.19      0.28        96\n     confusion       0.49      0.19      0.27       102\n     curiosity       0.46      0.51      0.48       164\n        desire       0.66      0.48      0.56        52\ndisappointment       0.20      0.01      0.02        91\n   disapproval       0.49      0.14      0.22       212\n       disgust       0.44      0.39      0.41        61\n embarrassment       0.80      0.20      0.32        20\n    excitement       0.28      0.25      0.27        52\n          fear       0.45      0.57      0.50        58\n     gratitude       0.90      0.91      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.60      0.56      0.58       106\n          love       0.69      0.88      0.77       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.60      0.56      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.69      0.12      0.21        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.65      0.66        40\n       sadness       0.60      0.35      0.44        84\n      surprise       0.58      0.47      0.52        95\n       neutral       0.57      0.82      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.37      0.39      4548\n  weighted avg       0.58      0.59      0.55      4548\n', 'eval_runtime': 2.995, 'eval_samples_per_second': 1518.536, 'eval_steps_per_second': 47.746, 'epoch': 3.0, 'step': 3405}, {'loss': 1.423, 'grad_norm': 3.310408115386963, 'learning_rate': 0.0005291375291375291, 'epoch': 4.0, 'step': 4540}, {'eval_loss': 1.3701871633529663, 'eval_accuracy': 0.5897097625329816, 'eval_f1': 0.4058873082614291, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.63      0.79      0.70       326\n     amusement       0.77      0.77      0.77       208\n         anger       0.61      0.37      0.46       109\n     annoyance       0.45      0.15      0.23       164\n      approval       0.45      0.23      0.31       258\n        caring       0.72      0.14      0.23        96\n     confusion       0.46      0.25      0.33       102\n     curiosity       0.43      0.62      0.51       164\n        desire       0.64      0.54      0.58        52\ndisappointment       0.32      0.07      0.11        91\n   disapproval       0.33      0.32      0.33       212\n       disgust       0.31      0.61      0.41        61\n embarrassment       0.64      0.35      0.45        20\n    excitement       0.33      0.29      0.31        52\n          fear       0.63      0.50      0.56        58\n     gratitude       0.91      0.90      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.55      0.55       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.72      0.45      0.55        40\n       sadness       0.39      0.65      0.49        84\n      surprise       0.54      0.44      0.49        95\n       neutral       0.61      0.74      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.40      0.41      4548\n  weighted avg       0.59      0.59      0.56      4548\n', 'eval_runtime': 3.0111, 'eval_samples_per_second': 1510.413, 'eval_steps_per_second': 47.491, 'epoch': 4.0, 'step': 4540}, {'loss': 1.3646, 'grad_norm': 3.861185073852539, 'learning_rate': 0.0003968531468531469, 'epoch': 5.0, 'step': 5675}, {'eval_loss': 1.3969956636428833, 'eval_accuracy': 0.5738786279683378, 'eval_f1': 0.3740716927865218, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.44      0.88      0.58       326\n     amusement       0.68      0.84      0.75       208\n         anger       0.38      0.54      0.44       109\n     annoyance       0.40      0.10      0.17       164\n      approval       0.62      0.16      0.25       258\n        caring       0.67      0.23      0.34        96\n     confusion       0.46      0.24      0.31       102\n     curiosity       0.53      0.24      0.33       164\n        desire       0.84      0.40      0.55        52\ndisappointment       0.60      0.03      0.06        91\n   disapproval       0.47      0.13      0.21       212\n       disgust       0.50      0.31      0.38        61\n embarrassment       0.60      0.15      0.24        20\n    excitement       0.45      0.19      0.27        52\n          fear       0.51      0.66      0.57        58\n     gratitude       0.94      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.65      0.16      0.26       106\n          love       0.74      0.69      0.71       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.55      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       0.54      0.18      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.59      0.47      0.53        40\n       sadness       0.48      0.55      0.51        84\n      surprise       0.51      0.60      0.55        95\n       neutral       0.58      0.79      0.66      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.49      0.36      0.37      4548\n  weighted avg       0.58      0.57      0.53      4548\n', 'eval_runtime': 3.0163, 'eval_samples_per_second': 1507.784, 'eval_steps_per_second': 47.408, 'epoch': 5.0, 'step': 5675}, {'loss': 1.3029, 'grad_norm': 3.490330696105957, 'learning_rate': 0.00026456876456876455, 'epoch': 6.0, 'step': 6810}, {'eval_loss': 1.331539511680603, 'eval_accuracy': 0.5947669305189094, 'eval_f1': 0.43700791306335923, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.60      0.82      0.69       326\n     amusement       0.63      0.92      0.75       208\n         anger       0.44      0.45      0.45       109\n     annoyance       0.47      0.15      0.23       164\n      approval       0.54      0.19      0.28       258\n        caring       0.54      0.47      0.50        96\n     confusion       0.37      0.32      0.34       102\n     curiosity       0.43      0.65      0.52       164\n        desire       0.55      0.50      0.53        52\ndisappointment       0.23      0.13      0.17        91\n   disapproval       0.48      0.14      0.22       212\n       disgust       0.51      0.38      0.43        61\n embarrassment       0.57      0.40      0.47        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.74      0.45      0.56        58\n     gratitude       0.95      0.89      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.58      0.57       106\n          love       0.72      0.89      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.65      0.54      0.59       119\n         pride       0.50      0.22      0.31         9\n   realization       0.61      0.19      0.29        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.58      0.62      0.60        40\n       sadness       0.44      0.57      0.50        84\n      surprise       0.51      0.56      0.53        95\n       neutral       0.61      0.72      0.66      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.48      0.43      0.44      4548\n  weighted avg       0.58      0.59      0.57      4548\n', 'eval_runtime': 3.015, 'eval_samples_per_second': 1508.446, 'eval_steps_per_second': 47.429, 'epoch': 6.0, 'step': 6810}, {'loss': 1.2344, 'grad_norm': 3.8311047554016113, 'learning_rate': 0.00013228438228438227, 'epoch': 7.0, 'step': 7945}, {'eval_loss': 1.28355872631073, 'eval_accuracy': 0.6070800351802991, 'eval_f1': 0.4467454871530697, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.83      0.72       326\n     amusement       0.72      0.91      0.80       208\n         anger       0.44      0.50      0.47       109\n     annoyance       0.33      0.23      0.27       164\n      approval       0.48      0.26      0.34       258\n        caring       0.54      0.35      0.43        96\n     confusion       0.49      0.35      0.41       102\n     curiosity       0.45      0.37      0.41       164\n        desire       0.59      0.56      0.57        52\ndisappointment       0.37      0.16      0.23        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.49      0.41      0.45        61\n embarrassment       0.40      0.40      0.40        20\n    excitement       0.54      0.29      0.38        52\n          fear       0.51      0.69      0.58        58\n     gratitude       0.93      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.56      0.60      0.58       106\n          love       0.73      0.87      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.58      0.61      0.59       119\n         pride       1.00      0.11      0.20         9\n   realization       0.45      0.18      0.25        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.62      0.62        40\n       sadness       0.48      0.56      0.52        84\n      surprise       0.47      0.62      0.53        95\n       neutral       0.63      0.72      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.44      0.45      4548\n  weighted avg       0.59      0.61      0.59      4548\n', 'eval_runtime': 3.0176, 'eval_samples_per_second': 1507.159, 'eval_steps_per_second': 47.389, 'epoch': 7.0, 'step': 7945}, {'loss': 1.1416, 'grad_norm': 3.696929454803467, 'learning_rate': 0.0, 'epoch': 8.0, 'step': 9080}, {'eval_loss': 1.2610737085342407, 'eval_accuracy': 0.6134564643799473, 'eval_f1': 0.46243391934273304, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.82      0.74       326\n     amusement       0.72      0.91      0.81       208\n         anger       0.42      0.48      0.45       109\n     annoyance       0.34      0.21      0.26       164\n      approval       0.52      0.27      0.36       258\n        caring       0.56      0.46      0.50        96\n     confusion       0.48      0.31      0.38       102\n     curiosity       0.47      0.50      0.48       164\n        desire       0.65      0.58      0.61        52\ndisappointment       0.28      0.14      0.19        91\n   disapproval       0.45      0.30      0.36       212\n       disgust       0.46      0.49      0.48        61\n embarrassment       0.62      0.40      0.48        20\n    excitement       0.42      0.33      0.37        52\n          fear       0.66      0.50      0.57        58\n     gratitude       0.91      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.71      0.90      0.79       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.66      0.60      0.63       119\n         pride       1.00      0.11      0.20         9\n   realization       0.48      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.60      0.60        40\n       sadness       0.46      0.60      0.52        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.63      0.73      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.55      0.45      0.46      4548\n  weighted avg       0.60      0.61      0.59      4548\n', 'eval_runtime': 3.0208, 'eval_samples_per_second': 1505.581, 'eval_steps_per_second': 47.339, 'epoch': 8.0, 'step': 9080}, {'train_runtime': 260.634, 'train_samples_per_second': 1114.452, 'train_steps_per_second': 34.838, 'total_flos': 5450357510123232.0, 'train_loss': 1.4129993321086867, 'epoch': 8.0, 'step': 9080}]
Training Losses ( 8 ): [1.8024, 1.5537, 1.4814, 1.423, 1.3646, 1.3029, 1.2344, 1.1416]
Validation Losses ( 8 ): [1.541856288909912, 1.4451704025268555, 1.3813832998275757, 1.3701871633529663, 1.3969956636428833, 1.331539511680603, 1.28355872631073, 1.2610737085342407]
Graphs saved to disk
