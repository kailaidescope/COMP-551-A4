Starting BERT epoch experiments script
Train method: head+1
======= Search hyperparam: weight_decay  =======
====  weight_decay :  0.01  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.01 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8369, 'grad_norm': 7.658265590667725, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5583958625793457, 'eval_accuracy': 0.5573878627968337, 'eval_f1': 0.3545926043540719, 'eval_runtime': 3.0093, 'eval_samples_per_second': 1511.297, 'eval_steps_per_second': 94.705, 'epoch': 1.0}
{'loss': 1.5635, 'grad_norm': 5.42426872253418, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.4697152376174927, 'eval_accuracy': 0.5767370272647317, 'eval_f1': 0.38729105372761746, 'eval_runtime': 3.0299, 'eval_samples_per_second': 1501.05, 'eval_steps_per_second': 94.063, 'epoch': 2.0}
{'loss': 1.4738, 'grad_norm': 6.3211469650268555, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.3797661066055298, 'eval_accuracy': 0.5868513632365875, 'eval_f1': 0.3826055628718725, 'eval_runtime': 3.0393, 'eval_samples_per_second': 1496.419, 'eval_steps_per_second': 93.773, 'epoch': 3.0}
{'loss': 1.4038, 'grad_norm': 2.748565435409546, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3801599740982056, 'eval_accuracy': 0.5908091468777484, 'eval_f1': 0.43539024792099623, 'eval_runtime': 3.0442, 'eval_samples_per_second': 1493.996, 'eval_steps_per_second': 93.621, 'epoch': 4.0}
{'loss': 1.3517, 'grad_norm': 6.498403072357178, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.377465009689331, 'eval_accuracy': 0.5936675461741425, 'eval_f1': 0.4053070774531529, 'eval_runtime': 3.0459, 'eval_samples_per_second': 1493.137, 'eval_steps_per_second': 93.567, 'epoch': 5.0}
{'loss': 1.298, 'grad_norm': 5.312451362609863, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3533129692077637, 'eval_accuracy': 0.5985048372911169, 'eval_f1': 0.4482974443248816, 'eval_runtime': 3.0444, 'eval_samples_per_second': 1493.911, 'eval_steps_per_second': 93.616, 'epoch': 6.0}
{'loss': 1.2438, 'grad_norm': 4.076095104217529, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.338918924331665, 'eval_accuracy': 0.6020228671943711, 'eval_f1': 0.44252023057903456, 'eval_runtime': 3.0917, 'eval_samples_per_second': 1471.045, 'eval_steps_per_second': 92.183, 'epoch': 7.0}
{'loss': 1.2013, 'grad_norm': 4.891547203063965, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3157367706298828, 'eval_accuracy': 0.6072999120492524, 'eval_f1': 0.4696962525272915, 'eval_runtime': 3.0432, 'eval_samples_per_second': 1494.455, 'eval_steps_per_second': 93.65, 'epoch': 8.0}
{'train_runtime': 285.2241, 'train_samples_per_second': 1018.371, 'train_steps_per_second': 63.669, 'train_loss': 1.4216052219206017, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 20 ... 27 17 27]
Metrics:
F1: 0.4639866610612023 
Accuracy: 0.6071895424836601
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.71      0.67       348
     amusement       0.75      0.87      0.81       186
         anger       0.52      0.43      0.47       131
     annoyance       0.35      0.16      0.22       194
      approval       0.54      0.32      0.40       236
        caring       0.46      0.36      0.40        86
     confusion       0.46      0.32      0.38        97
     curiosity       0.45      0.48      0.46       176
        desire       0.62      0.32      0.42        56
disappointment       0.41      0.18      0.25        88
   disapproval       0.43      0.31      0.36       195
       disgust       0.54      0.50      0.52        76
 embarrassment       0.57      0.35      0.43        23
    excitement       0.47      0.42      0.44        57
          fear       0.64      0.71      0.67        65
     gratitude       0.90      0.89      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.54      0.59      0.56        93
          love       0.75      0.85      0.80       160
   nervousness       0.75      0.50      0.60        12
      optimism       0.60      0.58      0.59       107
         pride       0.33      0.14      0.20         7
   realization       0.35      0.07      0.11        89
        relief       0.00      0.00      0.00         7
       remorse       0.54      0.73      0.62        44
       sadness       0.63      0.56      0.59       102
      surprise       0.45      0.40      0.43        87
       neutral       0.62      0.77      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.51      0.45      0.46      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3545926043540719, 0.38729105372761746, 0.3826055628718725, 0.43539024792099623, 0.4053070774531529, 0.4482974443248816, 0.44252023057903456, 0.4696962525272915, 0.4639866610612023]
Accuracies: [0.5573878627968337, 0.5767370272647317, 0.5868513632365875, 0.5908091468777484, 0.5936675461741425, 0.5985048372911169, 0.6020228671943711, 0.6072999120492524, 0.6071895424836601]
Durations: [38.93542194366455, 74.19510531425476, 109.62125420570374, 145.06712079048157, 180.60504913330078, 216.1580731868744, 252.83634972572327, 288.72390031814575, 291.77828645706177]
Training Losses ( 8 ): [1.8369, 1.5635, 1.4738, 1.4038, 1.3517, 1.298, 1.2438, 1.2013]
Validation Losses ( 8 ): [1.5583958625793457, 1.4697152376174927, 1.3797661066055298, 1.3801599740982056, 1.377465009689331, 1.3533129692077637, 1.338918924331665, 1.3157367706298828]
====  weight_decay :  0.1  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.1 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8342, 'grad_norm': 8.215070724487305, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.537731409072876, 'eval_accuracy': 0.552990325417766, 'eval_f1': 0.33833237838297786, 'eval_runtime': 3.0361, 'eval_samples_per_second': 1497.98, 'eval_steps_per_second': 93.871, 'epoch': 1.0}
{'loss': 1.5693, 'grad_norm': 5.315792560577393, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5128542184829712, 'eval_accuracy': 0.5716798592788038, 'eval_f1': 0.37364688633306065, 'eval_runtime': 3.0396, 'eval_samples_per_second': 1496.233, 'eval_steps_per_second': 93.761, 'epoch': 2.0}
{'loss': 1.4902, 'grad_norm': 4.573399543762207, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.419344186782837, 'eval_accuracy': 0.5804749340369393, 'eval_f1': 0.3694520552992079, 'eval_runtime': 3.0371, 'eval_samples_per_second': 1497.461, 'eval_steps_per_second': 93.838, 'epoch': 3.0}
{'loss': 1.4193, 'grad_norm': 3.7225475311279297, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.3903018236160278, 'eval_accuracy': 0.5850923482849604, 'eval_f1': 0.4087030800628048, 'eval_runtime': 3.0352, 'eval_samples_per_second': 1498.422, 'eval_steps_per_second': 93.898, 'epoch': 4.0}
{'loss': 1.3584, 'grad_norm': 6.226444721221924, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.3968901634216309, 'eval_accuracy': 0.5853122251539138, 'eval_f1': 0.3947235411668455, 'eval_runtime': 3.0886, 'eval_samples_per_second': 1472.491, 'eval_steps_per_second': 92.274, 'epoch': 5.0}
{'loss': 1.3026, 'grad_norm': 5.838990211486816, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3527816534042358, 'eval_accuracy': 0.5958663148636764, 'eval_f1': 0.4430544568506186, 'eval_runtime': 3.0383, 'eval_samples_per_second': 1496.867, 'eval_steps_per_second': 93.801, 'epoch': 6.0}
{'loss': 1.2383, 'grad_norm': 3.9234206676483154, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3396953344345093, 'eval_accuracy': 0.5974054529463501, 'eval_f1': 0.43960009396714206, 'eval_runtime': 3.0351, 'eval_samples_per_second': 1498.453, 'eval_steps_per_second': 93.9, 'epoch': 7.0}
{'loss': 1.1676, 'grad_norm': 5.232569217681885, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3234912157058716, 'eval_accuracy': 0.6026824978012313, 'eval_f1': 0.46219692656664096, 'eval_runtime': 3.0369, 'eval_samples_per_second': 1497.563, 'eval_steps_per_second': 93.845, 'epoch': 8.0}
{'train_runtime': 285.1697, 'train_samples_per_second': 1018.566, 'train_steps_per_second': 63.681, 'train_loss': 1.4224893040594024, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25  0 20 ... 27 17 27]
Metrics:
F1: 0.4712115857433065 
Accuracy: 0.6093681917211329
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.73      0.67       348
     amusement       0.74      0.88      0.80       186
         anger       0.51      0.40      0.45       131
     annoyance       0.40      0.20      0.27       194
      approval       0.53      0.35      0.42       236
        caring       0.45      0.35      0.39        86
     confusion       0.38      0.28      0.32        97
     curiosity       0.46      0.52      0.49       176
        desire       0.56      0.36      0.43        56
disappointment       0.45      0.16      0.24        88
   disapproval       0.44      0.31      0.36       195
       disgust       0.46      0.46      0.46        76
 embarrassment       0.53      0.39      0.45        23
    excitement       0.42      0.40      0.41        57
          fear       0.69      0.68      0.68        65
     gratitude       0.92      0.90      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.58      0.57        93
          love       0.75      0.88      0.81       160
   nervousness       0.67      0.50      0.57        12
      optimism       0.58      0.61      0.59       107
         pride       0.40      0.29      0.33         7
   realization       0.41      0.13      0.20        89
        relief       0.00      0.00      0.00         7
       remorse       0.60      0.77      0.67        44
       sadness       0.59      0.58      0.58       102
      surprise       0.46      0.37      0.41        87
       neutral       0.63      0.76      0.69      1606

      accuracy                           0.61      4590
     macro avg       0.51      0.46      0.47      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.33833237838297786, 0.37364688633306065, 0.3694520552992079, 0.4087030800628048, 0.3947235411668455, 0.4430544568506186, 0.43960009396714206, 0.46219692656664096, 0.4712115857433065]
Accuracies: [0.552990325417766, 0.5716798592788038, 0.5804749340369393, 0.5850923482849604, 0.5853122251539138, 0.5958663148636764, 0.5974054529463501, 0.6026824978012313, 0.6093681917211329]
Durations: [40.49839735031128, 76.04987382888794, 111.59731149673462, 147.10049676895142, 183.34183406829834, 219.16489005088806, 254.69725227355957, 290.19548892974854, 293.24277567863464]
Training Losses ( 8 ): [1.8342, 1.5693, 1.4902, 1.4193, 1.3584, 1.3026, 1.2383, 1.1676]
Validation Losses ( 8 ): [1.537731409072876, 1.5128542184829712, 1.419344186782837, 1.3903018236160278, 1.3968901634216309, 1.3527816534042358, 1.3396953344345093, 1.3234912157058716]
====  weight_decay :  0.2  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.2 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8397, 'grad_norm': 7.028056621551514, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6183427572250366, 'eval_accuracy': 0.5345206684256816, 'eval_f1': 0.3339977167403188, 'eval_runtime': 3.1213, 'eval_samples_per_second': 1457.069, 'eval_steps_per_second': 91.307, 'epoch': 1.0}
{'loss': 1.5944, 'grad_norm': 4.680171966552734, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5240840911865234, 'eval_accuracy': 0.570580474934037, 'eval_f1': 0.3690490415170686, 'eval_runtime': 3.0445, 'eval_samples_per_second': 1493.858, 'eval_steps_per_second': 93.612, 'epoch': 2.0}
{'loss': 1.5229, 'grad_norm': 5.33985710144043, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4468960762023926, 'eval_accuracy': 0.5758575197889182, 'eval_f1': 0.35030223533919747, 'eval_runtime': 3.046, 'eval_samples_per_second': 1493.13, 'eval_steps_per_second': 93.567, 'epoch': 3.0}
{'loss': 1.4559, 'grad_norm': 6.6767449378967285, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4323389530181885, 'eval_accuracy': 0.5813544415127528, 'eval_f1': 0.4037764504704128, 'eval_runtime': 3.0438, 'eval_samples_per_second': 1494.193, 'eval_steps_per_second': 93.633, 'epoch': 4.0}
{'loss': 1.4092, 'grad_norm': 7.14981746673584, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4144724607467651, 'eval_accuracy': 0.5795954265611257, 'eval_f1': 0.38057330449390164, 'eval_runtime': 3.0671, 'eval_samples_per_second': 1482.842, 'eval_steps_per_second': 92.922, 'epoch': 5.0}
{'loss': 1.3337, 'grad_norm': 8.222928047180176, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3536380529403687, 'eval_accuracy': 0.5976253298153035, 'eval_f1': 0.43712483476812963, 'eval_runtime': 3.0838, 'eval_samples_per_second': 1474.814, 'eval_steps_per_second': 92.419, 'epoch': 6.0}
{'loss': 1.2617, 'grad_norm': 5.442591667175293, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3296688795089722, 'eval_accuracy': 0.601363236587511, 'eval_f1': 0.4395410464411132, 'eval_runtime': 3.0442, 'eval_samples_per_second': 1493.986, 'eval_steps_per_second': 93.621, 'epoch': 7.0}
{'loss': 1.1771, 'grad_norm': 5.856396198272705, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3087158203125, 'eval_accuracy': 0.6083992963940194, 'eval_f1': 0.4640646996878102, 'eval_runtime': 3.0476, 'eval_samples_per_second': 1492.343, 'eval_steps_per_second': 93.518, 'epoch': 8.0}
{'train_runtime': 287.4602, 'train_samples_per_second': 1010.449, 'train_steps_per_second': 63.174, 'train_loss': 1.4493192294620731, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 20 ... 27 17 27]
Metrics:
F1: 0.4857393497774457 
Accuracy: 0.608714596949891
Final Report:
                 precision    recall  f1-score   support

    admiration       0.64      0.73      0.68       348
     amusement       0.76      0.87      0.81       186
         anger       0.50      0.43      0.46       131
     annoyance       0.38      0.20      0.26       194
      approval       0.54      0.33      0.41       236
        caring       0.50      0.42      0.46        86
     confusion       0.35      0.31      0.33        97
     curiosity       0.50      0.56      0.53       176
        desire       0.59      0.36      0.44        56
disappointment       0.36      0.19      0.25        88
   disapproval       0.43      0.31      0.36       195
       disgust       0.51      0.49      0.50        76
 embarrassment       0.53      0.43      0.48        23
    excitement       0.49      0.44      0.46        57
          fear       0.70      0.69      0.70        65
     gratitude       0.90      0.90      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.51      0.56      0.54        93
          love       0.73      0.88      0.80       160
   nervousness       0.54      0.58      0.56        12
      optimism       0.57      0.64      0.60       107
         pride       0.50      0.29      0.36         7
   realization       0.37      0.12      0.18        89
        relief       1.00      0.14      0.25         7
       remorse       0.58      0.75      0.65        44
       sadness       0.54      0.49      0.52       102
      surprise       0.49      0.40      0.44        87
       neutral       0.63      0.74      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.54      0.47      0.49      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3339977167403188, 0.3690490415170686, 0.35030223533919747, 0.4037764504704128, 0.38057330449390164, 0.43712483476812963, 0.4395410464411132, 0.4640646996878102, 0.4857393497774457]
Accuracies: [0.5345206684256816, 0.570580474934037, 0.5758575197889182, 0.5813544415127528, 0.5795954265611257, 0.5976253298153035, 0.601363236587511, 0.6083992963940194, 0.608714596949891]
Durations: [40.06605935096741, 75.93718242645264, 111.5677535533905, 147.12963962554932, 182.74874901771545, 219.6889009475708, 255.51830339431763, 291.1296896934509, 294.18252396583557]
Training Losses ( 8 ): [1.8397, 1.5944, 1.5229, 1.4559, 1.4092, 1.3337, 1.2617, 1.1771]
Validation Losses ( 8 ): [1.6183427572250366, 1.5240840911865234, 1.4468960762023926, 1.4323389530181885, 1.4144724607467651, 1.3536380529403687, 1.3296688795089722, 1.3087158203125]
====  weight_decay :  0.3  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.3 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8509, 'grad_norm': 13.448050498962402, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.5768451690673828, 'eval_accuracy': 0.5538698328935796, 'eval_f1': 0.33780054970523704, 'eval_runtime': 3.036, 'eval_samples_per_second': 1498.006, 'eval_steps_per_second': 93.872, 'epoch': 1.0}
{'loss': 1.6197, 'grad_norm': 5.439615249633789, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5415165424346924, 'eval_accuracy': 0.5602462620932278, 'eval_f1': 0.3618096761646245, 'eval_runtime': 3.0358, 'eval_samples_per_second': 1498.124, 'eval_steps_per_second': 93.88, 'epoch': 2.0}
{'loss': 1.5457, 'grad_norm': 4.993271350860596, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.4506884813308716, 'eval_accuracy': 0.5675021987686896, 'eval_f1': 0.333562663375566, 'eval_runtime': 3.0363, 'eval_samples_per_second': 1497.893, 'eval_steps_per_second': 93.865, 'epoch': 3.0}
{'loss': 1.4778, 'grad_norm': 2.8941192626953125, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.443627119064331, 'eval_accuracy': 0.5782761653474054, 'eval_f1': 0.3978292875690075, 'eval_runtime': 3.0371, 'eval_samples_per_second': 1497.506, 'eval_steps_per_second': 93.841, 'epoch': 4.0}
{'loss': 1.4215, 'grad_norm': 7.868800640106201, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4047640562057495, 'eval_accuracy': 0.5824538258575198, 'eval_f1': 0.3825378388114494, 'eval_runtime': 3.0396, 'eval_samples_per_second': 1496.226, 'eval_steps_per_second': 93.761, 'epoch': 5.0}
{'loss': 1.3431, 'grad_norm': 6.900140285491943, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3614763021469116, 'eval_accuracy': 0.5949868073878628, 'eval_f1': 0.4405476569224972, 'eval_runtime': 3.0364, 'eval_samples_per_second': 1497.806, 'eval_steps_per_second': 93.86, 'epoch': 6.0}
{'loss': 1.258, 'grad_norm': 5.591583728790283, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3258472681045532, 'eval_accuracy': 0.5974054529463501, 'eval_f1': 0.43263165890386773, 'eval_runtime': 3.0407, 'eval_samples_per_second': 1495.719, 'eval_steps_per_second': 93.729, 'epoch': 7.0}
{'loss': 1.1575, 'grad_norm': 6.325421333312988, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3036774396896362, 'eval_accuracy': 0.6044415127528584, 'eval_f1': 0.4566726493225866, 'eval_runtime': 3.0384, 'eval_samples_per_second': 1496.863, 'eval_steps_per_second': 93.801, 'epoch': 8.0}
{'train_runtime': 284.3124, 'train_samples_per_second': 1021.637, 'train_steps_per_second': 63.873, 'train_loss': 1.4592846975452574, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 20 ... 27  0 27]
Metrics:
F1: 0.4764775373091536 
Accuracy: 0.6061002178649237
Final Report:
                 precision    recall  f1-score   support

    admiration       0.65      0.73      0.68       348
     amusement       0.74      0.88      0.80       186
         anger       0.49      0.42      0.45       131
     annoyance       0.30      0.15      0.20       194
      approval       0.50      0.34      0.41       236
        caring       0.53      0.45      0.49        86
     confusion       0.40      0.37      0.39        97
     curiosity       0.45      0.50      0.47       176
        desire       0.63      0.43      0.51        56
disappointment       0.42      0.22      0.29        88
   disapproval       0.41      0.33      0.37       195
       disgust       0.45      0.46      0.45        76
 embarrassment       0.50      0.43      0.47        23
    excitement       0.50      0.44      0.47        57
          fear       0.61      0.71      0.65        65
     gratitude       0.91      0.91      0.91       260
         grief       0.00      0.00      0.00         2
           joy       0.57      0.59      0.58        93
          love       0.74      0.91      0.82       160
   nervousness       0.50      0.50      0.50        12
      optimism       0.61      0.64      0.62       107
         pride       0.40      0.29      0.33         7
   realization       0.34      0.12      0.18        89
        relief       0.00      0.00      0.00         7
       remorse       0.58      0.77      0.66        44
       sadness       0.57      0.54      0.56       102
      surprise       0.44      0.36      0.39        87
       neutral       0.63      0.73      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.50      0.47      0.48      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.33780054970523704, 0.3618096761646245, 0.333562663375566, 0.3978292875690075, 0.3825378388114494, 0.4405476569224972, 0.43263165890386773, 0.4566726493225866, 0.4764775373091536]
Accuracies: [0.5538698328935796, 0.5602462620932278, 0.5675021987686896, 0.5782761653474054, 0.5824538258575198, 0.5949868073878628, 0.5974054529463501, 0.6044415127528584, 0.6061002178649237]
Durations: [40.54390811920166, 76.07585382461548, 111.63937664031982, 147.13799476623535, 182.6610713005066, 218.18557500839233, 253.7353880405426, 289.2749590873718, 292.3174343109131]
Training Losses ( 8 ): [1.8509, 1.6197, 1.5457, 1.4778, 1.4215, 1.3431, 1.258, 1.1575]
Validation Losses ( 8 ): [1.5768451690673828, 1.5415165424346924, 1.4506884813308716, 1.443627119064331, 1.4047640562057495, 1.3614763021469116, 1.3258472681045532, 1.3036774396896362]
====  weight_decay :  0.4  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.4 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8553, 'grad_norm': 7.904767036437988, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6045042276382446, 'eval_accuracy': 0.544415127528584, 'eval_f1': 0.3313276213798169, 'eval_runtime': 3.0439, 'eval_samples_per_second': 1494.126, 'eval_steps_per_second': 93.629, 'epoch': 1.0}
{'loss': 1.6347, 'grad_norm': 4.747283935546875, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.5677902698516846, 'eval_accuracy': 0.5560686015831134, 'eval_f1': 0.3473303371061724, 'eval_runtime': 3.0548, 'eval_samples_per_second': 1488.81, 'eval_steps_per_second': 93.296, 'epoch': 2.0}
{'loss': 1.5751, 'grad_norm': 5.889585494995117, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.510063886642456, 'eval_accuracy': 0.5620052770448549, 'eval_f1': 0.3254059718134778, 'eval_runtime': 3.0448, 'eval_samples_per_second': 1493.713, 'eval_steps_per_second': 93.603, 'epoch': 3.0}
{'loss': 1.4989, 'grad_norm': 4.421504974365234, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4434915781021118, 'eval_accuracy': 0.5846525945470537, 'eval_f1': 0.39127331839755203, 'eval_runtime': 3.051, 'eval_samples_per_second': 1490.678, 'eval_steps_per_second': 93.413, 'epoch': 4.0}
{'loss': 1.4438, 'grad_norm': 7.527878284454346, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4240443706512451, 'eval_accuracy': 0.580255057167986, 'eval_f1': 0.3939606671899738, 'eval_runtime': 3.05, 'eval_samples_per_second': 1491.154, 'eval_steps_per_second': 93.443, 'epoch': 5.0}
{'loss': 1.3629, 'grad_norm': 6.078843116760254, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3769277334213257, 'eval_accuracy': 0.5857519788918206, 'eval_f1': 0.42668312846354217, 'eval_runtime': 3.1038, 'eval_samples_per_second': 1465.298, 'eval_steps_per_second': 91.823, 'epoch': 6.0}
{'loss': 1.278, 'grad_norm': 7.7963762283325195, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.336856722831726, 'eval_accuracy': 0.5996042216358839, 'eval_f1': 0.4422579943888148, 'eval_runtime': 3.106, 'eval_samples_per_second': 1464.257, 'eval_steps_per_second': 91.758, 'epoch': 7.0}
{'loss': 1.1687, 'grad_norm': 6.5010085105896, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.316495656967163, 'eval_accuracy': 0.605321020228672, 'eval_f1': 0.4623586261249315, 'eval_runtime': 3.1137, 'eval_samples_per_second': 1460.655, 'eval_steps_per_second': 91.532, 'epoch': 8.0}
{'train_runtime': 288.0661, 'train_samples_per_second': 1008.324, 'train_steps_per_second': 63.041, 'train_loss': 1.477194496188395, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 20 ... 27  0 27]
Metrics:
F1: 0.47156217376895 
Accuracy: 0.6089324618736384
Final Report:
                 precision    recall  f1-score   support

    admiration       0.62      0.76      0.68       348
     amusement       0.75      0.88      0.81       186
         anger       0.52      0.44      0.47       131
     annoyance       0.36      0.19      0.24       194
      approval       0.53      0.33      0.40       236
        caring       0.48      0.43      0.45        86
     confusion       0.40      0.35      0.37        97
     curiosity       0.48      0.56      0.52       176
        desire       0.59      0.39      0.47        56
disappointment       0.39      0.20      0.27        88
   disapproval       0.42      0.37      0.39       195
       disgust       0.44      0.46      0.45        76
 embarrassment       0.50      0.43      0.47        23
    excitement       0.49      0.40      0.44        57
          fear       0.62      0.68      0.65        65
     gratitude       0.89      0.89      0.89       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.58      0.57        93
          love       0.74      0.91      0.82       160
   nervousness       0.58      0.58      0.58        12
      optimism       0.60      0.61      0.60       107
         pride       1.00      0.14      0.25         7
   realization       0.37      0.08      0.13        89
        relief       0.00      0.00      0.00         7
       remorse       0.59      0.73      0.65        44
       sadness       0.55      0.53      0.54       102
      surprise       0.45      0.36      0.40        87
       neutral       0.64      0.73      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.52      0.46      0.47      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3313276213798169, 0.3473303371061724, 0.3254059718134778, 0.39127331839755203, 0.3939606671899738, 0.42668312846354217, 0.4422579943888148, 0.4623586261249315, 0.47156217376895]
Accuracies: [0.544415127528584, 0.5560686015831134, 0.5620052770448549, 0.5846525945470537, 0.580255057167986, 0.5857519788918206, 0.5996042216358839, 0.605321020228672, 0.6089324618736384]
Durations: [39.11334037780762, 74.73622798919678, 110.44215202331543, 146.0884871482849, 181.7451732158661, 218.27551937103271, 255.0097177028656, 291.66118335723877, 294.7652997970581]
Training Losses ( 8 ): [1.8553, 1.6347, 1.5751, 1.4989, 1.4438, 1.3629, 1.278, 1.1687]
Validation Losses ( 8 ): [1.6045042276382446, 1.5677902698516846, 1.510063886642456, 1.4434915781021118, 1.4240443706512451, 1.3769277334213257, 1.336856722831726, 1.316495656967163]
====  weight_decay :  0.5  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.5 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8688, 'grad_norm': 6.314305305480957, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6077311038970947, 'eval_accuracy': 0.5371591908531222, 'eval_f1': 0.3170902344787108, 'eval_runtime': 3.0938, 'eval_samples_per_second': 1470.046, 'eval_steps_per_second': 92.12, 'epoch': 1.0}
{'loss': 1.6487, 'grad_norm': 6.24553108215332, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.6145423650741577, 'eval_accuracy': 0.552990325417766, 'eval_f1': 0.32453643960669265, 'eval_runtime': 3.1036, 'eval_samples_per_second': 1465.382, 'eval_steps_per_second': 91.828, 'epoch': 2.0}
{'loss': 1.5869, 'grad_norm': 5.339900016784668, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.484167218208313, 'eval_accuracy': 0.5729991204925242, 'eval_f1': 0.34249025570892344, 'eval_runtime': 3.1091, 'eval_samples_per_second': 1462.794, 'eval_steps_per_second': 91.666, 'epoch': 3.0}
{'loss': 1.5195, 'grad_norm': 4.064177989959717, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.486251950263977, 'eval_accuracy': 0.5743183817062445, 'eval_f1': 0.37246668030950075, 'eval_runtime': 3.0946, 'eval_samples_per_second': 1469.658, 'eval_steps_per_second': 92.096, 'epoch': 4.0}
{'loss': 1.4594, 'grad_norm': 8.595508575439453, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4446781873703003, 'eval_accuracy': 0.56948109058927, 'eval_f1': 0.37681715179516445, 'eval_runtime': 3.0937, 'eval_samples_per_second': 1470.089, 'eval_steps_per_second': 92.123, 'epoch': 5.0}
{'loss': 1.3864, 'grad_norm': 7.36777925491333, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3630479574203491, 'eval_accuracy': 0.5982849604221636, 'eval_f1': 0.44141740852721384, 'eval_runtime': 3.1051, 'eval_samples_per_second': 1464.688, 'eval_steps_per_second': 91.785, 'epoch': 6.0}
{'loss': 1.3004, 'grad_norm': 8.040124893188477, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.330742597579956, 'eval_accuracy': 0.6011433597185576, 'eval_f1': 0.4337121790730062, 'eval_runtime': 3.1073, 'eval_samples_per_second': 1463.649, 'eval_steps_per_second': 91.719, 'epoch': 7.0}
{'loss': 1.1924, 'grad_norm': 7.433070659637451, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.3015162944793701, 'eval_accuracy': 0.6077396657871592, 'eval_f1': 0.44536613925211604, 'eval_runtime': 3.09, 'eval_samples_per_second': 1471.831, 'eval_steps_per_second': 92.232, 'epoch': 8.0}
{'train_runtime': 292.3559, 'train_samples_per_second': 993.529, 'train_steps_per_second': 62.116, 'train_loss': 1.4953138443867016, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [24 14 20 ... 27  0 27]
Metrics:
F1: 0.4761536358391151 
Accuracy: 0.6067538126361656
Final Report:
                 precision    recall  f1-score   support

    admiration       0.63      0.75      0.68       348
     amusement       0.76      0.88      0.81       186
         anger       0.50      0.42      0.46       131
     annoyance       0.27      0.14      0.18       194
      approval       0.52      0.33      0.40       236
        caring       0.53      0.50      0.51        86
     confusion       0.40      0.37      0.39        97
     curiosity       0.44      0.55      0.49       176
        desire       0.66      0.41      0.51        56
disappointment       0.40      0.24      0.30        88
   disapproval       0.40      0.33      0.36       195
       disgust       0.44      0.47      0.46        76
 embarrassment       0.48      0.43      0.45        23
    excitement       0.48      0.40      0.44        57
          fear       0.67      0.68      0.67        65
     gratitude       0.90      0.90      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.58      0.56        93
          love       0.72      0.89      0.80       160
   nervousness       0.38      0.42      0.40        12
      optimism       0.62      0.62      0.62       107
         pride       1.00      0.14      0.25         7
   realization       0.28      0.08      0.12        89
        relief       1.00      0.14      0.25         7
       remorse       0.60      0.77      0.67        44
       sadness       0.59      0.47      0.52       102
      surprise       0.49      0.38      0.43        87
       neutral       0.64      0.73      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.55      0.47      0.48      4590
  weighted avg       0.59      0.61      0.59      4590

F1 scores: [0.3170902344787108, 0.32453643960669265, 0.34249025570892344, 0.37246668030950075, 0.37681715179516445, 0.44141740852721384, 0.4337121790730062, 0.44536613925211604, 0.4761536358391151]
Accuracies: [0.5371591908531222, 0.552990325417766, 0.5729991204925242, 0.5743183817062445, 0.56948109058927, 0.5982849604221636, 0.6011433597185576, 0.6077396657871592, 0.6067538126361656]
Durations: [40.31799125671387, 76.95767998695374, 113.53718066215515, 149.95997262001038, 186.40696477890015, 222.90436935424805, 259.4478614330292, 296.18948125839233, 299.29353737831116]
Training Losses ( 8 ): [1.8688, 1.6487, 1.5869, 1.5195, 1.4594, 1.3864, 1.3004, 1.1924]
Validation Losses ( 8 ): [1.6077311038970947, 1.6145423650741577, 1.484167218208313, 1.486251950263977, 1.4446781873703003, 1.3630479574203491, 1.330742597579956, 1.3015162944793701]
====  weight_decay :  0.6  ====
Learning rate: 0.001 
Num epochs: 8 
Batch size: 16 
Weight decay: 0.6 
Warmup steps: 500
Loading model
Device: cuda
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8655, 'grad_norm': 9.361448287963867, 'learning_rate': 0.0008997734994337487, 'epoch': 1.0}
{'eval_loss': 1.6632208824157715, 'eval_accuracy': 0.5226473175021987, 'eval_f1': 0.29419230037728367, 'eval_runtime': 3.1278, 'eval_samples_per_second': 1454.072, 'eval_steps_per_second': 91.119, 'epoch': 1.0}
{'loss': 1.6634, 'grad_norm': 5.905492782592773, 'learning_rate': 0.0007712344280860703, 'epoch': 2.0}
{'eval_loss': 1.604275107383728, 'eval_accuracy': 0.5503518029903254, 'eval_f1': 0.31357502457605024, 'eval_runtime': 3.1102, 'eval_samples_per_second': 1462.284, 'eval_steps_per_second': 91.634, 'epoch': 2.0}
{'loss': 1.6048, 'grad_norm': 6.131109714508057, 'learning_rate': 0.0006426953567383919, 'epoch': 3.0}
{'eval_loss': 1.521633505821228, 'eval_accuracy': 0.5620052770448549, 'eval_f1': 0.3243234669937297, 'eval_runtime': 3.1329, 'eval_samples_per_second': 1451.688, 'eval_steps_per_second': 90.97, 'epoch': 3.0}
{'loss': 1.5318, 'grad_norm': 4.116964817047119, 'learning_rate': 0.0005141562853907134, 'epoch': 4.0}
{'eval_loss': 1.4890815019607544, 'eval_accuracy': 0.56948109058927, 'eval_f1': 0.3725252589246711, 'eval_runtime': 3.1112, 'eval_samples_per_second': 1461.801, 'eval_steps_per_second': 91.604, 'epoch': 4.0}
{'loss': 1.4722, 'grad_norm': 8.543816566467285, 'learning_rate': 0.00038561721404303513, 'epoch': 5.0}
{'eval_loss': 1.4323822259902954, 'eval_accuracy': 0.5734388742304309, 'eval_f1': 0.3749015233325107, 'eval_runtime': 3.113, 'eval_samples_per_second': 1460.951, 'eval_steps_per_second': 91.55, 'epoch': 5.0}
{'loss': 1.3995, 'grad_norm': 7.123642921447754, 'learning_rate': 0.0002570781426953567, 'epoch': 6.0}
{'eval_loss': 1.3647994995117188, 'eval_accuracy': 0.5943271767810027, 'eval_f1': 0.43068065744035533, 'eval_runtime': 3.1112, 'eval_samples_per_second': 1461.807, 'eval_steps_per_second': 91.604, 'epoch': 6.0}
{'loss': 1.3134, 'grad_norm': 5.859578609466553, 'learning_rate': 0.00012853907134767836, 'epoch': 7.0}
{'eval_loss': 1.3238250017166138, 'eval_accuracy': 0.6029023746701847, 'eval_f1': 0.43394348812660555, 'eval_runtime': 3.1147, 'eval_samples_per_second': 1460.149, 'eval_steps_per_second': 91.5, 'epoch': 7.0}
{'loss': 1.2072, 'grad_norm': 6.67758846282959, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.29095458984375, 'eval_accuracy': 0.6105980650835532, 'eval_f1': 0.4537030892578714, 'eval_runtime': 3.1085, 'eval_samples_per_second': 1463.066, 'eval_steps_per_second': 91.683, 'epoch': 8.0}
{'train_runtime': 294.5663, 'train_samples_per_second': 986.073, 'train_steps_per_second': 61.65, 'train_loss': 1.5072324643576198, 'epoch': 8.0}
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 17 ... 27  0 27]
Metrics:
F1: 0.4856695008133827 
Accuracy: 0.611764705882353
Final Report:
                 precision    recall  f1-score   support

    admiration       0.62      0.75      0.68       348
     amusement       0.77      0.89      0.83       186
         anger       0.53      0.44      0.48       131
     annoyance       0.33      0.17      0.22       194
      approval       0.51      0.32      0.39       236
        caring       0.50      0.41      0.45        86
     confusion       0.41      0.38      0.40        97
     curiosity       0.48      0.60      0.53       176
        desire       0.54      0.38      0.44        56
disappointment       0.37      0.22      0.27        88
   disapproval       0.41      0.31      0.35       195
       disgust       0.47      0.50      0.49        76
 embarrassment       0.56      0.43      0.49        23
    excitement       0.52      0.44      0.48        57
          fear       0.66      0.69      0.68        65
     gratitude       0.91      0.90      0.90       260
         grief       0.00      0.00      0.00         2
           joy       0.55      0.57      0.56        93
          love       0.74      0.91      0.81       160
   nervousness       0.56      0.42      0.48        12
      optimism       0.59      0.64      0.61       107
         pride       1.00      0.14      0.25         7
   realization       0.54      0.16      0.24        89
        relief       1.00      0.14      0.25         7
       remorse       0.60      0.80      0.69        44
       sadness       0.55      0.50      0.52       102
      surprise       0.48      0.38      0.42        87
       neutral       0.64      0.73      0.68      1606

      accuracy                           0.61      4590
     macro avg       0.57      0.47      0.49      4590
  weighted avg       0.60      0.61      0.59      4590

F1 scores: [0.29419230037728367, 0.31357502457605024, 0.3243234669937297, 0.3725252589246711, 0.3749015233325107, 0.43068065744035533, 0.43394348812660555, 0.4537030892578714, 0.4856695008133827]
Accuracies: [0.5226473175021987, 0.5503518029903254, 0.5620052770448549, 0.56948109058927, 0.5734388742304309, 0.5943271767810027, 0.6029023746701847, 0.6105980650835532, 0.611764705882353]
Durations: [37.96385216712952, 74.95767092704773, 112.00519609451294, 148.6684126853943, 185.33203887939453, 221.98317074775696, 258.9158811569214, 295.8430676460266, 298.9502213001251]
Training Losses ( 8 ): [1.8655, 1.6634, 1.6048, 1.5318, 1.4722, 1.3995, 1.3134, 1.2072]
Validation Losses ( 8 ): [1.6632208824157715, 1.604275107383728, 1.521633505821228, 1.4890815019607544, 1.4323822259902954, 1.3647994995117188, 1.3238250017166138, 1.29095458984375]
Graphs saved to disk
