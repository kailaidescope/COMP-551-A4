Starting BERT epoch experiments script
Train method: full
Learning rate: 2e-05 
Num epochs: 8 
Batch size: 32 
Weight decay: 1 
Warmup steps: 500
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])  - Requires grad: True
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])  - Requires grad: True
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])  - Requires grad: True
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.pooler.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: classifier.weight  - Size: torch.Size([28, 768])  - Requires grad: True
Name: classifier.bias  - Size: torch.Size([28])  - Requires grad: True
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.9547, 'grad_norm': 9.156770706176758, 'learning_rate': 1.8519813519813522e-05, 'epoch': 1.0}
{'eval_loss': 1.3516144752502441, 'eval_accuracy': 0.6112576956904133, 'eval_f1': 0.4093317022924049, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.81      0.72       326\n     amusement       0.70      0.88      0.78       208\n         anger       0.40      0.63      0.49       109\n     annoyance       0.35      0.16      0.22       164\n      approval       0.51      0.22      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.59      0.29      0.39       102\n     curiosity       0.46      0.62      0.53       164\n        desire       0.79      0.42      0.55        52\ndisappointment       0.33      0.08      0.12        91\n   disapproval       0.46      0.20      0.28       212\n       disgust       0.58      0.34      0.43        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.86      0.12      0.20        52\n          fear       0.63      0.55      0.59        58\n     gratitude       0.96      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.53      0.58       106\n          love       0.70      0.89      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.56      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.88      0.74        40\n       sadness       0.54      0.57      0.55        84\n      surprise       0.48      0.55      0.51        95\n       neutral       0.60      0.78      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.40      0.41      4548\n  weighted avg       0.60      0.61      0.58      4548\n', 'eval_runtime': 3.0501, 'eval_samples_per_second': 1491.114, 'eval_steps_per_second': 46.884, 'epoch': 1.0}
{'loss': 1.2421, 'grad_norm': 10.479072570800781, 'learning_rate': 1.5874125874125875e-05, 'epoch': 2.0}
{'eval_loss': 1.263283610343933, 'eval_accuracy': 0.6323658751099385, 'eval_f1': 0.4745209967970227, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.71      0.79      0.74       326\n     amusement       0.74      0.88      0.80       208\n         anger       0.49      0.61      0.55       109\n     annoyance       0.32      0.24      0.27       164\n      approval       0.64      0.19      0.29       258\n        caring       0.65      0.31      0.42        96\n     confusion       0.57      0.32      0.41       102\n     curiosity       0.46      0.70      0.55       164\n        desire       0.74      0.44      0.55        52\ndisappointment       0.36      0.16      0.23        91\n   disapproval       0.48      0.36      0.41       212\n       disgust       0.53      0.49      0.51        61\n embarrassment       0.65      0.55      0.59        20\n    excitement       0.52      0.23      0.32        52\n          fear       0.68      0.81      0.74        58\n     gratitude       0.95      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.55      0.60       106\n          love       0.69      0.91      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.71      0.58      0.64       119\n         pride       0.00      0.00      0.00         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.66      0.93      0.77        40\n       sadness       0.56      0.55      0.55        84\n      surprise       0.56      0.66      0.61        95\n       neutral       0.63      0.76      0.69      1592\n\n      accuracy                           0.63      4548\n     macro avg       0.53      0.47      0.47      4548\n  weighted avg       0.63      0.63      0.61      4548\n', 'eval_runtime': 3.0937, 'eval_samples_per_second': 1470.085, 'eval_steps_per_second': 46.223, 'epoch': 2.0}
{'loss': 1.0205, 'grad_norm': 13.909720420837402, 'learning_rate': 1.3228438228438229e-05, 'epoch': 3.0}
{'eval_loss': 1.267223834991455, 'eval_accuracy': 0.6207124010554089, 'eval_f1': 0.4704927685575538, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.83      0.75       326\n     amusement       0.75      0.86      0.80       208\n         anger       0.45      0.60      0.51       109\n     annoyance       0.39      0.26      0.31       164\n      approval       0.47      0.30      0.37       258\n        caring       0.52      0.45      0.48        96\n     confusion       0.47      0.31      0.38       102\n     curiosity       0.46      0.56      0.50       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.47      0.23      0.31        91\n   disapproval       0.47      0.30      0.37       212\n       disgust       0.58      0.54      0.56        61\n embarrassment       0.80      0.40      0.53        20\n    excitement       0.27      0.42      0.33        52\n          fear       0.72      0.62      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.68      0.55      0.61       106\n          love       0.76      0.84      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.59      0.64      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.53      0.22      0.31        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.75      0.70        40\n       sadness       0.57      0.58      0.58        84\n      surprise       0.55      0.56      0.55        95\n       neutral       0.64      0.72      0.68      1592\n\n      accuracy                           0.62      4548\n     macro avg       0.50      0.46      0.47      4548\n  weighted avg       0.61      0.62      0.61      4548\n', 'eval_runtime': 3.0959, 'eval_samples_per_second': 1469.057, 'eval_steps_per_second': 46.191, 'epoch': 3.0}
{'loss': 0.8249, 'grad_norm': 7.5537214279174805, 'learning_rate': 1.0582750582750583e-05, 'epoch': 4.0}
{'eval_loss': 1.3819111585617065, 'eval_accuracy': 0.613896218117854, 'eval_f1': 0.48897467578558923, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.82      0.73       326\n     amusement       0.77      0.83      0.80       208\n         anger       0.58      0.50      0.54       109\n     annoyance       0.37      0.33      0.35       164\n      approval       0.45      0.35      0.39       258\n        caring       0.52      0.49      0.51        96\n     confusion       0.47      0.32      0.38       102\n     curiosity       0.45      0.58      0.51       164\n        desire       0.56      0.56      0.56        52\ndisappointment       0.40      0.35      0.37        91\n   disapproval       0.36      0.37      0.36       212\n       disgust       0.39      0.56      0.46        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.27      0.37      0.31        52\n          fear       0.68      0.72      0.70        58\n     gratitude       0.94      0.91      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.52      0.58       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.61      0.58      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       0.71      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.70      0.68        40\n       sadness       0.51      0.62      0.56        84\n      surprise       0.51      0.61      0.56        95\n       neutral       0.68      0.67      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.50      0.49      4548\n  weighted avg       0.61      0.61      0.61      4548\n', 'eval_runtime': 3.098, 'eval_samples_per_second': 1468.022, 'eval_steps_per_second': 46.158, 'epoch': 4.0}
{'loss': 0.651, 'grad_norm': 11.947890281677246, 'learning_rate': 7.937062937062937e-06, 'epoch': 5.0}
{'eval_loss': 1.467684268951416, 'eval_accuracy': 0.6031222515391381, 'eval_f1': 0.48198481548184635, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.65      0.84      0.73       326\n     amusement       0.74      0.80      0.77       208\n         anger       0.46      0.61      0.52       109\n     annoyance       0.34      0.35      0.35       164\n      approval       0.43      0.34      0.38       258\n        caring       0.48      0.51      0.49        96\n     confusion       0.46      0.31      0.37       102\n     curiosity       0.47      0.51      0.49       164\n        desire       0.62      0.54      0.58        52\ndisappointment       0.36      0.29      0.32        91\n   disapproval       0.36      0.37      0.37       212\n       disgust       0.46      0.51      0.48        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.36      0.29      0.32        52\n          fear       0.73      0.66      0.69        58\n     gratitude       0.90      0.92      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.73      0.83      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.65      0.55      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.48      0.22      0.30        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.65      0.65        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.53      0.55      0.54        95\n       neutral       0.66      0.65      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.49      0.48      0.48      4548\n  weighted avg       0.60      0.60      0.60      4548\n', 'eval_runtime': 3.1081, 'eval_samples_per_second': 1463.269, 'eval_steps_per_second': 46.009, 'epoch': 5.0}
{'loss': 0.5137, 'grad_norm': 13.049745559692383, 'learning_rate': 5.291375291375292e-06, 'epoch': 6.0}
{'eval_loss': 1.6141308546066284, 'eval_accuracy': 0.5976253298153035, 'eval_f1': 0.4911742275663733, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.80      0.73       326\n     amusement       0.71      0.85      0.77       208\n         anger       0.48      0.57      0.52       109\n     annoyance       0.31      0.35      0.33       164\n      approval       0.41      0.36      0.38       258\n        caring       0.49      0.49      0.49        96\n     confusion       0.38      0.37      0.37       102\n     curiosity       0.46      0.54      0.49       164\n        desire       0.58      0.54      0.56        52\ndisappointment       0.35      0.32      0.33        91\n   disapproval       0.37      0.30      0.33       212\n       disgust       0.45      0.52      0.48        61\n embarrassment       0.55      0.55      0.55        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.67      0.67      0.67        58\n     gratitude       0.93      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.56      0.60       106\n          love       0.71      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.67      0.59      0.63       119\n         pride       1.00      0.22      0.36         9\n   realization       0.32      0.23      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.65      0.63        40\n       sadness       0.49      0.64      0.56        84\n      surprise       0.52      0.58      0.55        95\n       neutral       0.68      0.63      0.65      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.50      0.49      4548\n  weighted avg       0.60      0.60      0.59      4548\n', 'eval_runtime': 3.0865, 'eval_samples_per_second': 1473.533, 'eval_steps_per_second': 46.331, 'epoch': 6.0}
{'loss': 0.4108, 'grad_norm': 10.576498031616211, 'learning_rate': 2.645687645687646e-06, 'epoch': 7.0}
{'eval_loss': 1.7132115364074707, 'eval_accuracy': 0.5872911169744943, 'eval_f1': 0.4794594039356178, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.79      0.72       326\n     amusement       0.73      0.84      0.78       208\n         anger       0.50      0.57      0.53       109\n     annoyance       0.33      0.41      0.36       164\n      approval       0.37      0.38      0.37       258\n        caring       0.46      0.46      0.46        96\n     confusion       0.40      0.35      0.37       102\n     curiosity       0.45      0.46      0.46       164\n        desire       0.52      0.54      0.53        52\ndisappointment       0.32      0.25      0.28        91\n   disapproval       0.37      0.34      0.35       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.69      0.66      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.53      0.56       106\n          love       0.70      0.85      0.77       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.62      0.60      0.61       119\n         pride       1.00      0.11      0.20         9\n   realization       0.28      0.24      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.61      0.70      0.65        40\n       sadness       0.48      0.64      0.55        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.67      0.61      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.48      4548\n  weighted avg       0.59      0.59      0.58      4548\n', 'eval_runtime': 3.085, 'eval_samples_per_second': 1474.222, 'eval_steps_per_second': 46.353, 'epoch': 7.0}
{'loss': 0.3439, 'grad_norm': 12.520172119140625, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.7583812475204468, 'eval_accuracy': 0.5914687774846086, 'eval_f1': 0.48714627768893043, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.73      0.85      0.78       208\n         anger       0.51      0.56      0.54       109\n     annoyance       0.31      0.41      0.35       164\n      approval       0.38      0.36      0.37       258\n        caring       0.48      0.50      0.49        96\n     confusion       0.39      0.34      0.37       102\n     curiosity       0.46      0.49      0.47       164\n        desire       0.53      0.54      0.53        52\ndisappointment       0.34      0.30      0.32        91\n   disapproval       0.36      0.33      0.34       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.28      0.29      0.28        52\n          fear       0.71      0.64      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.63      0.53      0.57       106\n          love       0.72      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.59      0.59      0.59       119\n         pride       1.00      0.22      0.36         9\n   realization       0.27      0.22      0.24        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.65      0.64        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.52      0.56      0.54        95\n       neutral       0.67      0.62      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.49      4548\n  weighted avg       0.59      0.59      0.59      4548\n', 'eval_runtime': 3.1401, 'eval_samples_per_second': 1448.352, 'eval_steps_per_second': 45.54, 'epoch': 8.0}
{'train_runtime': 723.8339, 'train_samples_per_second': 401.285, 'train_steps_per_second': 12.544, 'train_loss': 0.8702042398998916, 'epoch': 8.0}
Saving all layers
Gathered layers to save.
Layer weights saved.
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25  0 20 ... 27  0 27]
[1615, 'Thank you for your service', 'gratitude', 'gratitude']
[2529, "We already had that fake news before. There's no such discussion.", 'disapproval', 'disapproval']
[3174, '[NAME] x [NAME] sounds cute for some reason.', 'admiration', 'admiration']
[23, "What's your source for that? Just curious (and yes I know it sounds like a tired contrarian statement).", 'curiosity', 'curiosity']
[4586, 'Well that makes sense.', 'approval', 'approval']
[1745, 'You still didn’t answer the question. Sorry it’s bugging me :)', 'remorse', 'remorse']
[1047, "You conveniently aren't speaking to my assertion.", 'neutral', 'neutral']
[2031, "This hits hard, sadly both of my relationships have been toxic so I've decided not to start any new ones until I start going to uni ", 'sadness', 'sadness']
[354, 'Sorry your right', 'remorse', 'remorse']
[2034, 'SHE SHOULD BE ON A HILL SOMEWHERE WITH THE SUN AND THE CLOUDS ABOVE HER!', 'neutral', 'neutral']
[2963, "Deep down you know pain is temporary and you'll do it all over again the next weekend", 'neutral', 'caring']
[644, "I swear to [NAME], I'm going to approach you. Instead of running away, I'll come right to you.", 'neutral', 'caring']
[745, 'Yeah I wish they could just finish 9th every year in the conference', 'optimism', 'desire']
[1863, 'I do not trust our defense at all. I do not believe you can increase the range of Andujar.', 'surprise', 'disapproval']
[1150, 'Difficult to see how this video wouldn’t have been much more interesting if properly shot in landscape.', 'disapproval', 'confusion']
[2475, 'For the people and finding out how they end up? Sure. Other than that, it’s not great. Frustrating at best. ', 'anger', 'disapproval']
[2788, 'RIGHT?! My mom would literally never forgive the bitch 😂', 'amusement', 'anger']
[1376, 'At my job I can/Do get laid a lot so the second one!!', 'approval', 'neutral']
[3261, "I wouldn't say age would stop it just lessen the affect of it but probably start to notice it around mid to late 30's.", 'realization', 'neutral']
[3143, "Good luck for everyone pronouncing [NAME] name. If he keeps scoring like this, i'll have fun listening some commentators around NHL.", 'gratitude', 'joy']
Correct Instances:  [[1615, 'Thank you for your service', 'gratitude', 'gratitude'], [2529, "We already had that fake news before. There's no such discussion.", 'disapproval', 'disapproval'], [3174, '[NAME] x [NAME] sounds cute for some reason.', 'admiration', 'admiration'], [23, "What's your source for that? Just curious (and yes I know it sounds like a tired contrarian statement).", 'curiosity', 'curiosity'], [4586, 'Well that makes sense.', 'approval', 'approval'], [1745, 'You still didn’t answer the question. Sorry it’s bugging me :)', 'remorse', 'remorse'], [1047, "You conveniently aren't speaking to my assertion.", 'neutral', 'neutral'], [2031, "This hits hard, sadly both of my relationships have been toxic so I've decided not to start any new ones until I start going to uni ", 'sadness', 'sadness'], [354, 'Sorry your right', 'remorse', 'remorse'], [2034, 'SHE SHOULD BE ON A HILL SOMEWHERE WITH THE SUN AND THE CLOUDS ABOVE HER!', 'neutral', 'neutral']]
Incorrect Instances:  [[2963, "Deep down you know pain is temporary and you'll do it all over again the next weekend", 'neutral', 'caring'], [644, "I swear to [NAME], I'm going to approach you. Instead of running away, I'll come right to you.", 'neutral', 'caring'], [745, 'Yeah I wish they could just finish 9th every year in the conference', 'optimism', 'desire'], [1863, 'I do not trust our defense at all. I do not believe you can increase the range of Andujar.', 'surprise', 'disapproval'], [1150, 'Difficult to see how this video wouldn’t have been much more interesting if properly shot in landscape.', 'disapproval', 'confusion'], [2475, 'For the people and finding out how they end up? Sure. Other than that, it’s not great. Frustrating at best. ', 'anger', 'disapproval'], [2788, 'RIGHT?! My mom would literally never forgive the bitch 😂', 'amusement', 'anger'], [1376, 'At my job I can/Do get laid a lot so the second one!!', 'approval', 'neutral'], [3261, "I wouldn't say age would stop it just lessen the affect of it but probably start to notice it around mid to late 30's.", 'realization', 'neutral'], [3143, "Good luck for everyone pronouncing [NAME] name. If he keeps scoring like this, i'll have fun listening some commentators around NHL.", 'gratitude', 'joy']]
Metrics:
F1: 0.505372185575147 
Accuracy: 0.593681917211329
Results: {'f1': [0.4093317022924049, 0.4745209967970227, 0.4704927685575538, 0.48897467578558923, 0.48198481548184635, 0.4911742275663733, 0.4794594039356178, 0.48714627768893043, 0.505372185575147], 'accuracy': [0.6112576956904133, 0.6323658751099385, 0.6207124010554089, 0.613896218117854, 0.6031222515391381, 0.5976253298153035, 0.5872911169744943, 0.5914687774846086, 0.593681917211329], 'duration': [91.16596817970276, 181.51626586914062, 272.31275153160095, 363.20208764076233, 454.04840660095215, 544.6505920886993, 635.4349443912506, 726.1325314044952, 733.7052068710327], 'reports': ['                precision    recall  f1-score   support\n\n    admiration       0.64      0.81      0.72       326\n     amusement       0.70      0.88      0.78       208\n         anger       0.40      0.63      0.49       109\n     annoyance       0.35      0.16      0.22       164\n      approval       0.51      0.22      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.59      0.29      0.39       102\n     curiosity       0.46      0.62      0.53       164\n        desire       0.79      0.42      0.55        52\ndisappointment       0.33      0.08      0.12        91\n   disapproval       0.46      0.20      0.28       212\n       disgust       0.58      0.34      0.43        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.86      0.12      0.20        52\n          fear       0.63      0.55      0.59        58\n     gratitude       0.96      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.53      0.58       106\n          love       0.70      0.89      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.56      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.88      0.74        40\n       sadness       0.54      0.57      0.55        84\n      surprise       0.48      0.55      0.51        95\n       neutral       0.60      0.78      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.40      0.41      4548\n  weighted avg       0.60      0.61      0.58      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.71      0.79      0.74       326\n     amusement       0.74      0.88      0.80       208\n         anger       0.49      0.61      0.55       109\n     annoyance       0.32      0.24      0.27       164\n      approval       0.64      0.19      0.29       258\n        caring       0.65      0.31      0.42        96\n     confusion       0.57      0.32      0.41       102\n     curiosity       0.46      0.70      0.55       164\n        desire       0.74      0.44      0.55        52\ndisappointment       0.36      0.16      0.23        91\n   disapproval       0.48      0.36      0.41       212\n       disgust       0.53      0.49      0.51        61\n embarrassment       0.65      0.55      0.59        20\n    excitement       0.52      0.23      0.32        52\n          fear       0.68      0.81      0.74        58\n     gratitude       0.95      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.55      0.60       106\n          love       0.69      0.91      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.71      0.58      0.64       119\n         pride       0.00      0.00      0.00         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.66      0.93      0.77        40\n       sadness       0.56      0.55      0.55        84\n      surprise       0.56      0.66      0.61        95\n       neutral       0.63      0.76      0.69      1592\n\n      accuracy                           0.63      4548\n     macro avg       0.53      0.47      0.47      4548\n  weighted avg       0.63      0.63      0.61      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.68      0.83      0.75       326\n     amusement       0.75      0.86      0.80       208\n         anger       0.45      0.60      0.51       109\n     annoyance       0.39      0.26      0.31       164\n      approval       0.47      0.30      0.37       258\n        caring       0.52      0.45      0.48        96\n     confusion       0.47      0.31      0.38       102\n     curiosity       0.46      0.56      0.50       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.47      0.23      0.31        91\n   disapproval       0.47      0.30      0.37       212\n       disgust       0.58      0.54      0.56        61\n embarrassment       0.80      0.40      0.53        20\n    excitement       0.27      0.42      0.33        52\n          fear       0.72      0.62      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.68      0.55      0.61       106\n          love       0.76      0.84      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.59      0.64      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.53      0.22      0.31        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.75      0.70        40\n       sadness       0.57      0.58      0.58        84\n      surprise       0.55      0.56      0.55        95\n       neutral       0.64      0.72      0.68      1592\n\n      accuracy                           0.62      4548\n     macro avg       0.50      0.46      0.47      4548\n  weighted avg       0.61      0.62      0.61      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.66      0.82      0.73       326\n     amusement       0.77      0.83      0.80       208\n         anger       0.58      0.50      0.54       109\n     annoyance       0.37      0.33      0.35       164\n      approval       0.45      0.35      0.39       258\n        caring       0.52      0.49      0.51        96\n     confusion       0.47      0.32      0.38       102\n     curiosity       0.45      0.58      0.51       164\n        desire       0.56      0.56      0.56        52\ndisappointment       0.40      0.35      0.37        91\n   disapproval       0.36      0.37      0.36       212\n       disgust       0.39      0.56      0.46        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.27      0.37      0.31        52\n          fear       0.68      0.72      0.70        58\n     gratitude       0.94      0.91      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.52      0.58       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.61      0.58      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       0.71      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.70      0.68        40\n       sadness       0.51      0.62      0.56        84\n      surprise       0.51      0.61      0.56        95\n       neutral       0.68      0.67      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.50      0.49      4548\n  weighted avg       0.61      0.61      0.61      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.65      0.84      0.73       326\n     amusement       0.74      0.80      0.77       208\n         anger       0.46      0.61      0.52       109\n     annoyance       0.34      0.35      0.35       164\n      approval       0.43      0.34      0.38       258\n        caring       0.48      0.51      0.49        96\n     confusion       0.46      0.31      0.37       102\n     curiosity       0.47      0.51      0.49       164\n        desire       0.62      0.54      0.58        52\ndisappointment       0.36      0.29      0.32        91\n   disapproval       0.36      0.37      0.37       212\n       disgust       0.46      0.51      0.48        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.36      0.29      0.32        52\n          fear       0.73      0.66      0.69        58\n     gratitude       0.90      0.92      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.73      0.83      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.65      0.55      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.48      0.22      0.30        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.65      0.65        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.53      0.55      0.54        95\n       neutral       0.66      0.65      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.49      0.48      0.48      4548\n  weighted avg       0.60      0.60      0.60      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.67      0.80      0.73       326\n     amusement       0.71      0.85      0.77       208\n         anger       0.48      0.57      0.52       109\n     annoyance       0.31      0.35      0.33       164\n      approval       0.41      0.36      0.38       258\n        caring       0.49      0.49      0.49        96\n     confusion       0.38      0.37      0.37       102\n     curiosity       0.46      0.54      0.49       164\n        desire       0.58      0.54      0.56        52\ndisappointment       0.35      0.32      0.33        91\n   disapproval       0.37      0.30      0.33       212\n       disgust       0.45      0.52      0.48        61\n embarrassment       0.55      0.55      0.55        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.67      0.67      0.67        58\n     gratitude       0.93      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.56      0.60       106\n          love       0.71      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.67      0.59      0.63       119\n         pride       1.00      0.22      0.36         9\n   realization       0.32      0.23      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.65      0.63        40\n       sadness       0.49      0.64      0.56        84\n      surprise       0.52      0.58      0.55        95\n       neutral       0.68      0.63      0.65      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.50      0.49      4548\n  weighted avg       0.60      0.60      0.59      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.66      0.79      0.72       326\n     amusement       0.73      0.84      0.78       208\n         anger       0.50      0.57      0.53       109\n     annoyance       0.33      0.41      0.36       164\n      approval       0.37      0.38      0.37       258\n        caring       0.46      0.46      0.46        96\n     confusion       0.40      0.35      0.37       102\n     curiosity       0.45      0.46      0.46       164\n        desire       0.52      0.54      0.53        52\ndisappointment       0.32      0.25      0.28        91\n   disapproval       0.37      0.34      0.35       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.69      0.66      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.53      0.56       106\n          love       0.70      0.85      0.77       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.62      0.60      0.61       119\n         pride       1.00      0.11      0.20         9\n   realization       0.28      0.24      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.61      0.70      0.65        40\n       sadness       0.48      0.64      0.55        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.67      0.61      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.48      4548\n  weighted avg       0.59      0.59      0.58      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.73      0.85      0.78       208\n         anger       0.51      0.56      0.54       109\n     annoyance       0.31      0.41      0.35       164\n      approval       0.38      0.36      0.37       258\n        caring       0.48      0.50      0.49        96\n     confusion       0.39      0.34      0.37       102\n     curiosity       0.46      0.49      0.47       164\n        desire       0.53      0.54      0.53        52\ndisappointment       0.34      0.30      0.32        91\n   disapproval       0.36      0.33      0.34       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.28      0.29      0.28        52\n          fear       0.71      0.64      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.63      0.53      0.57       106\n          love       0.72      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.59      0.59      0.59       119\n         pride       1.00      0.22      0.36         9\n   realization       0.27      0.22      0.24        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.65      0.64        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.52      0.56      0.54        95\n       neutral       0.67      0.62      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.49      4548\n  weighted avg       0.59      0.59      0.59      4548\n', '                precision    recall  f1-score   support\n\n    admiration       0.66      0.75      0.70       348\n     amusement       0.76      0.85      0.80       186\n         anger       0.51      0.50      0.50       131\n     annoyance       0.33      0.31      0.32       194\n      approval       0.38      0.43      0.40       236\n        caring       0.35      0.40      0.37        86\n     confusion       0.35      0.37      0.36        97\n     curiosity       0.48      0.52      0.50       176\n        desire       0.60      0.43      0.50        56\ndisappointment       0.41      0.31      0.35        88\n   disapproval       0.36      0.37      0.36       195\n       disgust       0.58      0.58      0.58        76\n embarrassment       0.57      0.52      0.55        23\n    excitement       0.38      0.44      0.41        57\n          fear       0.67      0.74      0.70        65\n     gratitude       0.94      0.90      0.92       260\n         grief       0.00      0.00      0.00         2\n           joy       0.58      0.60      0.59        93\n          love       0.79      0.84      0.81       160\n   nervousness       0.50      0.58      0.54        12\n      optimism       0.56      0.55      0.55       107\n         pride       0.50      0.14      0.22         7\n   realization       0.25      0.20      0.22        89\n        relief       1.00      0.29      0.44         7\n       remorse       0.67      0.75      0.71        44\n       sadness       0.55      0.55      0.55       102\n      surprise       0.51      0.53      0.52        87\n       neutral       0.67      0.64      0.65      1606\n\n      accuracy                           0.59      4590\n     macro avg       0.53      0.50      0.51      4590\n  weighted avg       0.59      0.59      0.59      4590\n'], 'final': {'f1': 0.505372185575147, 'accuracy': 0.593681917211329, 'duration': 733.7528364658356, 'report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.75      0.70       348\n     amusement       0.76      0.85      0.80       186\n         anger       0.51      0.50      0.50       131\n     annoyance       0.33      0.31      0.32       194\n      approval       0.38      0.43      0.40       236\n        caring       0.35      0.40      0.37        86\n     confusion       0.35      0.37      0.36        97\n     curiosity       0.48      0.52      0.50       176\n        desire       0.60      0.43      0.50        56\ndisappointment       0.41      0.31      0.35        88\n   disapproval       0.36      0.37      0.36       195\n       disgust       0.58      0.58      0.58        76\n embarrassment       0.57      0.52      0.55        23\n    excitement       0.38      0.44      0.41        57\n          fear       0.67      0.74      0.70        65\n     gratitude       0.94      0.90      0.92       260\n         grief       0.00      0.00      0.00         2\n           joy       0.58      0.60      0.59        93\n          love       0.79      0.84      0.81       160\n   nervousness       0.50      0.58      0.54        12\n      optimism       0.56      0.55      0.55       107\n         pride       0.50      0.14      0.22         7\n   realization       0.25      0.20      0.22        89\n        relief       1.00      0.29      0.44         7\n       remorse       0.67      0.75      0.71        44\n       sadness       0.55      0.55      0.55       102\n      surprise       0.51      0.53      0.52        87\n       neutral       0.67      0.64      0.65      1606\n\n      accuracy                           0.59      4590\n     macro avg       0.53      0.50      0.51      4590\n  weighted avg       0.59      0.59      0.59      4590\n'}}
Final Report:
                 precision    recall  f1-score   support

    admiration       0.66      0.75      0.70       348
     amusement       0.76      0.85      0.80       186
         anger       0.51      0.50      0.50       131
     annoyance       0.33      0.31      0.32       194
      approval       0.38      0.43      0.40       236
        caring       0.35      0.40      0.37        86
     confusion       0.35      0.37      0.36        97
     curiosity       0.48      0.52      0.50       176
        desire       0.60      0.43      0.50        56
disappointment       0.41      0.31      0.35        88
   disapproval       0.36      0.37      0.36       195
       disgust       0.58      0.58      0.58        76
 embarrassment       0.57      0.52      0.55        23
    excitement       0.38      0.44      0.41        57
          fear       0.67      0.74      0.70        65
     gratitude       0.94      0.90      0.92       260
         grief       0.00      0.00      0.00         2
           joy       0.58      0.60      0.59        93
          love       0.79      0.84      0.81       160
   nervousness       0.50      0.58      0.54        12
      optimism       0.56      0.55      0.55       107
         pride       0.50      0.14      0.22         7
   realization       0.25      0.20      0.22        89
        relief       1.00      0.29      0.44         7
       remorse       0.67      0.75      0.71        44
       sadness       0.55      0.55      0.55       102
      surprise       0.51      0.53      0.52        87
       neutral       0.67      0.64      0.65      1606

      accuracy                           0.59      4590
     macro avg       0.53      0.50      0.51      4590
  weighted avg       0.59      0.59      0.59      4590

F1 scores: [0.4093317022924049, 0.4745209967970227, 0.4704927685575538, 0.48897467578558923, 0.48198481548184635, 0.4911742275663733, 0.4794594039356178, 0.48714627768893043, 0.505372185575147]
Accuracies: [0.6112576956904133, 0.6323658751099385, 0.6207124010554089, 0.613896218117854, 0.6031222515391381, 0.5976253298153035, 0.5872911169744943, 0.5914687774846086, 0.593681917211329]
Durations: [91.16596817970276, 181.51626586914062, 272.31275153160095, 363.20208764076233, 454.04840660095215, 544.6505920886993, 635.4349443912506, 726.1325314044952, 733.7052068710327]
log_history: [{'loss': 1.9547, 'grad_norm': 9.156770706176758, 'learning_rate': 1.8519813519813522e-05, 'epoch': 1.0, 'step': 1135}, {'eval_loss': 1.3516144752502441, 'eval_accuracy': 0.6112576956904133, 'eval_f1': 0.4093317022924049, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.81      0.72       326\n     amusement       0.70      0.88      0.78       208\n         anger       0.40      0.63      0.49       109\n     annoyance       0.35      0.16      0.22       164\n      approval       0.51      0.22      0.31       258\n        caring       0.60      0.34      0.44        96\n     confusion       0.59      0.29      0.39       102\n     curiosity       0.46      0.62      0.53       164\n        desire       0.79      0.42      0.55        52\ndisappointment       0.33      0.08      0.12        91\n   disapproval       0.46      0.20      0.28       212\n       disgust       0.58      0.34      0.43        61\n embarrassment       0.00      0.00      0.00        20\n    excitement       0.86      0.12      0.20        52\n          fear       0.63      0.55      0.59        58\n     gratitude       0.96      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.64      0.53      0.58       106\n          love       0.70      0.89      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.56      0.61       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.01      0.03        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.88      0.74        40\n       sadness       0.54      0.57      0.55        84\n      surprise       0.48      0.55      0.51        95\n       neutral       0.60      0.78      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.40      0.41      4548\n  weighted avg       0.60      0.61      0.58      4548\n', 'eval_runtime': 3.0501, 'eval_samples_per_second': 1491.114, 'eval_steps_per_second': 46.884, 'epoch': 1.0, 'step': 1135}, {'loss': 1.2421, 'grad_norm': 10.479072570800781, 'learning_rate': 1.5874125874125875e-05, 'epoch': 2.0, 'step': 2270}, {'eval_loss': 1.263283610343933, 'eval_accuracy': 0.6323658751099385, 'eval_f1': 0.4745209967970227, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.71      0.79      0.74       326\n     amusement       0.74      0.88      0.80       208\n         anger       0.49      0.61      0.55       109\n     annoyance       0.32      0.24      0.27       164\n      approval       0.64      0.19      0.29       258\n        caring       0.65      0.31      0.42        96\n     confusion       0.57      0.32      0.41       102\n     curiosity       0.46      0.70      0.55       164\n        desire       0.74      0.44      0.55        52\ndisappointment       0.36      0.16      0.23        91\n   disapproval       0.48      0.36      0.41       212\n       disgust       0.53      0.49      0.51        61\n embarrassment       0.65      0.55      0.59        20\n    excitement       0.52      0.23      0.32        52\n          fear       0.68      0.81      0.74        58\n     gratitude       0.95      0.90      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.55      0.60       106\n          love       0.69      0.91      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.71      0.58      0.64       119\n         pride       0.00      0.00      0.00         9\n   realization       0.75      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.66      0.93      0.77        40\n       sadness       0.56      0.55      0.55        84\n      surprise       0.56      0.66      0.61        95\n       neutral       0.63      0.76      0.69      1592\n\n      accuracy                           0.63      4548\n     macro avg       0.53      0.47      0.47      4548\n  weighted avg       0.63      0.63      0.61      4548\n', 'eval_runtime': 3.0937, 'eval_samples_per_second': 1470.085, 'eval_steps_per_second': 46.223, 'epoch': 2.0, 'step': 2270}, {'loss': 1.0205, 'grad_norm': 13.909720420837402, 'learning_rate': 1.3228438228438229e-05, 'epoch': 3.0, 'step': 3405}, {'eval_loss': 1.267223834991455, 'eval_accuracy': 0.6207124010554089, 'eval_f1': 0.4704927685575538, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.83      0.75       326\n     amusement       0.75      0.86      0.80       208\n         anger       0.45      0.60      0.51       109\n     annoyance       0.39      0.26      0.31       164\n      approval       0.47      0.30      0.37       258\n        caring       0.52      0.45      0.48        96\n     confusion       0.47      0.31      0.38       102\n     curiosity       0.46      0.56      0.50       164\n        desire       0.61      0.52      0.56        52\ndisappointment       0.47      0.23      0.31        91\n   disapproval       0.47      0.30      0.37       212\n       disgust       0.58      0.54      0.56        61\n embarrassment       0.80      0.40      0.53        20\n    excitement       0.27      0.42      0.33        52\n          fear       0.72      0.62      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.68      0.55      0.61       106\n          love       0.76      0.84      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.59      0.64      0.62       119\n         pride       0.00      0.00      0.00         9\n   realization       0.53      0.22      0.31        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.75      0.70        40\n       sadness       0.57      0.58      0.58        84\n      surprise       0.55      0.56      0.55        95\n       neutral       0.64      0.72      0.68      1592\n\n      accuracy                           0.62      4548\n     macro avg       0.50      0.46      0.47      4548\n  weighted avg       0.61      0.62      0.61      4548\n', 'eval_runtime': 3.0959, 'eval_samples_per_second': 1469.057, 'eval_steps_per_second': 46.191, 'epoch': 3.0, 'step': 3405}, {'loss': 0.8249, 'grad_norm': 7.5537214279174805, 'learning_rate': 1.0582750582750583e-05, 'epoch': 4.0, 'step': 4540}, {'eval_loss': 1.3819111585617065, 'eval_accuracy': 0.613896218117854, 'eval_f1': 0.48897467578558923, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.82      0.73       326\n     amusement       0.77      0.83      0.80       208\n         anger       0.58      0.50      0.54       109\n     annoyance       0.37      0.33      0.35       164\n      approval       0.45      0.35      0.39       258\n        caring       0.52      0.49      0.51        96\n     confusion       0.47      0.32      0.38       102\n     curiosity       0.45      0.58      0.51       164\n        desire       0.56      0.56      0.56        52\ndisappointment       0.40      0.35      0.37        91\n   disapproval       0.36      0.37      0.36       212\n       disgust       0.39      0.56      0.46        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.27      0.37      0.31        52\n          fear       0.68      0.72      0.70        58\n     gratitude       0.94      0.91      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.52      0.58       106\n          love       0.69      0.90      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.61      0.58      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       0.71      0.20      0.32        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.67      0.70      0.68        40\n       sadness       0.51      0.62      0.56        84\n      surprise       0.51      0.61      0.56        95\n       neutral       0.68      0.67      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.50      0.50      0.49      4548\n  weighted avg       0.61      0.61      0.61      4548\n', 'eval_runtime': 3.098, 'eval_samples_per_second': 1468.022, 'eval_steps_per_second': 46.158, 'epoch': 4.0, 'step': 4540}, {'loss': 0.651, 'grad_norm': 11.947890281677246, 'learning_rate': 7.937062937062937e-06, 'epoch': 5.0, 'step': 5675}, {'eval_loss': 1.467684268951416, 'eval_accuracy': 0.6031222515391381, 'eval_f1': 0.48198481548184635, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.65      0.84      0.73       326\n     amusement       0.74      0.80      0.77       208\n         anger       0.46      0.61      0.52       109\n     annoyance       0.34      0.35      0.35       164\n      approval       0.43      0.34      0.38       258\n        caring       0.48      0.51      0.49        96\n     confusion       0.46      0.31      0.37       102\n     curiosity       0.47      0.51      0.49       164\n        desire       0.62      0.54      0.58        52\ndisappointment       0.36      0.29      0.32        91\n   disapproval       0.36      0.37      0.37       212\n       disgust       0.46      0.51      0.48        61\n embarrassment       0.61      0.55      0.58        20\n    excitement       0.36      0.29      0.32        52\n          fear       0.73      0.66      0.69        58\n     gratitude       0.90      0.92      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.62      0.55      0.58       106\n          love       0.73      0.83      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.65      0.55      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.48      0.22      0.30        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.65      0.65      0.65        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.53      0.55      0.54        95\n       neutral       0.66      0.65      0.66      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.49      0.48      0.48      4548\n  weighted avg       0.60      0.60      0.60      4548\n', 'eval_runtime': 3.1081, 'eval_samples_per_second': 1463.269, 'eval_steps_per_second': 46.009, 'epoch': 5.0, 'step': 5675}, {'loss': 0.5137, 'grad_norm': 13.049745559692383, 'learning_rate': 5.291375291375292e-06, 'epoch': 6.0, 'step': 6810}, {'eval_loss': 1.6141308546066284, 'eval_accuracy': 0.5976253298153035, 'eval_f1': 0.4911742275663733, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.80      0.73       326\n     amusement       0.71      0.85      0.77       208\n         anger       0.48      0.57      0.52       109\n     annoyance       0.31      0.35      0.33       164\n      approval       0.41      0.36      0.38       258\n        caring       0.49      0.49      0.49        96\n     confusion       0.38      0.37      0.37       102\n     curiosity       0.46      0.54      0.49       164\n        desire       0.58      0.54      0.56        52\ndisappointment       0.35      0.32      0.33        91\n   disapproval       0.37      0.30      0.33       212\n       disgust       0.45      0.52      0.48        61\n embarrassment       0.55      0.55      0.55        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.67      0.67      0.67        58\n     gratitude       0.93      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.66      0.56      0.60       106\n          love       0.71      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.67      0.59      0.63       119\n         pride       1.00      0.22      0.36         9\n   realization       0.32      0.23      0.27        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.65      0.63        40\n       sadness       0.49      0.64      0.56        84\n      surprise       0.52      0.58      0.55        95\n       neutral       0.68      0.63      0.65      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.51      0.50      0.49      4548\n  weighted avg       0.60      0.60      0.59      4548\n', 'eval_runtime': 3.0865, 'eval_samples_per_second': 1473.533, 'eval_steps_per_second': 46.331, 'epoch': 6.0, 'step': 6810}, {'loss': 0.4108, 'grad_norm': 10.576498031616211, 'learning_rate': 2.645687645687646e-06, 'epoch': 7.0, 'step': 7945}, {'eval_loss': 1.7132115364074707, 'eval_accuracy': 0.5872911169744943, 'eval_f1': 0.4794594039356178, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.79      0.72       326\n     amusement       0.73      0.84      0.78       208\n         anger       0.50      0.57      0.53       109\n     annoyance       0.33      0.41      0.36       164\n      approval       0.37      0.38      0.37       258\n        caring       0.46      0.46      0.46        96\n     confusion       0.40      0.35      0.37       102\n     curiosity       0.45      0.46      0.46       164\n        desire       0.52      0.54      0.53        52\ndisappointment       0.32      0.25      0.28        91\n   disapproval       0.37      0.34      0.35       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.30      0.35      0.32        52\n          fear       0.69      0.66      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.53      0.56       106\n          love       0.70      0.85      0.77       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.62      0.60      0.61       119\n         pride       1.00      0.11      0.20         9\n   realization       0.28      0.24      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.61      0.70      0.65        40\n       sadness       0.48      0.64      0.55        84\n      surprise       0.52      0.54      0.53        95\n       neutral       0.67      0.61      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.48      4548\n  weighted avg       0.59      0.59      0.58      4548\n', 'eval_runtime': 3.085, 'eval_samples_per_second': 1474.222, 'eval_steps_per_second': 46.353, 'epoch': 7.0, 'step': 7945}, {'loss': 0.3439, 'grad_norm': 12.520172119140625, 'learning_rate': 0.0, 'epoch': 8.0, 'step': 9080}, {'eval_loss': 1.7583812475204468, 'eval_accuracy': 0.5914687774846086, 'eval_f1': 0.48714627768893043, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.68      0.79      0.73       326\n     amusement       0.73      0.85      0.78       208\n         anger       0.51      0.56      0.54       109\n     annoyance       0.31      0.41      0.35       164\n      approval       0.38      0.36      0.37       258\n        caring       0.48      0.50      0.49        96\n     confusion       0.39      0.34      0.37       102\n     curiosity       0.46      0.49      0.47       164\n        desire       0.53      0.54      0.53        52\ndisappointment       0.34      0.30      0.32        91\n   disapproval       0.36      0.33      0.34       212\n       disgust       0.46      0.54      0.50        61\n embarrassment       0.58      0.55      0.56        20\n    excitement       0.28      0.29      0.28        52\n          fear       0.71      0.64      0.67        58\n     gratitude       0.92      0.92      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.63      0.53      0.57       106\n          love       0.72      0.85      0.78       173\n   nervousness       0.44      0.50      0.47         8\n      optimism       0.59      0.59      0.59       119\n         pride       1.00      0.22      0.36         9\n   realization       0.27      0.22      0.24        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.65      0.64        40\n       sadness       0.51      0.64      0.57        84\n      surprise       0.52      0.56      0.54        95\n       neutral       0.67      0.62      0.64      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.50      0.49      0.49      4548\n  weighted avg       0.59      0.59      0.59      4548\n', 'eval_runtime': 3.1401, 'eval_samples_per_second': 1448.352, 'eval_steps_per_second': 45.54, 'epoch': 8.0, 'step': 9080}, {'train_runtime': 723.8339, 'train_samples_per_second': 401.285, 'train_steps_per_second': 12.544, 'total_flos': 5450357510123232.0, 'train_loss': 0.8702042398998916, 'epoch': 8.0, 'step': 9080}]
Training Losses ( 8 ): [1.9547, 1.2421, 1.0205, 0.8249, 0.651, 0.5137, 0.4108, 0.3439]
Validation Losses ( 8 ): [1.3516144752502441, 1.263283610343933, 1.267223834991455, 1.3819111585617065, 1.467684268951416, 1.6141308546066284, 1.7132115364074707, 1.7583812475204468]
Graphs saved to disk
