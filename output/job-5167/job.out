Starting BERT epoch experiments script
Train method: head+1
Learning rate: 0.001 
Num epochs: 8 
Batch size: 32 
Weight decay: 1 
Warmup steps: 500
Loading model
Device: cuda
Name: bert.embeddings.word_embeddings.weight  - Size: torch.Size([30522, 768])  - Requires grad: False
Name: bert.embeddings.position_embeddings.weight  - Size: torch.Size([512, 768])  - Requires grad: False
Name: bert.embeddings.token_type_embeddings.weight  - Size: torch.Size([2, 768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.embeddings.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.0.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.0.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.0.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.1.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.1.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.1.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.2.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.2.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.2.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.3.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.3.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.3.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.4.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.4.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.4.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.5.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.5.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.5.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.6.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.6.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.6.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.7.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.7.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.7.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.8.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.8.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.8.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.9.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.9.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.9.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: False
Name: bert.encoder.layer.10.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: False
Name: bert.encoder.layer.10.output.dense.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.10.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: False
Name: bert.encoder.layer.11.attention.self.query.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.query.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.key.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.self.value.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.attention.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.weight  - Size: torch.Size([3072, 768])  - Requires grad: True
Name: bert.encoder.layer.11.intermediate.dense.bias  - Size: torch.Size([3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.weight  - Size: torch.Size([768, 3072])  - Requires grad: True
Name: bert.encoder.layer.11.output.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.weight  - Size: torch.Size([768])  - Requires grad: True
Name: bert.encoder.layer.11.output.LayerNorm.bias  - Size: torch.Size([768])  - Requires grad: True
Name: bert.pooler.dense.weight  - Size: torch.Size([768, 768])  - Requires grad: True
Name: bert.pooler.dense.bias  - Size: torch.Size([768])  - Requires grad: True
Name: classifier.weight  - Size: torch.Size([28, 768])  - Requires grad: True
Name: classifier.bias  - Size: torch.Size([28])  - Requires grad: True
Fine-tuning the model on the GoEmotions dataset...
Filtered dataset:
 DatasetDict({
    train: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 36308
    })
    validation: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4548
    })
    test: Dataset({
        features: ['text', 'labels', 'id'],
        num_rows: 4590
    })
})
{'loss': 1.8027, 'grad_norm': 4.767917156219482, 'learning_rate': 0.000925990675990676, 'epoch': 1.0}
{'eval_loss': 1.5563863515853882, 'eval_accuracy': 0.5466138962181178, 'eval_f1': 0.31097502949941047, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.67      0.73      0.70       326\n     amusement       0.44      0.93      0.60       208\n         anger       0.00      0.00      0.00       109\n     annoyance       0.20      0.29      0.23       164\n      approval       0.65      0.12      0.20       258\n        caring       0.36      0.09      0.15        96\n     confusion       0.31      0.28      0.30       102\n     curiosity       0.45      0.54      0.49       164\n        desire       0.78      0.40      0.53        52\ndisappointment       0.33      0.01      0.02        91\n   disapproval       0.42      0.14      0.21       212\n       disgust       0.60      0.05      0.09        61\n embarrassment       0.19      0.15      0.17        20\n    excitement       0.50      0.06      0.10        52\n          fear       0.80      0.21      0.33        58\n     gratitude       0.93      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.58      0.52      0.55       106\n          love       0.74      0.84      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.73      0.20      0.32       119\n         pride       0.00      0.00      0.00         9\n   realization       0.00      0.00      0.00        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.49      0.90      0.63        40\n       sadness       0.36      0.52      0.43        84\n      surprise       0.50      0.23      0.32        95\n       neutral       0.56      0.76      0.64      1592\n\n      accuracy                           0.55      4548\n     macro avg       0.41      0.32      0.31      4548\n  weighted avg       0.53      0.55      0.50      4548\n', 'eval_runtime': 2.9567, 'eval_samples_per_second': 1538.206, 'eval_steps_per_second': 48.365, 'epoch': 1.0}
{'loss': 1.5403, 'grad_norm': 4.114956855773926, 'learning_rate': 0.0007937062937062938, 'epoch': 2.0}
{'eval_loss': 1.4791849851608276, 'eval_accuracy': 0.5690413368513633, 'eval_f1': 0.4061228231362694, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.70      0.66      0.68       326\n     amusement       0.70      0.86      0.77       208\n         anger       0.44      0.53      0.48       109\n     annoyance       0.44      0.12      0.19       164\n      approval       0.60      0.11      0.18       258\n        caring       0.43      0.03      0.06        96\n     confusion       0.51      0.18      0.26       102\n     curiosity       0.43      0.65      0.52       164\n        desire       0.77      0.52      0.62        52\ndisappointment       0.27      0.13      0.18        91\n   disapproval       0.30      0.41      0.35       212\n       disgust       0.40      0.46      0.43        61\n embarrassment       0.70      0.35      0.47        20\n    excitement       1.00      0.08      0.14        52\n          fear       0.68      0.47      0.55        58\n     gratitude       0.99      0.83      0.90       261\n         grief       0.00      0.00      0.00         6\n           joy       0.44      0.63      0.52       106\n          love       0.69      0.89      0.78       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.54      0.54      0.54       119\n         pride       1.00      0.11      0.20         9\n   realization       0.21      0.27      0.24        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.85      0.72        40\n       sadness       0.51      0.45      0.48        84\n      surprise       0.56      0.43      0.49        95\n       neutral       0.58      0.71      0.64      1592\n\n      accuracy                           0.57      4548\n     macro avg       0.52      0.40      0.41      4548\n  weighted avg       0.58      0.57      0.54      4548\n', 'eval_runtime': 2.9765, 'eval_samples_per_second': 1527.956, 'eval_steps_per_second': 48.043, 'epoch': 2.0}
{'loss': 1.4719, 'grad_norm': 3.5165605545043945, 'learning_rate': 0.0006614219114219114, 'epoch': 3.0}
{'eval_loss': 1.383717656135559, 'eval_accuracy': 0.590589270008795, 'eval_f1': 0.3903123968592924, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.65      0.77      0.71       326\n     amusement       0.72      0.80      0.76       208\n         anger       0.31      0.56      0.40       109\n     annoyance       0.37      0.08      0.13       164\n      approval       0.72      0.16      0.26       258\n        caring       0.39      0.38      0.38        96\n     confusion       0.64      0.14      0.23       102\n     curiosity       0.48      0.51      0.49       164\n        desire       0.67      0.56      0.61        52\ndisappointment       0.25      0.01      0.02        91\n   disapproval       0.46      0.16      0.23       212\n       disgust       0.41      0.33      0.36        61\n embarrassment       0.80      0.20      0.32        20\n    excitement       0.32      0.29      0.30        52\n          fear       0.55      0.45      0.50        58\n     gratitude       0.93      0.91      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.54      0.52      0.53       106\n          love       0.66      0.90      0.76       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.56      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       0.82      0.12      0.21        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.63      0.65      0.64        40\n       sadness       0.57      0.32      0.41        84\n      surprise       0.55      0.44      0.49        95\n       neutral       0.57      0.80      0.67      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.49      0.38      0.39      4548\n  weighted avg       0.58      0.59      0.55      4548\n', 'eval_runtime': 2.9963, 'eval_samples_per_second': 1517.872, 'eval_steps_per_second': 47.726, 'epoch': 3.0}
{'loss': 1.4146, 'grad_norm': 3.0750997066497803, 'learning_rate': 0.0005291375291375291, 'epoch': 4.0}
{'eval_loss': 1.3809168338775635, 'eval_accuracy': 0.5868513632365875, 'eval_f1': 0.4170313495035729, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.64      0.78      0.70       326\n     amusement       0.76      0.71      0.73       208\n         anger       0.59      0.37      0.45       109\n     annoyance       0.46      0.14      0.21       164\n      approval       0.45      0.28      0.34       258\n        caring       0.71      0.23      0.35        96\n     confusion       0.54      0.26      0.36       102\n     curiosity       0.43      0.62      0.51       164\n        desire       0.64      0.52      0.57        52\ndisappointment       0.28      0.10      0.15        91\n   disapproval       0.34      0.32      0.33       212\n       disgust       0.28      0.61      0.38        61\n embarrassment       0.58      0.35      0.44        20\n    excitement       0.36      0.29      0.32        52\n          fear       0.74      0.48      0.58        58\n     gratitude       0.87      0.91      0.89       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.52      0.55       106\n          love       0.67      0.90      0.77       173\n   nervousness       0.50      0.12      0.20         8\n      optimism       0.61      0.57      0.59       119\n         pride       0.00      0.00      0.00         9\n   realization       1.00      0.04      0.08        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.68      0.42      0.52        40\n       sadness       0.39      0.67      0.49        84\n      surprise       0.51      0.48      0.50        95\n       neutral       0.61      0.73      0.66      1592\n\n      accuracy                           0.59      4548\n     macro avg       0.51      0.41      0.42      4548\n  weighted avg       0.59      0.59      0.56      4548\n', 'eval_runtime': 3.0057, 'eval_samples_per_second': 1513.144, 'eval_steps_per_second': 47.577, 'epoch': 4.0}
{'loss': 1.3588, 'grad_norm': 3.716571569442749, 'learning_rate': 0.0003968531468531469, 'epoch': 5.0}
{'eval_loss': 1.3910579681396484, 'eval_accuracy': 0.5817941952506597, 'eval_f1': 0.40190910890387166, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.44      0.88      0.59       326\n     amusement       0.68      0.85      0.76       208\n         anger       0.39      0.59      0.47       109\n     annoyance       0.42      0.14      0.21       164\n      approval       0.60      0.16      0.25       258\n        caring       0.62      0.27      0.38        96\n     confusion       0.52      0.23      0.32       102\n     curiosity       0.51      0.26      0.35       164\n        desire       0.90      0.37      0.52        52\ndisappointment       0.50      0.03      0.06        91\n   disapproval       0.51      0.15      0.23       212\n       disgust       0.48      0.36      0.41        61\n embarrassment       0.83      0.25      0.38        20\n    excitement       0.56      0.19      0.29        52\n          fear       0.58      0.64      0.61        58\n     gratitude       0.94      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.77      0.25      0.38       106\n          love       0.72      0.79      0.75       173\n   nervousness       0.33      0.12      0.18         8\n      optimism       0.63      0.56      0.60       119\n         pride       0.00      0.00      0.00         9\n   realization       0.52      0.22      0.30        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.53      0.58        40\n       sadness       0.49      0.50      0.50        84\n      surprise       0.56      0.59      0.57        95\n       neutral       0.58      0.78      0.66      1592\n\n      accuracy                           0.58      4548\n     macro avg       0.53      0.38      0.40      4548\n  weighted avg       0.59      0.58      0.54      4548\n', 'eval_runtime': 3.0101, 'eval_samples_per_second': 1510.895, 'eval_steps_per_second': 47.506, 'epoch': 5.0}
{'loss': 1.2988, 'grad_norm': 3.5995893478393555, 'learning_rate': 0.00026456876456876455, 'epoch': 6.0}
{'eval_loss': 1.3331049680709839, 'eval_accuracy': 0.5989445910290238, 'eval_f1': 0.43116433774314566, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.59      0.82      0.69       326\n     amusement       0.67      0.90      0.77       208\n         anger       0.45      0.46      0.45       109\n     annoyance       0.51      0.15      0.23       164\n      approval       0.60      0.17      0.27       258\n        caring       0.50      0.45      0.47        96\n     confusion       0.38      0.33      0.35       102\n     curiosity       0.43      0.62      0.51       164\n        desire       0.57      0.50      0.53        52\ndisappointment       0.28      0.14      0.19        91\n   disapproval       0.55      0.19      0.29       212\n       disgust       0.47      0.38      0.42        61\n embarrassment       0.64      0.45      0.53        20\n    excitement       0.32      0.37      0.34        52\n          fear       0.82      0.40      0.53        58\n     gratitude       0.97      0.89      0.93       261\n         grief       0.00      0.00      0.00         6\n           joy       0.54      0.58      0.56       106\n          love       0.72      0.90      0.80       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.67      0.50      0.58       119\n         pride       0.00      0.00      0.00         9\n   realization       0.54      0.19      0.28        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.60      0.68      0.64        40\n       sadness       0.44      0.57      0.49        84\n      surprise       0.56      0.59      0.57        95\n       neutral       0.61      0.73      0.67      1592\n\n      accuracy                           0.60      4548\n     macro avg       0.48      0.43      0.43      4548\n  weighted avg       0.59      0.60      0.57      4548\n', 'eval_runtime': 3.0081, 'eval_samples_per_second': 1511.899, 'eval_steps_per_second': 47.538, 'epoch': 6.0}
{'loss': 1.2335, 'grad_norm': 3.5400381088256836, 'learning_rate': 0.00013228438228438227, 'epoch': 7.0}
{'eval_loss': 1.281908392906189, 'eval_accuracy': 0.6086191732629728, 'eval_f1': 0.4600184179616839, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.60      0.82      0.70       326\n     amusement       0.72      0.88      0.80       208\n         anger       0.48      0.47      0.47       109\n     annoyance       0.36      0.23      0.28       164\n      approval       0.45      0.28      0.35       258\n        caring       0.59      0.42      0.49        96\n     confusion       0.48      0.32      0.39       102\n     curiosity       0.47      0.34      0.40       164\n        desire       0.63      0.56      0.59        52\ndisappointment       0.33      0.18      0.23        91\n   disapproval       0.49      0.28      0.35       212\n       disgust       0.48      0.46      0.47        61\n embarrassment       0.56      0.45      0.50        20\n    excitement       0.48      0.29      0.36        52\n          fear       0.56      0.66      0.60        58\n     gratitude       0.94      0.90      0.92       261\n         grief       0.00      0.00      0.00         6\n           joy       0.55      0.58      0.56       106\n          love       0.71      0.89      0.79       173\n   nervousness       0.00      0.00      0.00         8\n      optimism       0.61      0.59      0.60       119\n         pride       1.00      0.22      0.36         9\n   realization       0.54      0.19      0.28        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.64      0.68      0.66        40\n       sadness       0.49      0.58      0.53        84\n      surprise       0.46      0.62      0.53        95\n       neutral       0.63      0.73      0.68      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.51      0.45      0.46      4548\n  weighted avg       0.59      0.61      0.59      4548\n', 'eval_runtime': 3.0172, 'eval_samples_per_second': 1507.337, 'eval_steps_per_second': 47.394, 'epoch': 7.0}
{'loss': 1.1406, 'grad_norm': 3.7565512657165527, 'learning_rate': 0.0, 'epoch': 8.0}
{'eval_loss': 1.266005039215088, 'eval_accuracy': 0.6077396657871592, 'eval_f1': 0.46614978127110646, 'eval_classification_report': '                precision    recall  f1-score   support\n\n    admiration       0.66      0.79      0.72       326\n     amusement       0.71      0.89      0.79       208\n         anger       0.44      0.50      0.47       109\n     annoyance       0.40      0.22      0.28       164\n      approval       0.44      0.24      0.31       258\n        caring       0.58      0.47      0.52        96\n     confusion       0.45      0.29      0.36       102\n     curiosity       0.47      0.55      0.51       164\n        desire       0.60      0.52      0.56        52\ndisappointment       0.25      0.14      0.18        91\n   disapproval       0.44      0.26      0.33       212\n       disgust       0.47      0.51      0.49        61\n embarrassment       0.67      0.40      0.50        20\n    excitement       0.44      0.33      0.37        52\n          fear       0.66      0.57      0.61        58\n     gratitude       0.91      0.90      0.91       261\n         grief       0.00      0.00      0.00         6\n           joy       0.59      0.54      0.56       106\n          love       0.70      0.90      0.79       173\n   nervousness       1.00      0.12      0.22         8\n      optimism       0.62      0.60      0.61       119\n         pride       1.00      0.22      0.36         9\n   realization       0.52      0.18      0.26        74\n        relief       0.00      0.00      0.00         8\n       remorse       0.62      0.60      0.61        40\n       sadness       0.43      0.61      0.50        84\n      surprise       0.55      0.57      0.56        95\n       neutral       0.63      0.72      0.67      1592\n\n      accuracy                           0.61      4548\n     macro avg       0.54      0.45      0.47      4548\n  weighted avg       0.59      0.61      0.59      4548\n', 'eval_runtime': 3.0104, 'eval_samples_per_second': 1510.765, 'eval_steps_per_second': 47.502, 'epoch': 8.0}
{'train_runtime': 260.0827, 'train_samples_per_second': 1116.814, 'train_steps_per_second': 34.912, 'train_loss': 1.4076498292091135, 'epoch': 8.0}
Saving classifier, encoder, and pooler layers
Gathered layers to save.
Layer weights saved.
Predictions shape:  (4590, 28) 
Labels shape:  (4590, 1) 
Class Predictions:  [25 14 20 ... 27  0 27]
